<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "XHTML1-s.dtd" >
<html xmlns="http://www.w3.org/TR/1999/REC-html-in-xml" xml:lang="en" lang="en">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"></meta>
<style>
.bodyContainer {
    font-family: Arial, Helvetica, sans-serif;
    text-align: center;
    padding-left: 32px;
    padding-right: 32px;
}

.notebookFor {
    font-size: 18px;
    font-weight: 700;
    text-align: center;
    color: rgb(119, 119, 119);
    margin: 24px 0px 0px;
    padding: 0px;
}

.bookTitle {
    font-size: 32px;
    font-weight: 700;
    text-align: center;
    color: #333333;
    margin-top: 22px;
    padding: 0px;
}

.authors {
    font-size: 13px;
    font-weight: 700;
    text-align: center;
    color: rgb(119, 119, 119);
    margin-top: 22px;
    margin-bottom: 24px; 
    padding: 0px;
}

.sectionHeading {
    font-size: 24px;
    font-weight: 700;
    text-align: left;
    color: #333333;
    margin-top: 24px;
    padding: 0px;
}

.noteHeading {
    font-size: 18px;
    font-weight: 700;
    text-align: left;
    color: #333333;
    margin-top: 20px;
    padding: 0px;
}

.noteText {
    font-size: 18px;
    font-weight: 500;
    text-align: left;
    color: #333333;
    margin: 2px 0px 0px;
    padding: 0px;
}

.highlight_blue {
    color: rgb(178, 205, 251);
}

.highlight_orange {
    color: #ffd7ae;
}

.highlight_pink {
    color: rgb(255, 191, 206);
}

.highlight_yellow {
    color: rgb(247, 206, 0);
}

.notebookGraphic {
    margin-top: 10px;
    text-align: left;
}

.notebookGraphic img {
    -o-box-shadow:      0px 0px 5px #888;
    -icab-box-shadow:   0px 0px 5px #888;
    -khtml-box-shadow:  0px 0px 5px #888;
    -moz-box-shadow:    0px 0px 5px #888;
    -webkit-box-shadow: 0px 0px 5px #888;
    box-shadow:         0px 0px 5px #888; 
    max-width: 100%;
    height: auto;
}

hr {
    border: 0px none;
    height: 1px;
    background: none repeat scroll 0% 0% rgb(221, 221, 221);
}
</style>
</head>
<body>
<div class='bodyContainer'>
<h1><div class='notebookFor'>Notes and highlights for</div><div class='bookTitle'>The Dream Machine
</div><div class='authors'>
Waldrop, M. Mitchell
</div></h1><hr/>

<h2 class='sectionHeading'>Prologue:       Tracy’s Dad</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 96</div><div class='noteText'>But the very first thing he’d always do was turn to Tracy and his thirteen - year - old sister Lindy and ask , “ What have you done today that was altruistic , creative , or educational ? ” And he meant it . Tracy and Lindy would have to think through all the things they had done that day to find something they could fit into one of those categories .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 108</div><div class='noteText'>And then there were the art galleries . On the weekends Mom liked to have a little time for herself , so Dad would take Tracy and Lindy out to look at paintings , usually at the National Gallery of Art down on the Mall . It was mostly the Impressionists that Dad liked : Gauguin , Monet , Pissarro , Cézanne . He loved the light , the glow that seemed to come through their paintings . But Dad had also come up with a technique for how you should look at a painting , based on “ color displacements ” ( he had been a psychologist up at Harvard and MIT ) . He claimed that if you covered one eye with your hand and stood back about five feet , and then suddenly dropped your hand so you could look at the picture with both eyes , the flat surface would seem to leap into three dimensions . And it worked ! He and Tracy and Lindy would go wandering through the National Gallery for hours , each of them looking at the paintings with a hand over one eye .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 141</div><div class='noteText'>Tracy had taken to all of this like a natural ; he’d even learned how to program the machine himself . But now , in hindsight , looking back forty years from the perspective of the new millennium , he thinks maybe that’s also why he didn’t pay too much attention to what his father was doing in the Pentagon . He’d been spoiled . He was like one of those kids today who fool around with 3 - D computer graphics , play games off of DVD - ROMs , go blithely surfing through the Internet — and take all of that for granted . Since his father’s joyfully interactive computer was the only one he’d ever seen , Tracy just assumed that computing was like that for everyone . As a teenager , he had no way of knowing that for most people the word computer still meant a big , mysterious mainframe sitting off in a back room somewhere , an ominous , implacable , pitiless machine of the sort that served only large institutions — them — and seemed to be reducing the rest of us to numbers on a punch card . Nor did Tracy have any way of understanding that his father was one of the very few people in the world who had looked at that technology and seen the possibility of something profoundly different .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 156</div><div class='noteText'>Tracy’s dad was doing everything he could to turn that vision into a reality . Up at MIT , for example , he was already in the process of establishing Project MAC , the world’s first large - scale experiment in personal computing . The project managers there couldn’t hope to give anyone a stand - alone personal computer , of course , not with the cheapest machines still costing hundreds of thousands of dollars . But they could scatter dozens of remote terminals around the campus and in people’s homes . And then , through the technology of “ time - sharing , ” they could tell their big , central machine to dole out little slices of processing time very , very rapidly , so that each user would feel as if the thing were responding to him or her as an individual . This scheme would work surprisingly well . Indeed , within just a few years , Project MAC would not only introduce hundreds of people to the joys of interactive computing but also evolve into the world’s first on - line community , complete with on - line bulletin boards , E - mail , a “ freeware ” exchange — and hackers . It would pioneer essentially all the social phenomena that would later be found in the on - line communities of the Internet era .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 165</div><div class='noteText'>remote terminals would plant the notion of a “ home information center , ” an idea that would circulate in the technological community’s collective consciousness until the 1970s , when it would inspire a slew of young hobbyists with names such as Jobs and Wozniak to market something called a microcomputer .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 170</div><div class='noteText'>Douglas Engelbart had been a voice in the wilderness until then ; his own bosses at SRI International , in what would soon become Silicon Valley , thought he was an absolute flake . But once Tracy’s father had given him his first real funding — and vigorously defended him to his higher - ups — Engelbart , with his group , would go on to invent the mouse , on - screen windows , hypertext , full - screen word processing , and a host of other innovations . Engelbart’s December 1968 presentation at a computer meeting in San Francisco would blow about a thousand minds at once — and later be remembered as one of the turning points in computer history , the moment when the rising generation of computer professionals at last began to understand what interactive computing could do . By no coincidence , this was also the rising generation whose members had had their graduate educations supported by Tracy’s dad and his successors at the Pentagon — and a talented portion of which would soon be gathering at PARC , the Xerox Corporation’s legendary Palo Alto Research Center . There they would put Dad’s “ symbiosis ” vision into the form we are still using more than three decades later : a stand - alone personal computer equipped with a graphics display screen and a mouse . A graphical user interface with windows , icons , menus , scroll bars , and all the rest . A laser printer to print things out . And the Ethernet local - area network to tie it all together .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 184</div><div class='noteText'>On April 25 , 1963 , in a memo to “ the members and affiliates of the Intergalactic Computer Network , ” he would outline a key part of his strategy : to connect all their individual computers and time - sharing systems into a single computer network spanning the continent . True , networking technology was still too primitive to enable the creation of such a system — for now , anyway . But Dad’s mind was already racing ahead . He would soon be talking about the Intergalactic Network as an electronic commons open to all , “ the main and essential medium of informational interaction for governments , institutions , corporations , and individuals . ” This electronic commons would support electronic banking , E - commerce , digital libraries , “ investment guidance , tax counseling , selective dissemination of information in your field of specialization , announcement of cultural , sport , and entertainment events ” — and on and on . By the late 1960s such visions would inspire Dad’s hand - picked successors to implement his Intergalactic Network , now known as the Arpanet .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 193</div><div class='noteText'>Tracy’s dad was setting in motion the forces that would give rise to essentially all of modern computing : time - sharing , personal computing , the mouse , graphical user interfaces , the explosion of creativity at Xerox PARC , the Internet — all of it . Of course , not even he could have imagined such an outcome , not in 1962 . But it would have delighted him no end . After all , it was why he had uprooted his family from the home they loved , and why he had come to Washington to work in the sort of bureaucracy he hated : because he believed in his dream . Because he was determined to see it become real . Because the Pentagon — though some of the higher - ups didn’t quite seem to understand this yet — was putting up the money to make it real .</h3>
<h2 class='sectionHeading'>Chapter 1:      Missouri boys</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 245</div><div class='noteText'>As he grew , moreover , his parents encouraged him in piano lessons , tennis , and whatever else he wanted to try , especially if the activity was at all intellectual . And Robnett did not disappoint them , maturing into a bright , energetic boy with a lively sense of fun , an insatiable curiosity , and an abiding love of all things technological .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 285</div><div class='noteText'>He also possessed a streak of mischievous anarchy . When confronted by officious stupidity , for example , he would never challenge it directly ; the belief that a gentleman never caused a scene was bred into his bones . But he loved to subvert it . When he pledged the Sigma Chi fraternity during his freshman year at Washington University , he was informed that pledges had to carry two kinds of cigarettes with them at all times so that upperclassmen could demand a smoke at any hour of the day or night . Not being a smoker himself , he promptly went out and bought the foulest Egyptian cigarettes that St . Louis had to offer . Nobody bothered him for a smoke more than once .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 327</div><div class='noteText'>Lick was in heaven . Physiological psychology had everything he loved : mathematics , electronics , and the challenge of deciphering that ultimate gadget , the brain . He threw himself into it — and in the process , though he certainly couldn’t have known it at the time , he took his first giant step toward that office in the Pentagon . Considering all that happened later , Lick’s youthful passion for psychology might seem like an aberration , a sideline , a twenty - five - year - long diversion from his ultimate career in computers . But in fact , his grounding in psychology would prove central to his very conception of computers . Virtually all the other computer pioneers of his generation would come to the field in the 1940s and 1950s with backgrounds in mathematics , physics , or electrical engineering , technological orientations that led them to focus on gadgetry — on making the machines bigger , faster , and more reliable . Lick was unique in bringing to the field a deep appreciation for human beings : our capacity to perceive , to adapt , to make choices , and to devise completely new ways of tackling apparently intractable problems . As an experimental psychologist , he found these abilities every bit as subtle and as worthy of respect as a computer’s ability to execute an algorithm . And that was why to him , the real challenge would always lie in adapting computers to the humans who used them , thereby exploiting the strengths of each .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 393</div><div class='noteText'>It also has to be said that life under Stevens was not exactly low - key . “ When [ Stevens ] was seriously interested in a problem , he could move forward only at full speed , ” recalled George Miller in a memoir written after Stevens’s death , in 1973 . “ Sometimes he ran over you . ” 3 In truth , Stevens’s title as “ director ” of the Psycho - Acoustics Lab didn’t quite capture the reality . He was its patriarch . “ Stevens was a primitive — he had in him the force of Nature , ” wrote Miller , who first encountered the director in August 1943 , when he arrived to start his graduate studies at Harvard . “ When the clouds gathered and thunder rolled forth , he was as little concerned as Nature for who might be caught in the storm . ” 4</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 410</div><div class='noteText'>“ The first thing I remember Lick doing at the laboratory was to borrow from the petty cash fund — with Smitty’s approval , ” says Karl Kryter , who had been Lick’s roommate and best friend when they were both in graduate school at the University of Rochester , and who arrived at the Psycho - Acoustics Lab not long after him . “ Then he went out to the clothing stores and bought up all these snaps , the kind that you used to make shirts and dresses . He would stay in the lab until one or two in the morning putting together boards and wires with snaps on them . He called this setup the Snappiac . He knew that if you asked the university shop to build you a gizmo for your experiment , it would require two or three months . But with the Snappiac , he could rearrange components very easily , so he could put together any kind of amplifier or electronic components he wanted . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 471</div><div class='noteText'>Lick found time to indulge his endlessly restless curiosity . “ Lick put his oar in almost everywhere , ” recalls Leo Beranek , who was working with him regularly during this period . Indeed , as Louise Licklider had come to know very well by that point , her new husband almost couldn’t help himself : “ He had a very hard time not grabbing on to the latest wave of ideas , ” she remembers , “ or to anything that sounded interesting or that he didn’t know much about . He wanted to learn about physics . He wanted to learn about abstract math . And when he wanted to learn something , he went after the people at the top — the ones who were most imaginative . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 518</div><div class='noteText'>Indeed , Wiener had long since become the single most influential figure at MIT , especially when it came to generating new ideas in unexpected places . He didn’t just cross disciplinary boundaries , noted another commentator ; he never even noticed their existence .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 526</div><div class='noteText'>For all practical purposes , however , his true home was the rarefied air of Cambridge , Massachusetts , where his family had moved in 1895 . Leo Wiener was a prodigiously talented man who was familiar with a broad range of science and mathematics , and who reputedly was able to read some forty different languages ; he eventually became the first professor of Slavic languages at Harvard . But Leo was also a firm believer in nurture over nature : genius , he felt , could be systematically engineered . He therefore took his son’s education in hand when Norbert was age six , and shortly became a harshly perfectionist taskmaster — surprisingly so , since he was a loving parent otherwise . Norbert was often reduced to tears over his lessons . Yet when he went back to public school two years later , he was seven years ahead of his age group — thus his entry into nearby Tufts University at eleven . In 1913 he received his Ph.D . in mathematics from Harvard , at age eighteen .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 538</div><div class='noteText'>It was not a prestigious appointment . MIT’s transformation still lay in the future , and the mathematics department existed mainly to teach math to the engineering students . The school wasn’t oriented toward research at all . However , no one seems to have informed Wiener of that fact , and his mathematical output soon became legendary . The Wiener measure , the Wiener process , the Wiener - Hopf equations , the Paly - Wiener theorems , the Wiener extrapolation of linear times series , generalized harmonic analysis — he saw mathematics everywhere he looked . He also made significant contributions to quantum theory as it developed in the 1920s and 1930s . Moreover , he did all this in a style that left his more conventional colleagues shaking their heads . Instead of treating mathematics as a formal exercise in the manipulation of symbols , Wiener worked by intuition , often groping his way toward a solution by trying to envision some physical model of the problem . He considered mathematical notation and language to be necessary evils at best — things that tended to get in the way of the real ideas .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 584</div><div class='noteText'>“ The thought of every age is reflected in its technique , ” Wiener asserted shortly after the war . During the Scientific Revolution of the seventeenth and eighteenth centuries , for example , when figures such as Galileo , Kepler , and Newton were laying the foundations of modern science , the most advanced and evocative technology had been that of the clock , whose gears seemed to move with the timeless , pristine perfection of a planet orbiting the sun . It was no coincidence that seventeenth - century philosophers such as René Descartes had described even plants and animals as organic clockwork mechanisms . Then , during the Industrial Revolution of the nineteenth century , the defining technology had been that of the steam engine , which was capable of converting vast amounts of energy and heat into work . And again it was no coincidence that scientists of that era had conceived of living organisms as biological heat engines , mechanisms that burned food to do useful physiological work . But now , said Wiener , in the twentieth century , we could perceive the beginnings of a new revolution . Unlike clocks and steam engines , he argued , the emerging technologies of the modern age didn’t just operate blindly , forging ahead without any reference to the world around them . Rather , they operated responsively , taking in information from their surroundings to guide their future actions . “ The machines of which we are now speaking are not the dream of the sensationalist nor the hope of some future time , ” he wrote . “ They already exist as thermostats , automatic gyrocompass ship - steering systems , self - propelled missiles — especially such as seek their target — anti - aircraft fire - control systems , automatically controlled oil - cracking stills , ultra - rapid computing machines , and the like . . . . Scarcely a month passes but a new book appears on these so - called control mechanisms , or servomechanisms , and the present age is as truly the age of servomechanisms as the nineteenth century was the age of the steam engine or the eighteenth century the age of the clock . ” 11</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 600</div><div class='noteText'>By the same token , said Wiener , the dominant sciences of the past had largely been physical sciences , dealing with matter , energy , motion , and intensity . But the central sciences of the modern era would increasingly deal with systems - level issues such as communication , control , organization , and information — whether in “ the animal or the machine , ” as he put it . The older sciences were already homing in on the fundamental nature both of matter and of the universe itself , two of the deepest mysteries of human existence . But the new sciences would point the way toward the fundamental nature of life and the mind , mysteries that the physical sciences had never been able to touch . Indeed , Wiener believed that these new sciences had already brought mankind to the brink of a kind of Grand Unified Theory of behavior , encompassing biological systems and artificial systems alike — a theory based on the underlying themes of communication and control .</h3>
<h2 class='sectionHeading'>Chapter 2:      The last transition</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 618</div><div class='noteText'>Best of all , for Wiener , was that Bush shared his fascination with computing devices . True , this was a distinctly unmathematician - like interest on Wiener’s part : most other members of his tribe were contemptuous of computation , arguing that a real mathematician gained insight by abstract reasoning , not by reckoning . Slide rules were acceptable for scientists and engineers , but brute number crunching was just arithmetic , a task for desktop adding machines — women’s work ( the word computer was still a job description in the 1920s , carrying much the same pink - collar connotation as typist ) . The building of computing machinery was , by extension , a job for mere tinkerers .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 623</div><div class='noteText'>Wiener , however , was among the few great mathematicians who had actually worked as computers , and his patriotic stint calculating artillery trajectories during World War I had taught him all too well that numerical calculation was not just a matter of punching numbers into an adding machine . A professional computer had to understand the whole complex process of computation — knowing which calculations to do in which order , for example , or whether to do this sequence of calculations or that sequence based on the result of , say , step C . That insight in turn resonated with Wiener’s lifelong interest with the workings of the brain and with the fundamental underpinnings of intelligence ( in 1909 he had actually started his graduate studies at Harvard in the zoology department ; until his hopeless clumsiness at the lab bench sent him back to mathematics , he had hoped to make brain science his career ) . The notion of a machine that could automate computation was deeply compelling to Wiener : here was a device that was purely mechanical yet could carry out a task that seemed to embody intelligence itself .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 652</div><div class='noteText'>And the original analyzer had undergone numerous upgrades — including several suggested by Norbert Wiener , whose instinct for understanding mathematical concepts in physical terms had produced a steady stream of ideas for “ analogy machines , ” as he called them . Indeed , over the years Wiener had become a regular visitor at Bush’s lab and a close friend of its director , who later wrote that he’d never realized “ a mathematician and an engineer could have such good times together . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 675</div><div class='noteText'>Bush departed for Washington in January 1939 and immediately started educating himself about the eternal game of politics , an activity that he found distasteful at best but that he knew to be essential to his larger goal of preparedness . He also struggled with the Carnegie Institution itself , which proved to be badly in need of revitalization . And in the meantime , he tried to tie up loose ends from Cambridge — including one idea that had been niggling in his brain for more than half a decade . Bush’s idea had first appeared in print in “ The Inscrutable Thirties , ” a semi - serious speculative article he published in January 1933 . Toward its end , almost in passing , he fantasized about being able to fit an “ unabridged dictionary on a square foot of film , ” and about “ the contents of a thousand volumes [ being ] located in a couple of cubic feet in a desk , so that by depressing a few keys one could have a given page instantly projected before him . ” 2</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 684</div><div class='noteText'>He may well have gotten the idea from librarians , some of whom had been touting the virtues of that medium since 1926 . But whatever had inspired him , Bush had taken the “ library problem ” to heart , declaring it to be the most critical bottleneck in modern research : “ The investigator is staggered by the findings and conclusions of thousands of other workers , ” he wrote a few years later , “ [ yet ] the means we use for threading through the consequent maze to the momentarily important item is the same as was used in the days of square - rigged ships . ” 3</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 698</div><div class='noteText'>Granted , from today’s perspective , Bush’s technology looks hopelessly quaint : his desk library was still very much an analog device , grounded in the microfilm and photocell technologies of the 1930s . In a larger sense , however , his vision was thoroughly modern , so that reading his 1939 draft now is like finding a fragment of turn - of - the - millennium sensibility that has somehow fallen sixty years backward in time . The essence of that sensibility lay in two ideas that were introduced for the first time in the 1939 draft . First , Bush no longer described his desk library as a tool for trained librarians , as he had in previous discussions , but rather characterized it as a device that anyone could use . More than that , he stressed that the desk library wouldn’t just help those nonprofessional users do the same old filing and retrieving a little faster ; it would also support and improve their very “ processes of thought . ” Of course , Bush was writing here for a general audience , so perhaps his emphasis on nonprofessionals shouldn’t be a complete surprise . Nonetheless , his vision of high technology’s enhancing and empowering the individual , as opposed to serving some large institution , was quite radical for 1939 — so radical , in fact , that it wouldn’t really take hold of the public’s imagination for another forty years , at which point it would reemerge as the central message of the personal - computer revolution .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 709</div><div class='noteText'>Even more radical , however , was Bush’s second new idea , which was the mechanism for implementing his vision . Instead of storing those countless microfilmed pages alphabetically , or according to subject , or by any of the other indexing methods in common use — all of which he found hopelessly rigid and arbitrary — Bush proposed a system based on the structure of thought itself . “ The human mind . . . operates by association , ” he noted . “ With one item in its grasp , it snaps instantly to the next that is suggested by the association of thoughts , in accordance with some intricate web of trails carried by the cells of the brain . . . . The speed of action , the intricacy of trails , the detail of mental pictures [ are ] awe - inspiring beyond all else in nature . ” 5 By analogy , he continued , the desk library would allow its user to forge a link between any two items that seemed to have an association ( the example he used was an article on the English long bow , which would be linked to a separate article on the Turkish short bow ; the actual mechanism of the link would be a symbolic code imprinted on the microfilm next to the two items ) . “ Thereafter , ” wrote Bush , “ when one of these items is in view , the other can be instantly recalled merely by tapping a button . . . . It is exactly as though the physical items had been gathered together from widely separated sources and bound together to form a new book . It is more than this , for any item can be joined into numerous trails . ” Such a device needed a name , added Bush , and the analogy to human memory suggested one : “ Memex . ” This name also appeared for the first time in the 1939 draft . In any case , Bush continued , once a Memex user had created an associative trail , he or she could copy it and exchange it with others . This meant that the construction of trails would quickly become a community endeavor , which would over time produce a vast , ever - expanding , and ever more richly cross - linked web of all human knowledge . Bush never explained where this notion of associative trails had come from ( if he even knew ; sometimes things just pop into our heads ) . But there is no doubt that it ranks as the Yankee Inventor’s most profoundly original idea . Today we know it as hypertext . And that vast , hyperlinked web of knowledge is called the World Wide Web .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 730</div><div class='noteText'>The Memex article we know today is a revised version that appeared in the July 1945 issue of the Atlantic Monthly under the title “ As We May Think . ” Even then , if the measure of such an article is its direct , technological impact , the piece must be judged a failure . The initial public response was quite favorable , much to Bush’s satisfaction . Yet in hindsight , he had managed to be both too far behind the times — his analog microfilm approach was hopelessly unworkable — and too far ahead of them : the newly emerging digital technology was hopelessly immature . Indirectly , however , the article’s influence would be profound . In effect , Bush’s larger vision of individual empowerment and creative enhancement was taken into the computer community’s collective unconscious , lurking in certain brains like a time bomb that wouldn’t explode for another twenty or thirty years , when the technology to realize that vision was finally ready .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 770</div><div class='noteText'>Once again , that last objection loomed larger in 1940 than we can easily understand now . Today we speak of “ the computer ” as if it were a single thing that had to be invented only once . But as Wiener’s list of features suggests , the modern digital computer is actually a combination of at least half a dozen separate inventions , most of which involved not just another gadget but a shift in the way people thought about computing . At the time of Wiener’s memo , moreover , it was far from clear whether he or anyone else had put the individual pieces together in the right way ; those conceptual transitions were still very much works in progress .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 782</div><div class='noteText'>Better yet , for Vannevar Bush and for many others , was that analog machines had a wonderfully evocative quality . They didn’t just calculate an answer ; they invited you to go in and make a tangible model of the world with your own hands , and then they acted out the unfolding reality right before your eyes . For anyone watching that process , Bush wrote , “ one part at least of formal mathematics will become a live thing . ” 8 Compared to that , digital computers seemed static and dead , nothing but electrons zipping invisibly through wires . That may have been why Bush himself later seemed to feel such a sense of loss as digital computing swept the world , starting in the 1950s . Certainly he never wavered in his own commitment to the analog approach . Doggedly , and without success , the Best Apparatus Man in America kept on trying to come up with a workable analog design for his Memex until his death , in 1974 . And until the end , his colleagues could hear him grumbling about the “ damn digital computer . ” All of which just goes to show that Fate does have a sense of irony . The qualities that would give digital computers their ultimate advantage over analog machines — their vastly greater flexibility and programmability — were still only dimly perceived in 1940 ( indeed , it would be several years yet before anyone even demonstrated a programmable digital computer ) . But one of the biggest single steps in that direction had already been taken — thanks to Vannevar Bush’s own Differential Analyzer .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 825</div><div class='noteText'>“ A Symbolic Analysis of Relay and Switching Circuits ” has just the kind of cerebral exuberance you’d expect from a very bright twenty - one - year - old . Shannon’s thesis is downright fun to read — and strangely compelling , given what’s happened in the six decades since it was written . In an aside toward the end , for example , Shannon points out that true and false could equally well be denoted by the digits 1 and 0 , in which case the operation of the relays could be associated with what was then an arcane and unfamiliar form of arithmetic — namely , binary arithmetic .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1006</div><div class='noteText'>So there it was : the history of the computer in the 1930s was a history of conceptual groping on the part of many individuals , each one wrestling with recalcitrant hardware and each one solving a piece of the conceptual puzzle . But only at the end of the decade were a few people such as Norbert Wiener beginning to put all the pieces together — and even they were only just beginning . ‡ Ultimately , in fact , it would take the war itself to forge those pieces into a unified whole . The war , that is , plus a small group of young men with insufficient respect for the wisdom of their elders — and another world - famous mathematician on an insatiable quest for calculating power .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1235</div><div class='noteText'>“ According to my definition , ” Turing proclaimed at the outset of his manuscript , “ a number is computable if its decimal can be written down by a machine . ” This was taking Newman at his word about a “ mechanical process . ” But still , as Turing’s biographer Andrew Hodges points out , proper mathematical arguments were supposed to be couched in terms of abstract symbols and formal reasoning . In that context , Turing’s statement sounded almost shockingly industrial . But things quickly got even stranger : as he began to describe the structure of his imaginary machine , Turing seemed to veer off into a kind of abstract psychology .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1275</div><div class='noteText'>But Turing’s argument applies to any nontrivial behavior : except in very special cases , the fastest way to find out if your program will take a given action is to run it and see . And that , in turn , means that the old saying about the mindlessness of computers is true but also irrelevant . A computer does only what its programmers tell it to do — but the programmers can’t really know the consequences of their commands until they see their program running . ( That’s one big reason software vendors have to spend so much time debugging their products : there is no universal testing program that can guarantee another program’s correctness . ) Or to say it still another way , the imaginary machine that Turing modeled on human mathematicians had some of the same unpredictability as the human mind .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1407</div><div class='noteText'>Through feedback , said Wiener , Bigelow , and Rosenblueth , a mechanism could embody purpose .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1411</div><div class='noteText'>Consider that humble thermostat again . It definitely embodies a purpose : to keep the room at a constant temperature . And yet there is nothing you can point to and say , “ Here it is — this is the psychological state called purpose . ” Rather , purpose in the thermostat is a property of the system as a whole and how its components are organized . It is a mental state that is invisible and ineffable , yet a natural phenomenon that is perfectly comprehensible .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1416</div><div class='noteText'>If we can understand how ordinary matter in the form of a machine can embody purpose , then we can also begin to understand how those three pounds of ordinary matter inside our skulls can embody purpose — and spirit , and will , and volition . Conversely , if we can see living organisms as ( enormously complex ) feedback systems actively interacting with their environments , then we can begin to comprehend how the ineffable qualities of mind are not separate from the body but rather inextricably bound up in it .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1444</div><div class='noteText'>Their own paper , published in 1943 as “ A Logical Calculus of the Ideas Immanent in Nervous Activity , ” was essentially a demonstration that their idealized neural networks were functionally equivalent to Turing machines . That is , any problem that a Turing machine could solve , an appropriately designed network could also solve . And conversely , anything that was beyond a Turing machine’s power — such as the decidability problem — was likewise beyond a network’s power . As the science historian William Aspray has written , “ With the Turing machines providing an abstract characterization of thinking in the machine world and McCulloch and Pitts’s neuron nets providing one in the biological world , the equivalence result suggested a unified theory of thought that broke down barriers between the physical and biological worlds . ” 14 Or , as McCulloch himself would put it in his 1965 autobiography Embodiments of Mind , he and Pitts had proved the equivalence of all general Turing machines , whether “ man - made or begotten . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1461</div><div class='noteText'>Indeed , von Neumann had found the analogy so compelling that in late 1944 he had joined forces with Wiener and Aiken to organize a conference on the subject . Held at Princeton on January 6 – 7 , 1945 , the meeting was a tiny affair that included only the three organizers plus McCulloch , Pitts , Goldstine , and a number of like - minded neurophysiologists — fewer than a dozen people , all told . But it definitely had an impact . With a lecture on computing machines given by von Neumann , one on communications engineering by Wiener , and still others on the structure of the brain by McCulloch and Rafael Lorente de No of Rockefeller University , plus some extremely lively discussions , it was later cited by Wiener as one of the defining moments in his emerging science of communication and control . Given the presence of von Neumann , Goldstine , and Aiken , moreover , it symbolized the emergence of the modern computer - research community , which today numbers in the millions . In those war years , the scattered computer pioneers were finally beginning to meet one another face to face , where they could trade ideas directly and start to learn from their respective experiences .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1486</div><div class='noteText'>Even more telling , however , was the fact that as von Neumann went on to describe the five functional units of his abstract computer , he referred to them as “ organs ” and went out of his way to make provocative comparisons with biological functions . Within the first page or two of his report , for instance , he was comparing the input units of the machine with the sensory neurons of the brain , the ones that allow us to perceive the world . He likewise compared the output units with the motor neurons of the brain , the ones that govern bone , muscle , and action . And then he compared the remaining three functions with the brain’s associative neurons , which are devoted to abstract thought . The central arithmetic unit , for example , would be the computer’s own internal calculating machine , the high - speed , electronic equivalent of an accountant’s desktop calculator . This was the portion of the computer that would do the actual work of computation , carrying out additions , subtractions , multiplications , divisions , square roots , and the like , as needed . ( All calculations , of course , were to be done in binary arithmetic . ) Next , said von Neumann , the memory unit would be the computer’s electronic scratch pad , the place where it stored data , programs , intermediate results , and the final answer . Following a careful analysis of typical problems in fields such as statistics and fluid dynamics , von Neumann estimated that the memory unit would need a capacity of at least 256,000 binary digits — just thirty - two kilobytes in modern parlance , but a number that he clearly found daunting in 1945 . After much additional discussion , he concluded that such a memory could be built , though it would be at the outer edge of technological feasibility . ( He was right : memory would continue to be the biggest single constraint on computer performance until the microchip revolution of the 1970s . ) Finally , said von Neumann , the central control unit would be the heart of the computer , the part that decided what to do next . ( Today this is usually known as the central processing unit , or CPU . ) Its decisions would in turn be governed by a program stored in the memory unit . This left just one critical question : How was the central control unit supposed to go about executing those programs ? Von Neumann had quite a bit of leeway in his answer , thanks to Alan Turing . As he was undoubtedly well aware , his abstract architecture was logically equivalent to a Turing machine , with the memory , input , and output units collectively corresponding to the tape , and the central arithmetic and central control units collectively corresponding to the read / write head . § In particular , von Neumann knew that his architecture was universal in precisely the same sense as Turing’s , which meant that he ( like the generations of computer designers to come after him ) was free to focus his attention on real - world factors such as cost , speed , efficiency , and reliability , without having to worry about his machine’s fundamental ability to compute : there was nothing one design could do that another couldn’t , given enough time and storage capacity .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1525</div><div class='noteText'>Even as it stood , however , the draft was compelling . After a decade in which the computer pioneers had struggled to master the vagaries of hardware , barely able to see the forest for the trees , von Neumann had laid out the fundamental principles of computer design with breathtaking clarity . His paper was so good , in fact , that Goldstine , in what was apparently a burst of innocent enthusiasm , had it typed up verbatim as “ First Draft of a Report on the EDVAC ” and circulated it within the group for discussion — under von Neumann’s name alone . Goldstine thereby gave outsiders their first inkling of what was going on at the Moore School , since it wasn’t long before copies reached the hands of other groups working on high - speed computers . But alas , that very fact would soon give rise to a feud that would tear the Moore School group apart .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1554</div><div class='noteText'>Straightforward or not , however , the stored - program idea was the key technical advance in EDVAC . Eckert and Mauchly were anxious to patent it , arguing with some justice that they had conceived of it independently and that von Neumann’s report had simply summarized the thinking of the group as a whole . As time went on , however , von Neumann proved just as eager to keep them from monopolizing the idea . He refused to acknowledge them as the originators of the stored - program concept , insisting that so much had been said during their early discussions that it was impossible to assign specific credit to anyone . As a result , what had started out as annoyance quickly gave way to bitterness , with Eckert and Mauchly on one side versus Goldstine and von Neumann on the other . Indeed , it soon became a three - sided argument , since the University of Pennsylvania also felt that it had some claim to the idea : Eckert and Mauchly , after all , were university employees and had done their work on university time . So for the time being , at least , the university forbade Eckert and Mauchly to apply for any patent in their own names .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1573</div><div class='noteText'>The mess promptly landed in the lap of the army , whose role as the funding agency for both ENIAC and EDVAC gave it final authority in the matter . The whole unedifying saga would drag on for another year , ending only in April 1947 , when exasperated army attorneys at last threw out everybody’s patent claims on the ground that von Neumann’s “ First Draft ” paper represented prior public disclosure . They decreed that the stored - program idea rightfully belonged in the public domain . And there it has remained . That was probably just as well . However fierce the controversy surrounding its birth , the stored - program concept now ranks as one of the great ideas of the computer age — arguably the great idea .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1579</div><div class='noteText'>By rendering software completely abstract and decoupling it from the physical hardware , the stored - program concept has had the paradoxical effect of making software into something that is almost physically tangible . Software has become a medium that can be molded , sculpted , and engineered on its own terms . Indeed , as the Yale University computer scientist David Gelernter has pointed out , the modern relationship between software and hardware is essentially the same as that between music and the instrument or voice that brings it to life . A single computer can transform itself into the cockpit of a fighter jet , a budget projection , a chapter of a novel , or whatever else you want , just as a single piano can be used to play Bach or funky blues . Conversely , a spreadsheet file can ( with a little effort ) be run on a Microsoft Windows machine , a Macintosh , or a Unix workstation , just as a Bach fugue can be performed on a pipe organ or by an ensemble of tubas . The bits and bytes that encode the spreadsheet obviously can’t function without the computer , any more than a page full of notes can become music without a performer . And yet the spreadsheet also transcends the computer , in exactly the same way that the Bach fugue transcends any given performance of it . Everything important about that spreadsheet — its on - screen appearance , its structure , its logic , its functionality , its ability to respond to the user — exists , like the harmonies and cadences of Bach , in an abstract , platonic world of its own .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1590</div><div class='noteText'>Metaphorically , at least , this abstraction is probably about as close as science and technology have ever come to the pagan notion of animation , spirit , enchantment . It is certainly a big part of what gives computers their emotional clout . Anyone who has ever switched on a personal computer has felt it : watching the programs fill the screen is disconcertingly like watching a dead thing come alive . Without software , the glowing glass box is just a glass box . With software , it becomes what the MIT sociologist Sherry Turkle has dubbed the first psychological machine — active , surprising , goal - driven , and capable of responding to us in ways that no ordinary machine could ever do . “ A new mind that is not yet a mind , ” Turkle called the computer in her 1984 book , The Second Self , “ a new object , betwixt and between , equally shrouded in superstition as well as science . ” More recently , of course , software has also become the basis of a whole new abstraction , that vast network of interlinked computers known variously as the Internet , the Web , or cyberspace . After all , it is only when software becomes independent of hardware that we can even think about sending files and programs over a telephone line or a high - speed data network . Indeed , cyberspace now seems set to raise the software abstraction to yet another level , where programs won’t even be tied to one place anymore . Instead , software “ agents ” searching for data will be able to leave their home computers and fan out through the network at will , merging , spawning , communicating , collaborating , and leaping from machine to machine like a society of tame computer viruses .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1603</div><div class='noteText'>In any case , the stored - program concept articulated in von Neumann’s 101 - page “ First Draft ” marked the beginning of the last great transition in the development of computers , a transition that is still going on today . It was the shift in focus from structure to behavior , from how computers were made to what they could do . Before von Neumann’s paper , people viewed electronic digital computers merely as fancier and fancier adding machines . The things were immensely useful , to be sure , but they were still just crunchers of numbers . After von Neumann’s paper — though it would take the better part of a generation before this really became clear — people could begin to conceive of these machines as something fundamentally new . Computing machines had become computers , the devices that implemented software .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1626</div><div class='noteText'>Zuse told his story in 1979 , at the same history - of - computing conference that George Stibitz attended . His account is published as “ Some Remarks on the History of Computing in Germany ” in A History of Computing in the Twentieth Century , edited by N . Metropolis , J . Howlett , and Gian - Carlo Rota ( New York : Academic Press , 1980 ) , 611 – 27 . Zuse died at his home in Hünfeld , Germany , on December 18 , 1995 .</h3>
<h2 class='sectionHeading'>Chapter 3:      New kinds of people</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1676</div><div class='noteText'>In effect — though he himself probably wouldn’t have expressed it this way — Lick was trying to do for the human auditory cortex what von Neumann had done for computers in his “ First Draft ” : he was trying to understand the brain in architectural terms , rather than focus on the specific neural details . “ Lick approached any problem we were dealing with as a systems problem , ” said McGill . For example , he might sit someone down in front of an oscilloscope where a dot was moving erratically on the screen , and ask him or her to keep a circle centered on the dot . Since nobody could do it perfectly , Lick would record the tracking errors and then use that record to try to reconstruct the machinery of hand - eye coordination , asking himself what kind of neural circuitry would produce exactly those errors and no others . Likewise , in his “ Duplex Theory of Pitch Perception , ” Lick came up with a McCulloch - and - Pitts - style neural - network model to explain the pitchlike quality that musicians call chroma or tonality .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1686</div><div class='noteText'>What Lick was doing came out of systems engineering , the construction of servomechanisms , the construction of equipment for human operators in advanced aircraft — Lick must have developed these ideas by talking to electrical engineers and aircraft designers during the war . ” But just as influential was the intellectual turmoil surrounding Wiener and company . As George Miller told the psychologist Bernard J . Baars for the latter’s book The Cognitive Revolution in Psychology , “ Norbert was around , and we read his books , and we all were impressed with things like . . . the Rosenblueth - Wiener - Bigelow paper on feedback systems that set their own goals . Those things had quite a freeing effect . ” Miller also remembers being deeply impressed by McCulloch and Pitts’s wartime work on neural - network theory . “ We all thought it was wonderful , ” he says . “ Lick and I taught about it in our seminars . And right after the war we got Walter Pitts to come over from MIT to explain it to us . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1737</div><div class='noteText'>Watson , by contrast , came down on the “ body ” side of the duality , with a fervor that may well have had something to do with his strict Baptist upbringing in South Carolina . Human beings were automatons , he declared , describable in purely natural terms . Their behavior was nothing more than a series of learned responses to outside stimuli ; the “ mind , ” assuming that it even existed , was irrelevant . As Watson boasted in his 1930 book Behaviorism , “ Give me a dozen healthy infants , well - formed [ , ] and my own specified world to bring them up in and I’ll guarantee to take any one at random and train him to become any type of specialist I might select — doctor , lawyer , artist , merchant - chief and yes , even beggar - man and thief , regardless of his talents , penchants , tendencies , abilities , vocations , and [ the ] race of his ancestors . ” Indeed , he continued , we might even imagine a utopian future built around “ behavioristic freedom , ” in which children would be scientifically conditioned to produce a rationally ordered culture : “ Will not these children . . . with their better ways of living and thinking , replace us as a society , and in turn bring up their children in a still more scientific way , until the world finally becomes a place fit for human habitation ? ” Today , of course , that passage sounds profoundly cynical and manipulative , not to mention Orwellian . It seems somehow appropriate that after 1920 , when he was forced out of academia by a messy divorce scandal , Watson made a lucrative second career for himself as vice president of the advertising firm J . Walter Thompson . Condition people’s responses properly , he seemed to be saying , and you can make them do anything . And yet in the 1920s such ideas seemed just the opposite of cynical . Not only did behaviorism resonate with Americans ’ egalitarian belief that any child could grow up to become president , but in the bloody aftermath of the Great War it seemed like the last , best hope of saving the world . Certainly it allowed a great many psychologists to conduct their research in a spirit of idealism — and , not incidentally , with a rigor rivaling that employed in physics and chemistry . Behaviorist psychology would produce generations of well - conditioned pigeons and mice that would peck at lights or run through mazes with all the precision of planets orbiting the Sun . And that , in the status - conscious world of science , meant that psychologists could at last hold their heads high : they , too , were practicing a “ hard ” science .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1758</div><div class='noteText'>The power , the honors , the authority , the textbooks , the money , everything in psychology was owned by the behavioristic school . Those who didn’t give a damn , in clinical or social psychology , went off and did their own thing . But those of us who wanted to be scientific psychologists couldn’t really oppose it . You just wouldn’t get a job . ” Indeed , young researchers quickly learned not to use the word mind at all , even in casual conversation , lest they be declared “ unscientific ” and thereby undermine their own careers .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1765</div><div class='noteText'>It is impossible to know precisely why Skinner was so rabid on this subject , though it’s telling that his own religious upbringing had been just as strict as John B . Watson’s , and his rejection of it just as visceral . Fanatical or not , though , Skinner had recruited an impressive number of followers . His scientific credibility was enormous : in the early 1930s he had single - handedly established the field of “ operant ” conditioning , in which animals were trained to exhibit almost any desired behavior through a system of reward and punishment . And he was a wonderfully charismatic figure , with an undeniable flair for publicity and the dramatic gesture . He had raised his own infant daughter partially inside a babysized , Plexiglas “ Skinner box ” rigged for the appropriate rewards and punishments ; the reporters had eaten it up . He arrived at Harvard having just published the utopian novel Walden Two , in which he described an idyllic community governed by behaviorist principles ; he made it sound so attractive that he immediately became the guru for hundreds of disciples who sought to shape their lives by those principles . Then , some time after his arrival at Harvard , he hosted a group of reporters and photographers from Life magazine ; while he lectured them about the wonders of operant conditioning , his students , in the background , were photogenically training pigeons to play Ping - Pong .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1900</div><div class='noteText'>Shannon was determined to find a theory that could be applied not just to telephones but to any form of communication , from telegraphs and televisions to casual conversation or even nerve impulses . To achieve that ambitious goal , he first imagined the communication process as being divided into five parts : An information source : the person or thing generating the original message . A transmitter : the instrument that transforms the message into a signal suitable for transmission ( the voice that produces a sound wave , the telephone that produces an electrical signal , etc . ) . A communication channel : the medium that conducts the signal ( air , a telephone wire , a coaxial cable , a beam of light , etc . ) . A receiver : the instrument that takes the signal and tries to reconstruct the message ( the ear , the telephone on the receiving end , etc . ) . A destination : the person or thing the message is intended for . This deceptively simple five - part framework had the great virtue of clarity : just as John von Neumann’s abstract functional design for EDVAC would later do for computer engineering , Shannon’s outline gave him a way to think about the architecture of communication and what a given system was supposed to accomplish , preventing him from getting bogged down in the vagaries of vacuum tubes and cable connections . It provided the generality he needed to devise a truly fundamental theory of communications , in much the same way that Sir Isaac Newton had derived a fundamental theory of physics from just three general laws of motion and one universal law of gravitation . And yet it simultaneously gave him a framework that he could tailor to any given problem , much as Newton’s laws could be applied to the fall of an apple or the motions of the Moon .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1919</div><div class='noteText'>The term “ information ” had been common parlance around Bell Labs since 1928 , when an engineer there named Ralph Hartley had first used it to describe the amount of message flowing through a telephone wire , as opposed to static . Building on earlier work by Bell Labs mathematician Harry Nyquist — who had called it intelligence — Hartley had defined “ information ” as the useful part of the signal , the part that people wanted to listen to , the part that the engineers were always trying to maximize in the face of noise and distortion . More precisely , he said , “ information ” ought to measure how much you actually learned from a given message .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1928</div><div class='noteText'>At least in the simplest cases , said Shannon , the information content of a message was just the number of binary 1s and 0s required to encode it . For example , if you knew in advance that a message would convey a simple binary choice — yes or no , true or false , black or white — then one binary digit would suffice : a single 1 or a single 0 would tell you all you needed to know . That message would be said to contain one unit of information . However , if the message was more complicated , it would require more digits to encode and would contain that much more information ( think of the thousands of electronic 1s and 0s that make up a modern word - processing file ) . Of course , this definition did have its perverse aspects , as Shannon knew full well . If the two alternatives were yes and no , say , then the actual message might carry a world of meaning — as in “ Yes , I will marry you ” — but only one binary unit of information . The content and significance of the message , being unquantifiable , would just be ignored . Conversely , a long and turgid legal document might convey no meaning whatsoever to the recipient while , because of its very length , comprising a huge amount of information .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1938</div><div class='noteText'>Nonetheless , as Shannon would point out in his 1948 paper , the separation of information and meaning did have the virtue of putting the interpretation of meaning where it belonged : in the brains of the people sending and receiving the message . The engineers ’ job was merely to get the message from here to there with a minimum of distortion , whatever it might say . And for that purpose , the digital definition of information was ideal because it allowed for a precise mathematical analysis via questions such as , What are the fundamental limits of a given communication channel’s carrying capacity ? How much of that capacity can be used in practice ? How much is it degraded by the inevitable presence of noise in the line ? What are the best and most efficient ways to encode the information for transmittal in the presence of noise ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1945</div><div class='noteText'>Suppose you’re trying to send a birthday greeting down a telegraph line , say , or through a wireless link . The communication channel has an information capacity of so many binary digits per second . And the message likewise carries an average information content of so many binary digits per letter . But taken together , Shannon realized , these two quantities determine a fundamental speed limit , measured in binary digits per second . Above that speed limit , perfect fidelity is impossible : however cleverly you encode your message and compress it , you simply cannot make it go any faster unless you first throw some information away . Below that speed limit , however , the transmission is potentially perfect . Shannon was able to show that there must exist codes that will get you right up to the limit without losing any information at all . Moreover , such perfection is possible even in the presence of noise . Shannon demonstrated that no matter how much static and distortion there may be in a given communications channel , and no matter how faint the signal , messages can still get through with perfect fidelity . Of course , if the signal is very , very faint , you may have to assign a huge number of 1s and 0s to each letter or pixel so that some of them have a chance of getting through . And you may have to devise all kinds of elaborate error - correcting codes so that corrupted parts of the message can be reconstructed at the other end . In practice , diminishing returns will set in : the codes will eventually get so long and the communication so slow that you’ll have to give up and let the noise win . But in principle , you can make the probability of error as close to zero as you want . This “ fundamental theorem ” of information theory , as Shannon later called it , surprised even him : the conquest of noise seemed to violate common sense . And yet it was true . Just a few years earlier , with his master’s thesis on logic and switching , Shannon had laid the foundation for all of modern computer circuitry ; now , working on his own in the middle of the war , he had quietly done the same for most of the rest of the modern digital world .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1976</div><div class='noteText'>Indeed , as Turing’s biographer Andrew Hodges points out , there had been not only a parallel between Shannon’s work and Turing’s , but a kind of reciprocity . Turing had started from the concept of computability and come to realize that computation was inextricably bound up with information and encryption ; the very fact that his abstract machine had to read and write symbols encoded on a data tape guaranteed it . ( At Bletchley Park , in fact , Turing had invented the “ deciban , ” a measure of information content that was conceptually identical to Shannon’s . ) Shannon , conversely , had started from the communication and information end and come to much the same conclusion . In his five - part architecture of communication , after all , there was always a transmitter to encode the message and a receiver to decode it at the other end ( his example in the 1948 paper would be a transmitter that scanned through an English text letter by letter and turned it into Morse code ) . But whatever the physical structure of these devices — whether you were talking about the vocal chords and the ear , say , or a microphone and a radio receiver — they each took an input stream of information and converted it into an output stream using a well - defined procedure . And that process , broadly defined , was computation .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 1996</div><div class='noteText'>Over lunch one day in late 1946 , a group of Bell Labs researchers were grousing about the awkwardness of the term “ binary digit ” and deploring the lack of any good substitute ( existing proposals included hybrids such as binit and bigit , both considered loathsome ) . But then the statistician John Tukey joined the discussion . “ Well , ” he asked with a grin , “ isn’t the word obviously bit ? ” And it was . 2</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2009</div><div class='noteText'>It all depended on how you interpreted “ information theory . ” If you meant the specific set of mathematical tools that Shannon was inventing for communication engineers , then no , Wiener had not had much , if anything , to do with it . However , if you meant the broader concept of message in all its aspects , then yes , Wiener had been immersed in the field since the 1920s . His inspiration had come from Vannevar Bush , who’d explained to him that electrical engineering actually embraced two separate disciplines : power engineering , where the goal was to optimize the flow of energy through a line , and communication engineering , where the goal was to modulate a comparatively trivial energy flow into a meaningful signal . Wiener had been enchanted with this insight and deeply influenced by it . It had led directly to some of his most important technical work in the 1920s and 1930s , work that was certainly similar in spirit to Shannon’s theory and that ultimately resulted in a definition of information flow that was mathematically identical to his .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2053</div><div class='noteText'>However , there was even better yet to come . At the mathematics conference in Nancy , he was introduced to a Monsieur Freyman , a Mexican - born mathematician who was representing the French publishing house Hermann et Cie . M . Freyman had a proposal : might Professor Wiener be interested in writing a short book to explain his ideas about communication and control ? Professor Wiener would be fascinated ; at the moment the state of his personal finances was rather , um , fragile . So , he later recalled , “ over a cup of cocoa at a neighboring patisserie , ” he happily signed a contract . He went to work almost immediately , writing his book in Mexico City during the summer and fall of 1947 while spending a sabbatical semester with Arturo Rosenblueth at the Instituto Nacional de Cardiologia . ( In fact , he would dedicate the volume to Rosenblueth , “ for many years my companion in science . ” ) In the process , moreover , Wiener finally figured out what to call his new science . Wiener’s assistant Oliver Selfridge , who was also down in Mexico City that semester , along with Walter Pitts , remembers Wiener’s going through his reasoning for them one evening over coffee as they sat in the lovely rooftop garden of his apartment house . Given the central role of communication in his new science , Wiener explained , his first thought had been to derive a name from the Greek word for “ messenger . ” Unfortunately , that word was angelos , which in English had long since taken on the specific meaning of “ a messenger from God . ” Somehow , a new science of angelics wasn’t quite what he was looking for . So instead , said Wiener , he had decided to focus on the theme of control . In Latin , he knew , the word for “ steersman ” was gubernator , from which we get the English word governor . That was better , since the word governor could sometimes refer to a device used to control the speed of an engine . More often , though , it referred to a human “ governor , ” or steersman for policy : the wrong connotation again . However , the Latin gubernator turned out to be a corruption of the Greek word for “ steersman , ” kybernetes . And that , Wiener felt , could be transmuted into English very nicely , as cybernetics . Selfridge and Pitts agreed that cybernetics was indeed an excellent name for the new science . And so , blissfully ignorant that he had just given later generations the means to coin an endless string of buzzwords — cyberspace , cybercash , cyberpunk , cybersex , ad infinitum — Wiener continued writing .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2081</div><div class='noteText'>The new technology of machines guided by the feedback principle had the power to remake the world , he believed . And the public deserved to know that — especially since , as he put it , “ this new development has unbounded possibilities for good and for evil . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2136</div><div class='noteText'>And by 1946 , von Neumann , Goldstine , and Burks had laid out a more refined concept of machine architecture in “ Preliminary Discussion of the Logical Design of an Electronic Computing Instrument , ” a report that would prove to be even more influential than “ First Draft . ” Among many other things , the 1946 report pointed out how much more efficient a computer would be if it could get access to each memory address at “ random ” — that is , instantaneously , without having to wait until the correct address came around on a circulating tape or a mercury delay line . Naturally , such a storage scheme became known as Random - Access Memory , or RAM . ( Of course , the report also concluded that the memory unit should store the data as charged spots on the face of a cathode - ray tube — a cutting - edge technology in 1946 , but now so thoroughly obsolete that almost no one remembers it . )</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2167</div><div class='noteText'>Since 1946 , meanwhile , von Neumann had been attempting to create a “ General and Logical Theory of Automata ” that would integrate his own ideas about computing with the work of Wiener , Turing , Shannon , McCulloch , Pitts , and many others . Unfortunately , von Neumann was too preoccupied with his other duties ever to take his theory very far . Nonetheless , remarks he made at various times suggested that he intended the word automaton to encompass not just computers but brains , radar systems , the telephone system , homeostatic systems within biology , and anything else that processed information and regulated itself . In at least one instance , moreover , his theory proved to be spectacularly prescient .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2173</div><div class='noteText'>In the case of , say , a factory machine tool , von Neumann observed , you have an automaton that can turn out very complex parts but not another machine tool . Likewise , a universal Turing machine can output an arbitrarily complex tape but not another Turing machine . However , in almost any biological organism , you have an automaton that can not only reproduce identical copies of itself but also ( through evolution ) give rise to organisms that are more complex than itself . So von Neumann asked , What are the essential features required for an automaton to reproduce itself and to evolve ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2214</div><div class='noteText'>That said , though , he did throw himself into the arms race with an undeniable zeal . He had no compunction about continuing to work on the hydrogen bomb — which would be thousands of times more powerful than the uranium and plutonium bombs that had destroyed Hiroshima and Nagasaki — even as many Manhattan Project veterans were openly questioning the morality of such a device , not to mention its technical feasibility . “ I believe there is no such thing as saturation , ” he once told Robert Oppenheimer . “ I don’t think any weapon can be too large . ” 11 And after August 1949 , when the Soviets stunned the world by testing an atomic weapon of their own , von Neumann was reportedly willing to contemplate a preemptive war : “ If you say why not bomb them tomorrow , ” he was later quoted as having suggested , “ I say why not today ? If you say today at five o’clock , I say why not one o’clock ? ” 12 Wiener , not surprisingly , was appalled by that attitude . Not only did he see it as the kind of adolescent saber - rattling that was going to get us all incinerated , but he felt that his old friend had come to personify a dangerously seductive brand of intellectual hubris . Through the use of innovative analytical tools such as von Neumann’s game theory , went the argument — an argument that was already being embraced by strategic thinkers in the government and in newly formed think tanks such as the RAND Corporation — the nuclear - arms race could be rationalized , mathematized , reasoned about , and managed .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2243</div><div class='noteText'>Society , for him , was more closely akin to what would now be called a complex adaptive system — a constantly evolving , endlessly surprising web of interacting players and overlapping feedback loops . “ In the overwhelming majority of cases , ” Wiener insisted , “ when the number of players is large , the result is one of extreme indeterminacy and instability . ” In that kind of environment , he continued , it was foolhardy to assume that technological “ progress ” would always be benign . Consider the Industrial Revolution of the nineteenth century , for example , which had vastly increased the wealth and economic productivity of England , the United States , and many other countries but had also created the fetid slums and hellish factories described by Dickens . To Wiener , there seemed every possibility that computers and other such technologies of the cybernetic age — he would later coin the phrase “ the Second Industrial Revolution ” — would have consequences just as dire .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2266</div><div class='noteText'>“ From the point of view of cybernetics , the world is an organism , ” Wiener declared in his autobiography . “ In such a world , knowledge is in its essence the process of knowing . . . . Knowledge is an aspect of life which must be interpreted while we are living , if it is to be interpreted at all . Life is the continual interplay between the individual and his environment rather than a way of existing under the form of eternity . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2272</div><div class='noteText'>“ Even when the individual believes that science contributes to the human ends which he has at heart , ” he would write in 1960 , “ his belief needs a continual scanning and re - evaluation which is only partly possible . For the individual scientist , even the partial appraisal of this liaison between the man and the [ historical ] process requires an imaginative forward glance at history which is difficult , exacting , and only limitedly achievable . . . . We must always exert the full strength of our imagination . ” 17 And that , of course , was exactly what Wiener planned to do with Cybernetics .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2311</div><div class='noteText'>Information theory was being greatly oversold , he asserted in a 1956 editorial entitled “ The Bandwagon , ” and some moderation was in order . “ It has perhaps ballooned to an importance beyond its actual accomplishments , ” he wrote . “ Seldom do more than a few of nature’s secrets give way at one time . ” 18</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2323</div><div class='noteText'>For all Shannon’s unwanted celebrity , it’s hard to say whether he or Norbert Wiener bore more responsibility for the Information Bomb . After all , Cybernetics hit the bookstores only a few months after Shannon’s paper appeared , and greatly reinforced its message . Together , the two theories became like a self - exciting system , inseparable in their effects . There’s no question at all , however , about which of the two men had more fun . In the beginning , it’s true , most people found Cybernetics almost as hard to read as it had been for Wiener to write .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2357</div><div class='noteText'>He didn’t call it the Information Age ; that term would be invented later , by others . But he made it clear that this magical stuff called information lay at its heart . Information was a substance as old as the first living cell and as new as the latest technology . It was the stuff that flowed through communication channels ; indeed , it was the stuff that messages were made of . But it was also the stuff that concepts and images and stored programs were made of . It was the stuff that entered the eyes and the ears , that flowed through the brain , that provided the feedback for purposeful action . Information was what computers and brains were about . It was the one central concept that unified communication , computation , and control and made them all seem like different facets of one underlying reality . Information was at once the stuff of a new world and a whole new way of understanding that world .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2410</div><div class='noteText'>Lick likewise echoed Wiener as he worried about technology’s potential for harm : “ If all the Industrial Revolution accomplished was to turn people into drones in a factory , ” he was sometimes heard to say , “ then what was the point ? ” Indeed , Lick’s entire later career in computers can be seen as a thirty - year exercise in the human use of human beings , an effort to eliminate mind - numbing drudgery so that we could be free to use our full creative powers . Even in the 1940s , moreover , much of Lick’s work as a psychologist still revolved around the notion of the human - machine interface and the question of how to use technology not to replace people but to help them .</h3>
<h2 class='sectionHeading'>Chapter 4:      The freedom to make mistakes</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2550</div><div class='noteText'>approach instead ? 1 Being an MIT man , Forrester was steeped in analog thinking . But once he started looking into digital , stored - program computing — von Neumann’s “ First Draft ” was just then making the rounds — he immediately grasped the advantages for the trainer - analyzer . Rather than trying to hard - wire the system’s behavior with electric circuits , they could abstract the behavior , turn it into a set of algorithmic procedures , and encode it in software , a far more flexible medium . “ We are no longer building an analog computer , ” Forrester informed his team shortly thereafter . “ We are building a digital computer . ” Um , sure , Jay . “ Things were different in those days , ” Everett would recall in his own memoir . “ We didn’t have a big study group , and when Jay decided to build a digital computer , we all thought that was great . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2559</div><div class='noteText'>There they were , a pack of kids with no experience in digital computing , blithely proposing to build a machine of unprecedented speed and reliability . And worse , they were just as blithely proposing to take the technology in a radically new direction . So far , from Babbage’s Analytical Engine in the 1830s through ENIAC in the 1940s , digital computers had always been conceived of as calculating machines . Whatever else they might offer in the way of electronic speed and / or universal programmability , they were still designed to take in data for one specific problem at a time , grind away until they spit out an answer , and then stop and wait for new input . But this digital computer was supposed to act as a flight simulator , a machine for which there was never any “ answer , ” just a constantly changing sequence of pilot actions and simulated aircraft responses .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2573</div><div class='noteText'>In that same year of 1947 , Forrester and Everett wrote a paper describing how such a computer could be used to coordinate the activities of a naval task force , including submarines under the surface , ships on the surface , and aircraft overhead . 3 A year later that notion was reinforced when MIT president Karl Compton , who also happened to be the head of the Pentagon’s R &amp; D board , asked Forrester , Everett , and their team to examine the future of computers in the military . For their report they produced a fifteen - year timetable for real - time computer use in ten application areas , including logistics , antiballistic missile defense , air - traffic control , the coordination of naval task forces — and an air - defense system . Their estimated fifteen - year price tag for the research to create these machines was $ 1 billion ; adding in development and production costs would bring it to an estimated grand total of $ 2 billion .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2678</div><div class='noteText'>Convinced that psychologists should work with the engineers from the very beginning of the design process as opposed to coming in at the end , when it was too late to change anything , Lick had organized the Project Lincoln radar - display group jointly with the engineer Herbert Weiss , with a team membership that was half and half . It did not start out well . “ The engineers never took to it at all , ” says Bert Green , who had been just finishing up his Ph.D . at Princeton when Lick recruited him . Like most technical people of that era ( and many today ) , the engineers tended to view human - factors issues as a fuzzy - minded obsession with trivia such as the shapes of knobs and the colors of dials , things that were a distraction from the serious business of designing hardware . Moreover , it must be said that Lick’s band of greenhorns gave them reason for that view . “ The engineers would come ask , ‘ How bright should this display be ? ’ ” recalls Green . “ Well , we’d all been trained as academic psychologists . So we’d say , ‘ Come back in three months , after we do the experiments . ’ But they wanted the answer right now . ” It was a culture clash that took quite a while to bridge . But Lick was determined that his people do so , said McGill — and in time , they did . Once Project Lincoln started working with real radar signals , for example , the aircraft blips turned out to be surrounded by all kinds of extraneous noise and ground clutter . The engineers knew that they could filter out a lot of that stuff electronically , according to McGill , but the question was , How much ? Filter too little and the radar operator might be confused at a critical moment ; filter too much and a real attacker might be filtered right off the screen . It wasn’t really a technical question : finding the best balance required a deep understanding of human perception and our ability to detect patterns in the midst of chaos .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2744</div><div class='noteText'>Indeed , Lick was already honing the leadership style that he would use to such effect a decade later with the nationwide computer community . Call it rigorous laissez - faire . On the one hand , like his mentor Smitty Stevens , Lick expected his students to work very , very hard ; he had nothing but contempt for laziness and no time to waste on sloppy work or sloppy thinking . Moreover , he insisted that his students master the tools of their craft , whether they be experimental technique or mathematical analysis . On the other hand , Lick almost never told his students what to do in the lab , figuring that it was far better to let them make their own mistakes and find their own way . And imagination , of course , was always welcome ; the point here was to have fun .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2777</div><div class='noteText'>Or Elkind : “ Lick was very warm and supportive with his graduate students . I look back in amazement , but when I was getting into the serious part of my thesis work , I’d pop into his house at ten o’clock at night and we’d spend a few hours spreading data over his kitchen table . He was always willing to provide insights , without taking over the project at all — and Louise was most tolerant about these intrusions at every hour of the day and night . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2784</div><div class='noteText'>Or McGill again : “ Rather than having formal colloquia , which is the way departments usually do it , we’d all sit around at someone’s house with beer and pretzels , we’d look at a tough problem , and we’d brainstorm it . In the end , nobody could figure out who was responsible for which ideas . But the wonderful thing about Lick was that he didn’t give a damn . If you wrote a paper using an idea he’d come up with , he’d give it to you ! He much preferred this kind of brainstorming to the task of knocking out a long chapter himself . ” Indeed , McGill added , talking in the 1990s like a man in his seventies who remembered all too clearly what might have been , “ it was a much warmer , more interactive style of doing science than anything I’ve ever experienced since then . I think none of us really understood at the time what a golden moment it was . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2802</div><div class='noteText'>In effect , he said in a 1983 retrospective on the project , the MIT team improvised the whole air - defense system on the fly , “ building and designing and doing everything simultaneously . ” 7 Take communications , for example . The idea was to have computers at the various radar centers automatically exchange data over the existing telephone lines . But when the Lincoln Lab researchers tried it , they found that the digital signals came through the telephone system hopelessly corrupted by noise and frequency shifts . The problem was that the phone lines were analog , designed to carry the electronic equivalent of the human voice . In frustration , the engineers developed a desk - sized box full of vacuum tubes that would take the digital bits on one end , modulate them into something the analog connections could handle , and then fire them down the line . An identical box on the other end would then demodulate the signal and retrieve the bits unscathed . The engineers were able to achieve transmission speeds of up to 1,300 bits per second with the device , which they called a modulator - demodulator — a mouthful that they quickly shortened to “ modem . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2829</div><div class='noteText'>Forrester’s basic insight was that a piece of material magnetized in one direction — say , north — could represent a binary 1 , while a piece magnetized the other way — south — could represent a binary 0 . So he ordered some Deltamax and began to experiment . He found that by shaping the material into a little ring and then running a wire through the hole , he could flip the ring’s magnetization whichever way he wanted by changing the current in the wire . Moreover , he discovered that the magnetization in the ring would stay put until he flipped it again . Encouraged , Forrester took the concept back to the Whirlwind workshops for development . The next step was to make a grid of wires , with each intersection encircled by one of the “ cores , ” as the little magnetic rings came to be called . The idea was that if you energized , say , the third wire down and the fifth wire across , a computer could detect the magnetization of the core at the intersection of those particular wires and , if need be , flip it — that is , the computer could read or write that particular bit of data . What was more , it could read or write to any given intersection just as easily as any other . It was truly “ random access . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2852</div><div class='noteText'>Looking back on it , says Norman Taylor , then the chief engineer of Lincoln Lab’s Division Number 6 , this story is a prime example of why this enormous and half - panicked project worked as well as it did . For whatever reason — the perceived urgency of the task , perhaps , or the good sense of General Shiely and his oversight team — the researchers had remarkable freedom to make decisions without being second - guessed from the top . They simply paid for the Memory Test Computer out of Division 6 ’ s “ advanced research ” budget , which they could dip into for whatever they considered needful — with no committee meetings , no studying the question to death , and nobody’s pointing out a thousand ways they ought to do it differently .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2859</div><div class='noteText'>Just as important , Forrester adds , they also had the freedom to make mistakes and learn from them : project managers wasted very little time on finger - pointing . “ [ Mistakes were ] admitted and fixed rather than evaded or denied , ” he says . Perhaps the most spectacular example was recognized one weekend in the autumn of 1953 , when the Whirlwind staffers finally had to admit to themselves that they would never be able to deliver a computer as reliable as they had promised the air force . They had actually made phenomenal progress</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2892</div><div class='noteText'>That move was another reaction to the Cold War , as it happened . Soon after the Korean conflict broke out , in June 1950 , IBM sent two scientists on a tour of defense contractors , research institutes , and the military services , asking what the company could do to help the defense effort . James Birkenstock , executive assistant to Thomas J . Watson , Jr . , the son and heir apparent of the company’s chairman , and mathematician Cuthbert C . Hurd , head of IBM’s applied - science department , reported back that the answers kept adding up to the same thing : build computers .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2909</div><div class='noteText'>Nevertheless , there was a certain element of patriotism involved here , as quaint as that now seems . Even granting that this was a classic chance for the company to do well by doing good — collaborating with Lincoln Lab , after all , meant getting the first crack at that new technology from Whirlwind — there is little doubt that IBM’s higher - ups felt the same sense of national peril as everyone else . So in the end , as Forrester would note in 1983 , “ IBM management really threw their resources into the program without restraint . ” Indeed , the company actually used its own money to build a factory for the air - defense computers in Kingston , New York — even before the air force had officially signed the contract . IBM likewise committed dozens of its best engineers , setting them up in a former necktie factory on High Street in Poughkeepsie and then allowing them to operate as “ Project High , ” without any of the usual commercial constraints .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2927</div><div class='noteText'>One source of the camaraderie may well have been a shared sense of awe at what they were trying to accomplish . The Semi - Automated Ground Environment , or SAGE , as the overall air - defense architecture came to be known , was immense even in its preliminary version , which was formulated in 1954 . And it only got bigger as Lincoln and IBM filled in the details . The plans called for twenty - two “ direction centers ” in the United States and a twenty - third at North Bay , Ontario , each housed in a windowless , concrete , and hopefully atomic - bomb - proof fortress that would loom over its surroundings like some grim , modern version of the Great Pyramid .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2944</div><div class='noteText'>“ I didn’t know what hand grenade someone was going to roll out on the table , ” he said , “ but I knew there was going to be one . ” The only blessing , he added , was that the big problems tended to come one at a time instead of all at once , so that they had a chance to grapple with each crisis in turn before the next one came along to overwhelm them . Take software , for example . Lincoln Lab’s initial guess for the programming requirements on SAGE — that it would require perhaps a few thousand lines of computer code to run the entire air - defense system — was turning out to be the most laughable underestimate of the whole project .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2949</div><div class='noteText'>Many computer engineers still regarded programming as an afterthought : what could be so hard about writing down a logical sequence of commands ? Nonetheless , the Lincoln Lab programmers were being asked to create what would now be called a real - time operating system for the most complex computer / communications system in the world , and they had no modern tools to help them — no Fortran , no Cobol , no Algol ; no computer languages , period . All they had was the most basic , hardware - level computerese , alphanumeric codes that corresponded to operations like “ Add the contents of register A to the contents of register B and place the results in register C . ” Anyone who tried to program with such codes quickly discovered that it was terribly easy to make mistakes in even the simplest algorithms . And the SAGE system was anything but simple .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2962</div><div class='noteText'>Second , in the early 1950s there probably were no more than a few thousand programmers in the whole country . So the SAGE project soon found itself in the business of mass education . Special programming courses were set up at MIT , IBM , and RAND , and people from every walk of life were invited to enroll . The trainers quickly discovered that it was impossible to predict who their best pupils would be — not even professional mathematicians were a sure bet ; they often lost patience with the details — but it was very easy to spot the talented ones once they got started . As a general rule of thumb , for example , music teachers proved to be particularly adept . And much to the project leaders ’ astonishment ( this being the 1950s ) women often turned out to be more proficient than men at worrying about the details while simultaneously keeping the big picture in mind . One of the project’s best programming groups was 80 percent female .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 2976</div><div class='noteText'>Of course , it’s hard to say how effective the SAGE system really was in military terms , since it was ( fortunately ) never used in combat . Arguably , in fact , the SAGE system was obsolete almost from the day it was commissioned , since by that point the United States and the Soviet Union were hard at work on intercontinental ballistic missiles that could deliver a nuclear warhead across the North Pole in under an hour . But in hindsight there is no uncertainty whatsoever about the project’s enormous impact on the history of computing . First , it helped catalyze the formation of the Silicon Valley of the East . In the summer of 1953 , Lincoln Laboratory moved from the MIT campus into a shiny new complex in suburban Lexington , Massachusetts , not too far from a major ring road around Boston , Route 128 . In July 1958 , when SAGE was about to come on line and it was time to start integrating new jet fighters and missiles into the system , Lincoln Lab spun off its Division Number 6 as a whole new independent consulting firm just to deal with that task , renaming it the MITRE Corporation . And so it went .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3004</div><div class='noteText'>Finally — and in the long run , perhaps most significantly — SAGE planted the seeds of a truly powerful idea , the notion that humans and computers working together could be far more effective than either working separately . Of course , SAGE by itself didn’t get us all the way to the modern idea of personal computers ’ being used for personal empowerment ; the SAGE computers were definitely not “ personal , ” and the controllers could use them only for that one , tightly constrained task of air defense . Nonetheless , it’s no coincidence that the basic setup still seems so eerily familiar . An operator watching his CRT display screen , giving commands to a computer via a keyboard and a handheld light gun , and sending data to other computers via a digital communications link : SAGE may not have been the technological ancestor of the modern PC , mouse , and network , but it was definitely their conceptual and spiritual ancestor .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3024</div><div class='noteText'>So , yes : as a set of concepts , the cybernetics movement is still very much alive , and we are all members . We hear the voices of Wiener , Shannon , Turing , von Neumann , McCulloch , and Pitts from every side . But as a single , unified new science that encompasses both “ the animal and the machine ” ? No . That dream of unity was already failing by the early 1950s , when Norbert Wiener’s supper seminars and the Macy meetings both came to an end . And by mid - decade , with the movement increasingly left to third - raters and crackpots , it was effectively dead .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3030</div><div class='noteText'>After all , noted Bill McGill , “ these man - machine ideas didn’t seem so important when you were talking about the annihilation of the human race . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3198</div><div class='noteText'>as these young researchers applied the theory to more and more aspects of human perception , they found more and more evidence for the same kind of “ channel capacity ” that Miller had found in the perception of words . Their experimental subjects could distinguish very well between different musical pitches , say , or different positions of points on a line , or even different levels of saltiness in a taste of water — if there were only two alternatives . Salty — not salty and so on were really just yes - no choices , meaning that the subjects had to perceive only one bit of information . But as the number of alternatives increased , the subjects inevitably began to falter and make mistakes at the level of roughly seven choices , or slightly less than three bits of information . ¶</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3204</div><div class='noteText'>The clear implication was that perception didn’t just happen , as the behaviorists would have it . Perception was a real physical process with capacities and limits , in precisely the same way a telephone line had limits . Why this limit should be seven alternatives as opposed to , say , three , or nineteen , was a mystery ( and still is ) . But the number turned up so consistently that in 1956 , when Miller reviewed the evidence for human information - processing limits , he would entitle his article “ The Magical Number Seven , Plus or Minus Two ” — and begin it with one of the most memorable laments in the scientific literature : “ My problem is that I have been persecuted by an integer . For seven years this number has followed me around , has intruded in my most private data , and has assaulted me from the pages of our most public journals . . . . There is , to quote a famous senator [ the rabidly anti - Communist Joseph McCarthy ] , a design behind [ the persistence of this number ] , some pattern governing its appearances . ” 20</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3225</div><div class='noteText'>“ So information wasn’t a constant in memory , ” says Miller . “ Instead , we cooked up this notion that the amount of information you can hold is measured in ‘ chunks , ’ ” or meaningful clusters of items that you can remember as units . That’s why sentences are easier to remember than words listed at random : you can remember them as phrases , or chunks of meaning . And it’s why a twelve - digit sequence such as 149217761066 is very difficult to remember until you see it as three famous dates — 1492 + 1776 + 1066 — at which point it suddenly becomes trivial . In short , says Miller , “ the scare ” led to an even deeper confirmation of the phenomenon : the magical number was 7 , all right , but seven chunks , not just seven items . Moreover , he says , this recognition of chunking was what finally led him to make an open break with Skinner and company . Not only did the data prove the existence of mental states — namely , concepts in memory — but they showed that these mental states have structure .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3246</div><div class='noteText'>Chomsky , it turned out , had been staging his own revolt against behaviorism , and doing so with all the intellectual ferocity that he would later make famous . Brilliant , intense , and blessed with extraordinary abilities in mathematics and symbolic logic , the twenty - eight - year - old Philadelphia native was a near unknown in 1956 . But even then he relished the chance to take on conventional wisdom and demolish it . In this particular case , Chomsky was arguing that the behaviorist account of human language wasn’t just wrong , it was ludicrous . Moreover , he could prove that assertion mathematically . In truth , language had always been the ultimate hurdle for behaviorism . How could you avoid talking about “ mental states ” such as ideas , images , feelings , and intentions when the whole point of language was to communicate those states ? The behaviorist answer — naturally — was that such apparent mental states were illusory . We produced certain sequences of words only because we’d learned associations between individual words : John had a certain probability of being followed by kissed , which had a certain probability of being followed by Mary , and so on . Thus John kissed Mary . Indeed , B . F . Skinner himself was just finishing up a major book on the subject and had declared that a behaviorist account of language would be the culmination of his life’s work .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3283</div><div class='noteText'>To put it another way , the very fact that we human beings use language in the way we do is proof that , in some sense , our brains have the computational power of a Turing machine . Or to express it still another way , the pinnacle of all possible mathematical machines — the Turing machine — is also the baseline , the minimum needed for human cognition . Anybody who seriously wants to understand the workings of the mind had better start from there , because nothing less will do .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3287</div><div class='noteText'>Today , of course , Chomsky’s proof that computational machines form a hierarchy is considered a major refinement of Turing’s original insight , and one of the foundation stones of modern computer science . But to Chomsky himself that was just a pleasant side effect . His own goal was to overturn a linguistics establishment that he regarded as stuffy and unimaginative . And he did : starting in 1957 , when some of his lecture notes were published as the book Syntactic Structures , his notions of transformational grammar and mathematical linguistics swept the field , to the point where Chomsky himself would soon become the new establishment . Along the way , moreover , he also did a great deal to help undermine behaviorism . When Skinner’s book on language came out in that same year of 1957 , for example , Chomsky wrote a review that turned out to be more influential than the book itself , pointing out the inadequacies of Skinner’s account in withering detail .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3321</div><div class='noteText'>Simon had been captivated by Newell’s computer setup the first time he saw it . “ What was remarkable about this application , ” he would later write , “ was that the computer was being used not to generate numbers , but locations — points — on a two - dimensional map . Computers , then , were not merely number - crunchers ; they were general symbol manipulators , capable of processing symbols of any kind — numerical or not ! ” Newell , conversely , had already begun to notice some striking similarities between Simon’s specialty — the way humans organized their work in the center — and the way data were processed in his computers : both activities had a critical dependence on information flow , and on how that information was used to make decisions .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3344</div><div class='noteText'>Our “ bounded rationality , ” as he put it in Administrative Behavior , constrains and shapes everything we do . When you go out shopping for , say , a new pair of shoes , do you systematically visit every shoe store in town to find the lowest possible price ? Probably not ; the savings just aren’t worth it . The majority of us simply visit one or two convenient stores and settle for the most satisfactory buy we can find . Simon coined a new word for this kind of behavior — satisficing — and suggested that it was ubiquitous in human decision making , even at the highest levels of government and business . Indeed , this is why very smart people will sometimes arrive at disastrously wrong decisions ( for a later generation , the Vietnam war comes to mind ) . But trying to avoid every conceivable error is a recipe for paralysis : having the freedom to make mistakes is necessary for achieving any progress at all .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3356</div><div class='noteText'>Bounded rationality was a negative definition , he knew . It told us what human behavior is not — namely , perfectly rational — but not what human behavior is . If you really want to understand what people do , Simon reasoned , you need a language you can use to formulate rigorous theories about behavior , in much the same way Galileo and Newton used mathematics to analyze the motion of physical objects . Obviously , mathematics itself wasn’t the right language for this application : people are far too complicated to be described by mathematical variables ( Let X = motivation ? ) . But as for what to put in its place , well , that was the significance of the computer program that Simon and Newell called the Logic Theory Machine , or Logic Theorist . They hadn’t created it to prove that a computer could “ think ” ( though it would later be hailed as one of the first and most influential examples of artificial intelligence ) ; rather , they had created it to show that the proper analytical language for describing human thought and human behavior was computation .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3364</div><div class='noteText'>As the name indicated , Newell and Simon’s program proved theorems in symbolic logic , a task they chose partly because the material was ready at hand — Simon happened to have in his home library a copy of Principia Mathematica , Bertrand Russell and Alfred North Whitehead’s classic treatise on logic and the foundations of mathematics — but mostly because it seemed to be such a perfect model of bounded rationality in general .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3376</div><div class='noteText'>Imagine for a moment that you wanted Logic Theorist to prove its theorems by brute force . The method sounds easy enough : just start from the given premises and have the program systematically apply every inference rule until the correct solution is found . And in fact , that approach is guaranteed to produce the theorem — eventually . It’s an example of what is known in the trade as an algorithm , a well - defined procedure that takes you step by step from the input data to the final answer . ( The classic analogy is a cookbook recipe : take so many cups of this and so many tablespoons of that , mix it all together , shake it , bake it , and voilà ! ) Algorithms , of course , are usually seen as the essence of computation . The whole point of a computer is to execute such step - by - step procedures very , very fast — which is precisely why the machines are so useful for grinding out scientific calculations , generating corporate payrolls , and doing anything else that can be formulated as an algorithm .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3390</div><div class='noteText'>This “ combinatoric explosion ” of insanely multiplying possibilities was what threw logic - theorem proving into the realm of what Newell and Simon called complex information processing . There were any number of alternatives that you could choose at every step , but there was no practical way to anticipate what you should choose until you got there : the proper choice depended on context and on all the choices that had been made up until that point . Moreover , the two men pointed out , this same explosion crops up everywhere , not just in logic but in games such as chess and in everyday life . As an illustration , try calculating how many conceivable outfits you could put on tomorrow morning , counting every possible combination of shirts , slacks , belts , underwear , socks , and so forth that you own . It doesn’t take a very big closet to generate a number in the billions . So here’s the problem in a nutshell : how does anyone even manage to get dressed in the morning ? The answer — which is also the key to understanding our human mode of boundedly rational problem solving — is that we don’t go through all our billion - plus options one by one . Instead , we half consciously apply Simon’s “ satisficing ” strategy , thinking things like Those two look good together , or Do these shoes match ? or I can’t wear that to work ! And very quickly , using a few rules of thumb , we whittle the choices down to something manageable .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3426</div><div class='noteText'>On December 15 , 1955 , I simulated by hand a proof of Theorem 2.15 of Principia in such detail that we agreed the scheme was programmable . I have always celebrated that day as the birthday of heuristic problem - solving by computer . ” 23 Newell recalled their elation : “ Kind of crude , but it works , boy , does it work . ” 24 A few weeks later , when classes had resumed after Christmas break , Simon greeted the students in his course “ Mathematical Models for the Social Sciences ” by announcing , “ Over Christmas Allen Newell and I invented a thinking machine . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3446</div><div class='noteText'>The notion that there were rules that could generate behavior , that behavior wasn’t just the accumulation of reinforced responses — this was a thread that ran through all of the presentations . ” Once again , says Miller , these ideas had a freeing effect , just as the whole cybernetics movement had a decade earlier . After Wiener , Rosenblueth , and Bigelow , we could begin to understand how an ordinary physical mechanism could embody a mental state — purpose — through the simple mechanism of feedback . Purpose wasn’t a kind of stuff , it was a kind of organization</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3462</div><div class='noteText'>Indeed , Miller has always looked back on that Tuesday morning in 1956 as the real birthday of cognitive science . He remembers walking out of that meeting like a man transformed . He had found his mission : the computational , information - processing view of human cognition would guide his career from that day forward . In 1958 , for example , he joined with Simon and the psychologist Carl Hovland to organize a summer school on computer simulation at RAND , where he himself spent much of the session learning the basics of computation from Newell . The experience soon paid off .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3466</div><div class='noteText'>“ The next year I spent at the Stanford Center for Advanced Study in the Behavioral Sciences , ” Miller recalls , “ and Eugene Galanter and Karl Pribram were there . And I’d come along with all this material from this summer seminar . We began meeting together , and our discussions got rather interesting , so we decided we should record them ; and the first thing we knew we’d written a book . ” 25 In that book , published in 1960 as Plans and the Structure of Behavior , Miller and his coauthors started from the antibehaviorist ( but commonsense ) notion that all behavior arises from internal plans . Then they went on to provide a general model for such plans using cybernetic feedback , in a form that was strongly reminiscent of Newell and Simon’s heuristic search model and that a programmer would instantly recognize as a loop : TEST ( Has the goal been achieved ? If not , OPERATE . ) OPERATE ( Take steps to reach the goal . ) TEST ( Has the goal been achieved ? If so , EXIT . If not , OPERATE again . ) EXIT ( We’re there . )</h3>
<h2 class='sectionHeading'> Chapter 5:      The tale of the fig tree and the wasp</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3557</div><div class='noteText'>Interactive . Exciting . Fun . That wasn’t how most people thought about computers , not in 1956 . Within the industry , noted Kenneth Olsen , who was then one of the leaders of Lincoln Lab’s advanced computing group , the concept of having fun with a computer was , well , strange . “ Some people thought it was wrong , ” Olsen later told an interviewer . “ They almost spoke in ethical terms . Computers are serious , you shouldn’t treat them lightly . You shouldn’t have fun with them . They shouldn’t be exciting . They should be formal and distant with red tape involved . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3571</div><div class='noteText'>Then , too , this perception of bigness and remoteness was a reflection of engineering reality : from the start of modern computing in the 1940s , all the way through the 1950s , the prevailing vacuum - tube technology had meant that the machines had to be big and expensive . According to “ Grosch’s law , ” a bit of industry lore first formulated by IBM executive Herbert Grosch in the late 1940s , spending twice the money would get you roughly four times the processing power — which meant that customers could always get much more bang for their buck by buying the biggest machines they could afford . So that was what they did . On a day - to - day basis , however , what most powerfully reinforced the standard perception of computers was batch processing , an assembly - line style of operation inherited from the punch - card - tabulator era . In batch processing , the users weren’t allowed anywhere near the machine ; instead , they were supposed to hand in their decks of IBM punch cards to the computer - room technicians , who would run a group of jobs through the computer as a “ batch ” for efficiency’s sake and then deliver the resulting stacks of fan - fold printout a few hours later . Or maybe eight hours , twelve hours , or even twenty - four hours later . And if the only result was an error message about a comma that had been omitted on card 43 — well , next time be more careful .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3590</div><div class='noteText'>It was an inspiration born of luck , recalls Clark , who joined the Whirlwind project as a programmer in 1952 . Most members of his group had been around MIT long enough to remember what life had been like before SAGE really got going — before Whirlwind , the Memory Test Computer , and every other machine in sight had been totally monopolized by national security . Back in those days , says Clark , Whirlwind had actually functioned as a very large personal computer , complete with an interactive display screen . “ What now sits comfortably on a small desktop , in those days required an entire room for the control [ console ] alone , ” he wrote in a memoir . “ But its early users did indeed walk into the control room and , for their assigned block of time , typically fifteen minutes or so depending on the time of day , the entire machine was theirs . ” 2 For that whole glorious fifteen minutes they could play around , type in commands , try things out , see what happened , get new ideas and try those out — all the things we now take for granted . But then it was an experience unique in all the world .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3611</div><div class='noteText'>people paying the bills wanted to see their million - dollar IBMs and UNIVACs crunching numbers every possible second ; they weren’t about to let you play around with one of their machines just to see what happened . So if interactive computing was ever going to be anything more than a laboratory pastime , the group realized , computers were going to have to become a lot smaller , faster , and cheaper . And the only way to ensure that was to replace those big , power - hungry vacuum tubes with transistors . The problem , of course , was that transistor technology was still on the cutting edge in 1955 , which was why industry engineers generally preferred to stick with the proven , reliable , and familiar vacuum - tube technology . “ The commercial world just smiled at us and said we were ‘ academic , ’ ” recalls Olsen , who was not a man to take such condescension lightly . So there was nothing for it but to build a fully transistorized computer themselves , just to show it could be done .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3636</div><div class='noteText'>Indeed , Olsen was proving to be a born showman . “ We’d discovered with the MTC that blah - looking computers never really attracted attention , ” he says . “ So we made the TX - 0 as modern a design as we could . Now it looks quite naive . But it had rakish lines like a race car . And we picked a color [ that was ] just the opposite of the traditional black wrinkle finish , which was World War II . It looked so military and blah . So we picked brown and beige , which seemed like a dramatic change . Then we set the computer back from the door for good pictures and to show it off with a little bit of flair . The result was [ that ] when the head of Lincoln Laboratory had visitors , he of course brought them to our laboratory . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3665</div><div class='noteText'>By and by , however , he and Anderson heard about the American Research and Development Corporation , one of the nation’s first venture - capital firms . “ So we went to see them , ” recounts Olsen . “ It turned out that they were worried , too , because some of their investments hadn’t paid off very well . But the staff was fascinated enough to listen to our proposal . Then they told us we could go present it to their board of directors and see what happened — but gave us three bits of advice before we went . One was , Don’t use the word computer in the proposal , because Fortune magazine said that no one was making money in computers and no one was about to . So we took it out . ” Instead , Olsen and Anderson promised not to market a computer until they were making a profit by selling modular , transistor - based circuit boards — which would be the components of the computer in any case . The second bit of advice was “ Don’t promise five percent profit . ” That was about average for a well - run company in those days , says Olsen . “ But the staff said that if you’re asking someone to give you money , you’ve got to promise better results than that . So we promised ten percent . Then the third thing they said was , ‘ Most of the board is over eighty [ years old ] , so promise fast results . ’ So we promised to make a profit in a year . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3675</div><div class='noteText'>Olsen and Anderson gave their pitch on May 27 , 1957 , and apparently made a good impression : the ARDC board decided that they were worth a risk of seventy thousand dollars . It was enough to give them a chance . That July , after a long search for affordable space , the two men found what they were looking for in a renovated nineteenth - century mill out in rural Maynard , Massachusetts , where military blankets and uniforms had been manufactured during the Civil War . The second floor of Building 12 , containing precisely 8,680 square feet , rented for only three hundred dollars per month . Olsen and Anderson took it . And on August 27 , 1957 , having settled on a name that said “ computer ” without actually saying “ computer , ” Olsen , Anderson , and Olsen’s brother Stanley opened for business as DEC , the Digital Equipment Corporation .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3688</div><div class='noteText'>Lick , for his part , was captivated by Clark’s ideas on interactive computing . True , the concept wasn’t completely new to him : Lick had been working with Whirlwind and its successors ever since he joined Project Lincoln , and he’d long since turned the basement of the Sloan Building into his personal toy shop of analog machines . But sitting at the console of a digital computer that he could program and reprogram all by himself without changing a single wire , watching its responses appear instantly on the display screen , having all that power under his own two hands — now that was something . Lick was instantly bursting with ideas for using such a computer in the laboratory : he could run his experiments automatically , process his data in a flash , reprogram whole new experiments with a few taps on the keyboard . All his life he had been longing for a magical device that would let him implement ideas as fast as he could think of them . Now he’d found it .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3695</div><div class='noteText'>But even more compelling was the sense of freedom and autonomy he felt at the console . The TX - 2 was the first digital computer Lick had ever seen that didn’t just execute a preplanned algorithm ; instead , it invited him in and helped him to create new programs of his own . It was likewise the first computer he’d ever seen that didn’t just serve the needs of some large institution ; it was a personal computer , serving the needs of his own imagination . The TX - 2 put him in charge . Using it , Lick later wrote , “ [ was ] like sitting at the controls of a 707 jet aircraft after having been merely an airline passenger for years . ” 5</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3701</div><div class='noteText'>Lick’s encounter with the TX - 2 began to spark an idea . Unfortunately , there is no way to reconstruct his exact train of thought in this period , assuming he could even follow it himself . But it’s clear that at some point he began to reflect on a curious dichotomy . When it came to things that computers did well , Lick realized , thinking of rote , algorithmic tasks such as arithmetic and data sorting , humans were pathetically slow and mistake - prone . Most of us could be beaten several times over by the simplest desktop calculator . And no wonder : all our mental processing had to be done through laborious , conscious deliberation , using biological information processors that could execute no more than a few operations per second and handle only about seven chunks of data at a time . And yet , Lick further reasoned , when it came to things that computers did poorly or not at all — intuitive processes such as perception , goal setting , judgment , insight , and all the rest — our human capabilities surpassed the most powerful machines on the planet ( and still do ) . Having spent much of his career trying to untangle the relatively straightforward mechanisms of hearing , Lick could testify to that point personally : these “ heuristic ” mental functions , as he called them , actually involved a vast amount of information processing . They seemed effortless and intuitive only because that processing was carried out deep within the brain , by massively parallel networks of neurons operating well below the level of consciousness . It was ( and is ) a deep mystery why our conscious and unconscious mental functions should behave so differently . But there it was : the human - computer complementarity was almost perfect . So , Lick wondered , what would happen if you put humans and computers together as a system ? What would happen if you let the machines take over all those dreary , algorithmic chores they were so good at ? How much of your time would be opened up for real creativity ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3717</div><div class='noteText'>“ In the spring and summer of 1957 , ” he wrote a few years later , “ I tried to keep track of what one moderately technical person actually did during the hours he regarded as devoted to work . Although I was aware of the inadequacy of the sampling , I served as my own subject . . . . I obtained a picture of my activities that gave me pause . Perhaps my spectrum is not typical — I hope it is not , but I fear it is . About 85 per cent of my ‘ thinking ’ time was spent getting into a position to think , to make a decision , to learn something I needed to know . . . . [ These getting - into - position activities ] were essentially clerical or mechanical : searching , calculating , plotting , transforming , determining the logical or dynamic consequences of a set of assumptions or hypotheses , preparing the way for a decision or an insight . Moreover , my choices of what to attempt and what not to attempt were determined to an embarrassingly great extent by considerations of clerical feasibility , not intellectual capability . ” 6 Eighty - five percent ! ? That figure did more than give Lick pause . It seems to have hit him with the force of a religious epiphany : our minds were slaves to mundane detail , and computers would be our salvation . We and they were destined to unite in an almost mystical partnership : thinking together , sharing , dividing the load . Each half would be preeminent in its own sphere — rote algorithms for computers , creative heuristics for humans . But together we would become a greater whole , a symbiosis , a man - machine partnership unique in the history of the world : “ The hope is that , in not too many years , human brains and computing machines will be coupled together very tightly , and that the resulting partnership will think as no human brain has ever thought and process data in a way not approached by the information - handling machines we know today . ” 7</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3738</div><div class='noteText'>This is the part that still has Lick’s colleagues from the psychology years shaking their heads in bewilderment . Frustration with MIT ? Sure — who wouldn’t be frustrated with Dean Burchard ? But to give up a career he’d spent twenty years building , right at the moment when cognitive psychology was taking off ? To give up tenure ? For computers ? It was beyond belief . Yet that was exactly what he did . Not immediately ; nobody can completely redesign his life overnight . Lick would retain a lively interest in acoustics research well into the 1960s . Nonetheless , it was around this time that Louise Licklider began to notice the word computer cropping up more and more often in their late - evening mutual core dumps . It was likewise around this time that her husband’s associates began to note a certain evangelism on Lick’s part . “ I was computer - resistant , ” said Bill McGill , who wouldn’t become a convert until many years later . “ And Lick used to lecture me by the hour about the error of my ways ! ” He could be heard to say things like , “ Any psychologist is crazy to keep on working with people if he has access to a computer ! ” And it wasn’t entirely clear that he was joking . 8 Before very long , Lick’s fellow psychologists began to feel , well , not rejected , exactly , but aware somehow that he was inexorably drifting away . “ I saw him a couple of times after I went back to Harvard , ” says George Miller . “ But his interests were already elsewhere . The things that we had once talked about with enthusiasm , he was just vaguely interested in . ” Once again , it would be only a matter of time : Lick was ready for a change . And once again , change — in the person of Leo Beranek — came looking for him .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3782</div><div class='noteText'>The history of computing might have been very different if he had , says Beranek — not to mention the history of BBN . But as it was , the two men agreed that this decision would have to be a joint one , made with Louise Licklider . So the three of them met on the Santa Monica beach the next day , Sunday , August 12 . “ One of us brought a blanket from the hotel , and we brought some chips and soft drinks , ” says Beranek . “ I would say we talked for about two hours on the beach . My strategy was to convince Louise that she was so well liked in Cambridge and that her amateur drama activities at MIT were so successful that they should seriously consider staying there . My offer to Lick was that he would be vice president in charge of all psycho - acoustics research at BBN , and that we would offer him a liberal stock option at a greatly undervalued basis of a dollar fifty per share ” ( BBN would go public in 1961 at $ 12 per share ) . Beranek has no idea which argument was more persuasive , “ but by golly , a week or two later , Lick said he would come . ” Lick’s last official day at MIT was June 30 , 1957 .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3818</div><div class='noteText'>Four decades later , Leo Beranek can testify that J . C . R . Licklider was a very persuasive man . “ I consulted with my executive vice president and our treasurer , and we agreed , ” he says . “ So we bought him the computer . He didn’t use it very efficiently , as it turned out ; basically , he just wanted it so he could learn how to program . ” Well , yes , that was basically true . But then , the machine had come fully equipped with a teacher : Edward Fredkin , an arrogant , abrasive , insubordinate , and totally brilliant young man who had dropped out of college to fly fighter jets for the air force — and who had then decided to find himself some real excitement by programming computers . “ I had been part of the air force team that went up to Lincoln Lab to test the SAGE system , ” recalls Fredkin , who has mellowed considerably in the decades since then . “ But we discovered that SAGE was going to be a year late , so the air force just decided to assign me to Lincoln Lab . One day this guy came in and said , ‘ Hi , Lieutenant , I’m supposed to interface with you . ’ He described the most mundane things that I was supposed to do : make sure the reports came in , that sort of stuff . I said , ‘ That’s totally inappropriate . ’ So he went away , and nobody else ever told me anything to do . So I worked very hard doing whatever I wanted . I taught all kinds of people to program . When Sputnik went up , I wrote programs to calculate orbits . It was a wonderful environment . And after I got out of the air force [ in July 1958 ] , I just continued there . I didn’t have a degree , so they didn’t have any slot for me except ‘ clerk . ’ But I said , ‘ I don’t care what you call me , I just want to keep on doing what I’ve been doing . ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3858</div><div class='noteText'>Disappointing though the LGP - 30 may have been , however , it was the first computer that Lick ever sat at for hours on end . It helped him clarify in his own mind what a human - computer partnership might actually entail . And it seems to have confirmed him in his instinct that this partnership would require a fundamental shift in the direction of computer technology . Instead of simply making the machines bigger and faster , which was what IBM and the other big manufacturers were constantly trying to do , the industry would somehow have to start making them more intuitive , easier to program , easier to understand , and easier to communicate with — in short , more closely adapted to the workings of the human mind .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3876</div><div class='noteText'>Still more daunting , however , was the fact that DEC’s vision of interactive computing now lay even further outside the mainstream than when they’d started . IBM , UNIVAC , the new Control Data Corporation up in Minneapolis — by 1959 , everybody was committed to batch processing . But DEC went ahead anyway . Ted Johnson , who had been hired the year before as the company’s first and only salesman , remembered being in Olsen’s office one day in April 1959 when a letter came in from a naval laboratory in California . It was a formal request for a quotation on a new computer . “ When Ken opened the letter , ” said Johnson , “ his face lit up , and he said , ‘ That’s the machine I had in mind ! Go sell a computer ! ’ ” 10 Of course , that did require having a computer to sell . To create one , Olsen and Anderson hired the best engineer they knew : Lincoln Lab’s Ben Gurley , who had worked with them on the Memory Test Computer and the TX - 0 and had completed the construction of the TX - 2 after they left . And that , in turn , proved to be one of the best moves in DEC’s early history . In what Ed Fredkin would later call a tour de force of computer design , Gurley had the new machine ready to go in just three and a half months . True , it was only a smaller prototype version of the computer specified in the navy’s letter , which never did get built . But it worked beautifully . “ Ben Gurley , perhaps better than any other engineer of his time , had the right combination of technical brilliance and engineering conservatism to bring these ideas into reality , ” noted Fredkin , who later came to know Gurley well . “ When he drew something on paper , it worked exactly as drawn . There were no bugs in his logic . ” 11</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3914</div><div class='noteText'>Today it would be called a beta test of a new machine , says Beranek , with Lick and Fredkin the main testers . Lick was ecstatic . “ [ Now ] that was a serious computer , ” he said in his 1988 interview ; his main suggestion was that the PDP - 1 should have a “ thin skin ” so that experimenters could get inside it . And Fredkin was in his element , critiquing the design , tinkering with the machine , and offering endless suggestions for improvements . “ The PDP - 1 was revolutionary , ” Fredkin declares , still marveling four decades later . “ Today such things don’t happen . Today a machine comes along and is slightly faster than its competitors . But here was a machine that was off the charts . Its price performance was spectacularly better than anything that had come before . Compared to the LGP - 30 , it cost a little more than twice as much but was more than a thousand times faster . Or to put it another way , it was as fast as a computer that cost a hundred times as much . There had never before been a machine that was this much in front of the competition . And never since . It was a singular event . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3932</div><div class='noteText'>“ We kept that thing running day and night , ” Lick agreed in his 1988 interview . “ Everybody connected with it just sat at the console and did on - line interactive programming — and since I was one of the first ones to be involved , I got most of the time ! ” Indeed , the forty - five - year - old Lick was happily transforming himself into what would now be called a hacker . Every evening after having dinner with his family , he would be back at the console writing programs interactively . “ He would spend all night developing a program and never even save it ! ” marvels Karl Kryter , who watched any number of his friend’s efforts disappear into the midnight ether . By some standards , it’s true , very few of those efforts were worth saving : “ It was like Norbert Wiener’s trying to be a chess player , ” says Fredkin . “ Lick always had better ideas than anyone , but rotten execution . ” But who cared ? Lick was playing with the PDP - 1 , kicking it around , seeing what it could do . “ We were living out there in the future , ” says Fredkin . “ And Lick was one of the few people with the vision to understand . ” Early on , for example , Lick wrote some of the world’s first educational software , using Tracy and Linda Licklider as willing guinea pigs . “ In a small and preliminary way , ” he explained in 1961 , “ with only a small computer , a computer typewriter , and a few nights of programming , some of us have already created ‘ motivational traps ’ for our children , and we are sure that a computer teaching machine can be made more attractive than television . The youngsters love real - time interaction with a thing like a computer . It can tell them immediately , ‘ No , that was wrong ’ ; it can calculate and post a score as it goes along ; with the aid of a simple random process , it can look up in a table a suitable compliment or a suitable sarcastic remark such as ‘ Oh , oh , you’re slipping . ’ The youngsters will sit there and punch the keys for hours learning spelling and language vocabulary . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3947</div><div class='noteText'>In the future , Lick added prophetically , “ any student from grade school through graduate school who doesn’t get two hours a day at the console will be considered intellectually deprived — and will not like it . ” 12</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3967</div><div class='noteText'>But the other one — well , there was something about the wild shock of hair and the maniacal , fixated stare that gave him the look of a nineteenth - century anarchist getting ready to throw a bomb . This , Beranek sensed , was not just another consultant . “ Excuse me , ” he asked the two younger men . “ Who are you ? ” The second stranger looked him up and down with those disturbingly direct eyes . “ Who are you ? ” “ And that , ” says Beranek with a laugh , “ is how I met John McCarthy ! ” Beranek was right : John McCarthy was not just another consultant . At age thirty - three , this aloof , wild - eyed mathematician was already among the most innovative individuals in the short history of computing . In the process of achieving that stature , moreover , he had single - handedly reinvented the whole concept of interactive computing — albeit in his own highly idiosyncratic way . He was the founder of artificial intelligence , which for him meant ( among other things ) a computer that could respond to you in real time , with humanlike common sense . He was likewise the creator of Lisp , an interactive symbol - processing programming language that not only had a compelling mathematical beauty but would let you grow your programs in a much more open - ended , organic manner than batch processing ever could . And he was the inventor of general - purpose computer “ time - sharing , ” a technique that let individual users interact with batch - processing behemoths in a way that looked very much like present - day personal computing</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 3992</div><div class='noteText'>“ I had certain standards of mathematical precision for what a scientific paper ought to be like , ” he explained in an interview conducted by the writer Pamela McCorduck in 1974 , adding that by “ precision ” he meant mathematical abstraction , formal definitions , powerful theorems , and rigorous proofs . “ But finally it became clear that I wasn’t going to solve the artificial intelligence problem in a mathematically rigorous way in reasonable time , so I simply decided to start publishing what I had . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4054</div><div class='noteText'>Lasting through most of the summer of 1956 , the Dartmouth conference has subsequently become famous as the event that finally established artificial intelligence as a field in its own right and gave it the name that has stuck . Characteristically , however , McCarthy once again felt disappointed . “ I simply measured the distance between what I had hoped to accomplish and what we did accomplish , and it was pretty large , ” he says . He had hoped to see von Neumann there , but the great mathematician already lay dying . Of the ten people who did attend , few stayed for the full six weeks , and almost no one altered his thinking because of anything he learned there . Worse , only two participants had impressive new results to report — Newell and Simon came to Dartmouth bearing printouts from the preliminary runs of Logic Theorist — and they had a noticeable chip on their shoulder . “ They didn’t stay very long , ” says McCarthy , “ and they had a tendency to feel , perhaps quite correctly , that the conference was being run by people who hadn’t actually done anything . ” Besides , neither Newell nor Simon liked the term “ artificial intelligence ” ; the two would continue to use their own phrase , “ complex information processing , ” for years afterward .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4081</div><div class='noteText'>If you inputted a question , it should at least take a shot at passing the Turing test , and give you an answer . And it should do so now , not six hours from now , with the answer buried somewhere in a stack of fan - fold printout . This last was a point that McCarthy could speak to with some feeling , especially after 1955 and his summer at IBM’s Poughkeepsie lab , when he’d been traumatized by his introduction to programming via batch processing . Those bureaucrats wanted him to wait for the computer ? They considered his time to be less valuable than the computer’s ? Not hardly . Quite aside from any concerns about machine intelligence , McCarthy felt , a truly responsive computer would tell you about those damned missing commas right away , so you could fix them and keep going without breaking your train of thought . Nor would it force you to think through every detail of your programming code beforehand , as a batch - processing operation tacitly expected . That was fine for fields such as physics or data processing , where the equations were already in the textbooks and the only real problem was converting them into bug - free algorithms . But it was a disaster in an arena such as artificial intelligence , where there were no textbooks and you had to grope your way toward the solution every step of the way . What you needed in that case was a programming language and a computer system that would let you explore , try things out , see what happened , and learn . In effect — though McCarthy certainly wouldn’t have said it this way — what you needed was a system that would help you carry out Newell - and - Simon - style heuristic search . And most especially , what you needed was interactivity day or night , at work or at home , anytime you had an idea , anytime you wanted .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4101</div><div class='noteText'>McCarthy has always maintained that the idea simply popped into his head during that same IBM summer of 1955 , almost as soon as he’d recognized the problem . If you wanted to create your programs interactively , he’d reasoned , and if nobody was going to give you your very own 704 to do it with , then the obvious answer was to get together with a bunch of other users to share a machine . And not just share it in the lockstep , line - forms - at - the - rear manner of batch processing , either . Really share it . Give everybody a remote terminal so they could all tap in to the big computer through telephone lines whenever they liked , from wherever they liked . Once they were in , moreover , assign each of them a securely walled - off piece of the computer’s memory where they could store data and programming code without anybody else’s horning in . And finally , when the users needed some actual processing power , dole it out to them via an artful trick .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4108</div><div class='noteText'>You couldn’t literally divide a computer’s central processing unit , McCarthy knew ; the standard von Neumann architecture allowed for only one such unit , which could carry out only one operation at a time . However , even the slowest electronic computer was very , very fast on any human time scale . So , McCarthy wondered , why not let the CPU skip from one user’s memory area to the next user’s in sequence , executing a few steps of each task as it went ? If that cycle was repeated rapidly enough , the users would never notice the gaps ( think of a kindergarten teacher holding simultaneous conversations with a dozen insistent five - year - olds ) . Each of them would perceive his or her program to be executing continuously . And more to the point , each would be able to create and modify and execute programs interactively , as if he or she had sole control of the computer . Since the users would be sharing the computer’s processing time as well as its storage space , McCarthy took to calling his scheme time - sharing . And characteristically , he wasn’t too impressed with himself for having thought it up . “ Time - sharing to me was one of these ideas that seemed quite inevitable , ” he says . “ When I was first learning about computers , I [ thought ] that even if [ time - sharing ] wasn’t the way it was already done , surely it must be what everybody had in mind to do . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4122</div><div class='noteText'>McCarthy’s proposal was far more radical . He wanted to give the users free rein inside the computer so they could play , experiment , meditate , run programs , modify programs , crash programs , and waste time as they pleased . In effect , he was proposing to optimize human time instead of machine time .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4173</div><div class='noteText'>When it came to the fundamentals of the field , to their most basic assumptions about the nature of intelligence and how to create it in a machine , they didn’t agree on anything . The aloof , cerebral McCarthy was still in search of a mathematician’s explanation of intelligence ; he couldn’t be satisfied with anything less than a theory that was deep , precise , logical , and beautiful . And he was more convinced than ever that his Advice Taker notion was the right way to get there . Minsky , by contrast , was even then a balding gnome who went at AI with the playfulness of a child . Not for nothing was he known as the world’s oldest three - year - old : he liked to build things , to see how they behaved , and to learn by doing . He saw no particular requirement for elegance or rigor in a theory of intelligence . After all , he argued , both the mind and the brain were products of evolution , and natural selection was a consummate tinkerer , slapping parts together with the abandon of a Rube Goldberg . Indeed , Minsky would later become famous for declaring that intelligence was a kludge . So he was sympathetic to Newell and Simon’s heuristic - reasoning approach . But he was also sympathetic to the neural - network approach , to the robotics approach , and to any other approach that seemed useful ; for him , whatever worked , worked .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4189</div><div class='noteText'>“ Sure , ” enthused Wiesner , with all the expansiveness of an age when funding agencies were content to let managers manage without a lot of second - guessing . “ What do you need ? ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4204</div><div class='noteText'>Of course , the computer world was hardly suffering from a shortage of new languages , even then . Thanks to the proliferation of commercial machines such as the IBM 650 and 704 , plus the success of Fortran , the years 1956 and 1957 had already seen new dialects emerging by the dozens ( two of the languages produced during this era , Fortran itself and the business - oriented Cobol , are still in widespread use today ) . However , none of these efforts came close to meeting McCarthy’s standards . In all of the new languages , for example , each symbolic variable had to be assigned to a fixed block of storage in the computer’s memory , so that one block might be allocated to the variable “ name , ” another block to “ salary , ” and so on . In fact , those assignments had to be made by the programmer up front , before the program could even begin to execute ( in many modern languages , such as C + + , this is still the case ) . But in artificial - intelligence research , such a demand would be sure death . The “ variables ” in an AI program somehow had to represent the quicksilver fluidity of mental states in human working memory — the images , concepts , possibilities , goals , and alternatives that the problem solver focuses on at any given instant . And there was no way for the programmer to know in advance how big or how complex these variables should be , because they would constantly be changing as the problem solving advanced .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4215</div><div class='noteText'>Fortunately for McCarthy , however , a solution was already at hand , courtesy of Carnegie Tech’s Allen Newell . Some three years earlier , in the course of creating his Logic Theorist program , Newell had come up with something he called a list , a data structure in which chunks of information scattered throughout the computer’s memory were connected in a loose chain . In Newell’s conception , the list worked a bit like one of those old - fashioned treasure hunts in which each hiding place contained a piece of the treasure , plus a clue to the location of the next hiding place . ( Or to use a more up - to - date analogy , a list was like a chain of World Wide Web pages , with each page containing a certain amount of data plus a hyperlink to the next page . ) Thus , to go down the list , the computer would just have to follow the links in order , jumping freely through the memory banks as it did so . Moreover , by adding and dropping links or shifting them around , the computer could freely expand or contract the various lists without having to move the data themselves . It could start with , say , a simple linear chain of symbols — ( a b c d ) — and then replace the third element with a whole new list : ( a b ( gh ) d ) . Indeed , the computer could keep on nesting one list inside another like this until it had built up matrices , tables , trees , forms , or any other kind of data structures . Or conversely , it could lop off whole branches at will . The result would be a style of computation in which the data structures weren’t fixed at all but could form , grow , interact , change , and evaporate , much as human ideas do .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4231</div><div class='noteText'>McCarthy , not surprisingly , had a low opinion of the Information Processing Language as it stood ; Newell and Shaw , being in a hurry , had created a spartan , utilitarian framework in which the commands were abbreviated by arbitrary numeric codes , the program statements had to be rigidly formatted to fit on IBM punch cards , and many of the syntactical features existed only because they were required by JOHNNIAC , the particular computer they were using at RAND . But list processing itself — now that was an elegant idea . So in the autumn of 1958 , with the new AI lab finally giving him the opportunity and the wherewithal to focus on the problem , McCarthy decided that it was time to take that idea and turn it into a whole new language for AI . § He and his students soon took to calling it List Processor , or Lisp .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4241</div><div class='noteText'>Fortran and most of the other early languages had been created by formal teams and committees , Abrahams points out , so there were lots of related documents and memos circulated . “ [ But ] Lisp really was the work of one mind , ” he says . “ The rest of us mostly added things . We implemented it , we added trimmings , but basically Lisp was John McCarthy’s invention . ” 16</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4244</div><div class='noteText'>Certainly it was a giant step beyond Newell’s original conception of list processing . McCarthy’s most striking addition was his insistence that every list define what mathematicians call a function , a kind of abstract machine that takes in raw materials at the input hopper , grinds away , and produces a finished product at the output pipe . Thus , a Lisp function plus would be given two or more numbers as input , and the computer would produce their sum as its output : ( plus 2 2 ) → 4 , and so on . Now , the point of all this was that a Lisp programmer could start with a handful of basic functions and then systematically create new functions by hooking up the output pipe of one to feed the input hopper of the next . Syntactically speaking , it was simply a matter of nesting one function inside another ( and keeping track of all the parentheses ) . For example , a programmer might combine multiplication , addition , and subtraction in a certain way — ( times ( plus w x ) ( minus y z ) ) — and then feed in four numbers such as 2 , 2 , 5 and 3 , so : ( times ( plus 2 2 ) ( minus 5 3 ) ) → ( times 4 2 ) → 8 .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4266</div><div class='noteText'>The use of software building blocks was hardly a new concept even then , of course . Starting in the 1940s , long before Lisp , or Fortran , or any of the other languages appeared , programmers had learned that they could save themselves a lot of time and confusion by breaking up programs into subroutines — reusable , self - contained procedures that could each do one specific task . One subroutine might calculate the cube root of any given number , for instance , while another might sort any given list of names alphabetically . These procedures could in turn be broken up into still simpler subroutines , and so on , all the way down to the level of individual commands , if need be . Indeed , as programmers tackled tougher and tougher challenges in the 1950s — the SAGE project , for example — this kind of decomposition had become increasingly critical . ¶ Even today , under the rubric of “ structured programming , ” it is still considered the essence of good programming practice .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4280</div><div class='noteText'>Lisp , by contrast , was better suited to the kind of bottom - up , exploratory style of programming that McCarthy had been after all along . Instead of breaking things up , Lisp programmers were constantly putting things together , using simple functions to build more complex functions , trying things out , seeing what worked , seeing what didn’t work , and learning as they went . True , Lisp did pay a heavy price for its flexibility : being interpreted line by line made Lisp programs agonizingly slow and inefficient compared to , say , a Fortran program that had been compiled in the conventional manner . It would be the better part of a decade before more efficient versions of Lisp were developed , and years more before the language became widely used even for AI . Nonetheless , it’s fair to say that one of Lisp’s two greatest legacies to the art of programming was a certain style , a certain exploratory approach to pushing back the software frontiers . And the other legacy ? An undeniable grace , beauty , and power . As a Lisp programmer continued to link simpler functions into more complex ones , he or she would eventually reach a point where the whole program was a function — which , of course , would also be just another list . So to execute that program , the programmer would simply give a command for the list to evaluate itself in the context of all the definitions that had gone before . And in a truly spectacular exercise in self - reference , it would do precisely that . In effect , such a list provided the purest possible embodiment of John von Neumann’s original conception of a stored program : it was both data and executable code , at one and the same time . * *</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4293</div><div class='noteText'>In mathematics , the technical name for this sort of thing is recursive function theory , which was why McCarthy called his first public description of Lisp “ Recursive Functions of Symbolic Expressions and Their Computation by Machine . ” Today ranked as one of the most influential documents in the history of computer languages , that paper established that a language could have a rigorous mathematical foundation . And it signified that John McCarthy had finally come up with a framework that was precise enough , rigorous enough , and compelling enough to satisfy even him . Certainly it changed how McCarthy’s AI students perceived their creation , says Abrahams : “ Now , all of a sudden , Lisp was not merely a language you used to do things . It was now something you looked at , an object of beauty . It was something to be studied as an object in and of itself . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4325</div><div class='noteText'>By that point , too , McCarthy had also heard from time - sharing’s many critics . Jay Forrester , for one , was a charter member of the think - it - through - and - get - it - right - ahead - of - time school of programming ; like many others on the MIT faculty ( and in the mainstream computer industry ) he continued to view time - sharing as a horrendous waste of computational resources . But then , McCarthy still thought of authority as something to be challenged , not deferred to . So he simply kept on talking and talking and talking about time - sharing . What ultimately had value was not computer time , he kept insisting , but human time .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4331</div><div class='noteText'>What saved McCarthy , and gave him real credibility among the engineering types around MIT , was his willingness to get down and dirty with the technical details . A few years later , says Corbató , after time - sharing had become a well - funded and well - regarded strategy , “ a number of people came out of the woodwork and said , ‘ Oh , I invented time - sharing , ’ and ‘ Did you read my paper ? ’ and this and that . The problem was that everyone had kind of dreamy visions of people interacting with equipment . . . . The thing that John did was to spell out the particulars of how you go about [ it ] . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4375</div><div class='noteText'>But more than anything else , J . C . R . Licklider was still the guy who collected ideas as avidly as he collected people , who enjoyed nothing more than a good bull session , who loved to turn people’s assumptions inside out on them , and who was constantly pushing notions as far as they could go . Within that small , contentious community of interactive - computing pioneers , that made him — well , not the leader ; nobody could have gotten very far trying to tell John McCarthy what to do , or Wes Clark , or Ken Olsen , or Ed Fredkin . But it did make him the integrator and synthesizer , the one who was doing as much as or more than any of the others to envision what a fully computerized world might be like , to imagine what interactivity might mean in human terms , to articulate where computers were going and what researchers would have to do to get there . In short , Lick was the one who provided the road map .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4382</div><div class='noteText'>The paper was basically written as a favor , remembers Jerry Elkind . In the fall of 1959 , about the same time DEC was setting up its prototype PDP - 1 in the lobby , Elkind had agreed to edit a new journal called IRE Transactions on Human Factors in Electronics ( IRE was the Institute for Radio Engineers , a professional association that has since been renamed the Institute for Electrical and Electronics Engineers , or IEEE ) . “ So for the first issue I wanted a lead article that would speak to the future of human factors , not to the past , ” he explains . “ The future was with computing . And since Lick clearly was the person who could articulate that future better than anyone else , that’s what I asked him for . ” Lick , who hated to write but hated even more to disappoint anyone in his professional family , agreed to help out . He handed Elkind the completed manuscript of “ Man - Computer Symbiosis ” on January 13 , 1960 . “ It was . . . beyond expectations , ” says Elkind , who still marvels at what his mentor produced . Indeed , he says , when you look back at that paper from the perspective of today , knowing what happened later , you can see that it essentially laid out the vision and the agenda that would animate U.S . computer research for most of the next quarter century , and arguably down to the present day .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4422</div><div class='noteText'>The first and foremost challenge , said Lick , was what he called the speed mismatch : “ Any present - day computer is too fast and too costly for real - time cooperative thinking with one man . ” His phrasing suggests that he had already rejected as impractical the idea of everyone’s having a computer of his or her own , as Wes Clark or Ken Olsen might have advocated . “ Clearly , ” he wrote , “ for the sake of efficiency and economy , the computer must divide its time among many users . ” He was deliberately noncommittal about how this would be accomplished , noting only that time - sharing systems were currently under active development . Never one to hold his imagination in check , however , he couldn’t resist following the notion to its logical conclusion — namely , an on - line “ thinking center ” not unlike today’s World Wide Web . “ [ It ] will incorporate the functions of present - day libraries together with anticipated advances in information storage and retrieval and the symbiotic functions suggested earlier in this paper . The picture readily enlarges itself into a network of such centers , connected to one another by wide - band communications lines and to individual users by leased - wire services . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4439</div><div class='noteText'>wherever he got the idea , the essential fact was that by the fall of 1959 , Lick was already thinking about computer networks that connected individual users on a continental scale — the essence of today’s Internet .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4450</div><div class='noteText'>Finally , Lick’s article reveals considerable ambivalence about artificial intelligence . He knew that AI was important to symbiosis , since smart assistants are presumably better than dumb ones . And he was clearly fascinated by the subject ; as he said on another occasion , AI seemed to offer “ the most direct path toward the understanding of intellectual processes . ” 25 Yet he also knew far too much about the brain and its complexities to believe the hype about AI , which was abundant even then . Assertions by Minsky and others to the contrary , computers were nowhere near replicating basic human abilities such as judgment or common sense . So for a long time to come , Lick wrote , humans and computers would have to work together . With tongue only partly in cheek , moreover , he referred to a recent study he’d done for the air force predicting that artificial intelligence wouldn’t be of much use for another twenty years : “ That would leave , say , five years to develop man - computer symbiosis and fifteen years to use it . The fifteen may be ten or five hundred , but those years should be intellectually the most creative and exciting in the history of mankind . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4463</div><div class='noteText'>McCarthy , for his part , thought the whole human - computer - symbiosis notion was obvious ; he claims to have found “ no surprises ” in the paper .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4495</div><div class='noteText'>Computers and the World of the Future , 27</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4511</div><div class='noteText'>Interactive computers might even become a new kind of expressive medium . After all , he joked , “ I think the first apes who tried to talk with one another decided that learning language was a dreadful bore . They hoped that a few apes would work the thing out so the rest could avoid the bother . But some people write poetry in the language we speak . Perhaps better poetry will be written in the language of digital computers of the future than has ever been written in English . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4543</div><div class='noteText'>A model , in short , is any convenient simulation of reality . However , as Lick noted in another paper29 from the 1960s , there are models , and then there are models : “ Ordinary mathematical models are static models . They are representations in symbols , usually written in pencil or ink on paper . They do not behave in any way . They do not ‘ solve themselves . ’ For any transformation to be made , for any solution to be achieved , information contained in the model must be read out of the static form and processed in some active processor , such as a mathematician’s brain or a computing machine . A dynamic model , on the other hand , exists in its static form only while it is inactive . The dynamic model can be set into action , by one means or another , and when it is active , it does exhibit behavior and does ‘ solve itself . ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4553</div><div class='noteText'>A model sculpted from software is static when it exists as binary code on a disk or a tape . As such , it can be stored , transmitted , archived , and retrieved , just as ordinary text can be . It in fact is a kind of text . Like ordinary text , moreover — and unlike the balsa wood of a model airplane , or the electrical circuits of an analog computer , or any other physical medium — a computer model is infinitely malleable . Software can represent a jet fighter one minute and the girders of a bridge the next . It is the ultimate expressive medium , Lick later wrote — “ the moldable , retentive , yet dynamic medium — the medium within which one can create and preserve the most complex and subtle patterns and through which [ one ] can make those patterns operate ( as programs ) upon other patterns ( data ) . ” 30 And that is how a static computer model becomes dynamic : by being executed on a computer . In that context it becomes a process unfolding over time — not a text but a behavior . Of course , the process isn’t a very exciting one if all you get at the end is a fan - fold printout containing page after page of numbers . However , said Lick , if you could have a graphics display that allowed you to see the model’s behavior — and then if you could somehow grab the model , move it , change it , and play with it interactively — then the experience of working with that model would be very exciting indeed . It would be like sitting in the cool breeze of that fan and flying the Curtiss Robin : you wouldn’t just be thinking about the model , you would be feeling it , viscerally .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4604</div><div class='noteText'>Nowadays this sort of computer - assisted cooperative work comes under the heading of “ groupware . ” Lick’s PDP - 1 wasn’t up to doing many experiments along those lines , unfortunately . But the subject was much on his mind , thanks to one of the first nonacoustical projects he’d started at BBN : a contract with the Air Force Office of Scientific Research , which charged him with figuring out how systems of humans and machines could be organized to perform more effectively . There was ample cause for concern , he knew : modern “ military super - systems ” such as SAGE and the Strategic Air Command were rapidly growing too large and too technologically complex for human beings to cope with unaided . “ Modern technology is as much politics and sociology as physics and chemistry , ” Lick wrote in the project’s summary report . “ The problem is no longer to design a pulley or a gear . It is to find a mission worthy of a million men , to plan a flow of metal and ideas and of flexibility and change . . . . Requirements vary , year by year , and detailed plans must follow , day by day , the vagaries of new solutions over which no rigid schedule can prevail . To harmonize great projects thus demands an agent , flexible and fast as well as strong and wise . ” 33 That agent , not surprisingly , would be a time - shared computer . Or more precisely , it would be a system of humans and computers working together to plan , build , operate , and maintain another system — a satellite - reconnaissance network , say , or a combat - theater operations center . In the planning and design phases , Lick continued , this “ system system ” would create a computer model that would serve as the blueprint and specification for the target system — much as in a modern computer - aided design / manufacturing setup , in fact . But in later phases , the model would also serve as the basis for planning and evaluating tests of the target system and for training its users . Then , in still later phases , the model would provide a basis for planning upgrades and improvements to the target system . And so it would go , from cradle to grave .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4629</div><div class='noteText'>In November 1961 , he received a commission from the Council on Library Resources to explore what computers might mean for the “ library of the future ” — the future , in this case , being the year 2000 . He and his BBN colleagues immediately went to work on their PDP - ls to create one of the world’s first demonstrations of library automation . By the end of the project , they had done so much “ to facilitate the scholarly process ” with computers — reading and studying documents , tracing references , and so on — that the council’s delighted president , Verner Clapp , talked the editors at the MIT Press into publishing Lick’s final report in toto . It would eventually appear in 1965 as Libraries of the Future , Lick’s only book . “ I have always been pretty happy with that , ” Lick said in his 1988 interview . It was about as close as he ever came to bragging . Libraries of the Future is , in fact , one of the founding documents of what is now called digital library research , which includes ( among other things ) our efforts to manage information in that sprawling mass of data known as the World Wide Web . In his report , Lick examined all the computer tools that have since become familiar in libraries , such as the on - line card catalog , keyword bibliography searches , and on - line document retrieval . Yet he also emphasized that these tools were just the beginning . Such techniques can be wonderfully helpful when you already know exactly what documents you want , he said . But if you’re not even sure where to look , or if you’re still in that hazy beginning stage where you’re struggling to figure out what questions to ask , then the classic search techniques won’t help much at all . In this “ negotiation ” phase of the search , as Lick called it , what you desperately need is a good reference librarian ( a prize that is , alas , all too rare ) . And it is in this negotiation phase that good , intelligent symbiotic computing could be a real help — if only we knew how to create such a thing .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4652</div><div class='noteText'>Once again , it would be quite a while before Lick could articulate all these ideas as precisely as he wanted . But by the time of that MIT centennial celebration in April 1961 , they were clear enough . Indeed , he had enough confidence in his overall vision for the “ new science ” of computing that , with an unconscious foreshadowing of the future , he closed his commentary with an academic call to arms : “ It will not suffice to wait until the computer industry develops the [ symbiotic ] computer the university needs ; for commercial , industrial , and military requirements are not leading to development of such a computer on anything like the time scale that is feasible . Moreover , having such a computer is much less than half the battle . The task of preparing the programs required to make it ‘ go critical ’ is great . But it is a task that universities can and should handle , for it is itself an intellectual enterprise of high order . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4674</div><div class='noteText'>Back in the spring of 1959 , McCarthy and IBM’s Nat Rochester had offered MIT’s first programming course , a daunting intellectual gauntlet that included exercises in assembly language , Fortran , and Lisp . But it just so happened that among the students in their class were several members of the Tech Model Railroad Club , a band of techno - geek undergraduates who spent their free time creating ever more elaborate train layouts controlled by ever more intricate electrical switching networks , the more ingenious the better . Borrowing an ancient MIT slang word for a practical joke , the railroad club’s members had taken to calling any particularly clever bit of controller design a hack . And as the writer Steven Levy described in 1984 , the hackers in McCarthy and Rochester’s course soon got so caught up in the fiendishly intricate joys of programming that they started hanging around the Computation Center till all hours , the better to gain access to the 704 . There they were discovered one day by former railroad - club member Jack Dennis , now the staffer in charge of the TX - 0 , who asked them if they would like to come upstairs and see that machine . “ The TMRC people were awed , ” wrote Levy . Not only was the TX - 0 an interactive machine that let you modify your program on the fly , but you could sign up for blocks of time to use the computer all by yourself ! “ There was no way in hell that [ they ] were going to be kept away from that machine . ” 34 Actually , no one tried to keep them from it . Dennis and his fellow technicians were happy to let the model railroaders hang around the TX - 0 till all hours as well . And if the researcher who had officially signed up for the 2 : 00 A.M . slot happened to oversleep — well , there was no sense in letting all that computer time go to waste . So the “ TX - 0 hackers , ” as they were now calling themselves , would crowd around the display screen and explore what it really meant to play on a computer .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4771</div><div class='noteText'>“ Herb was trying to engineer it from the ground up , ” Corbató says . “ He wanted to do it just right ; he wanted to see the system running efficiently ; he wanted to see good user resources . And if he could not get it that way , he was willing to wait . ” Corbató , however , was not . By the early spring of 1961 , he was so frustrated by Teager’s achingly slow progress that he and two other staffers at the center started working on a time - sharing system of their own . They desperately wanted a prototype to give people a feel for interactive computing , he says : “ You could talk about it on a blackboard until you were blue in the face . You could try all these analogies , like describing it in terms of the difference between mailing a letter to your mother and getting on the telephone . And people would say , ‘ Oh , yes , but why do you need that ? ’ ” The prototype would be crude and primitive — basically a series of software patches applied to an IBM batch - processing operating system — but it would run now , on the center’s existing 709 ( and on the 7090 upgrade when it arrived ) . Moreover , it would run the software that people already had , without forcing them to change over . Thus the name : Compatible Time - Sharing System , or CTSS .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4818</div><div class='noteText'>Of course , McCarthy did manage to feel a bit insulted by the invitation ; despite his inclusion on the impressively heavyweight roster of participants , which ranged from C . P . Snow to Vannevar Bush , he couldn’t help but notice that he’d been asked to fill in only after someone else had taken ill . “ I was not considered important by the MIT higher - ups , ” he declares . Nonetheless , McCarthy’s talk had an impact , not least because at the very end of it he finally stated in public what he’d long been mulling over in private : “ If computers of the kind I have advocated become the computers of the future , ” he said , “ then computation may someday be organized as a public utility , just as the telephone system is a public utility . We can envisage computer service companies whose subscribers are connected to them by telephone lines . Each subscriber needs to pay only for the capacity that he actually uses , but he has access to all programming languages characteristic of a very large system . The system could develop commercially in fairly interesting ways . Certain subscribers might offer services to other subscribers . One example is weather prediction [ ; ] other possible services include . . . programming services . Some subscribers might rent the use of their compilers . Other subscribers might furnish economic predictions . The computing utility could become the basis for a new and important industry . ” 42</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4829</div><div class='noteText'>Indeed , he said , given the economies of scale then prevalent in the computer industry , it wasn’t too hard to imagine such service centers ’ growing to the size of municipal power plants : every city would have at least one computer , and the very biggest cities might have several . And yet in the process , paradoxically , computation would be democratized . Instead of being walled off in air - conditioned sanctums , instead of being nothing but the tools of powerful institutions , computers would become available to everybody . Like Thomas Edison , the time - sharing pioneers would quite literally be bringing power to the people .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4875</div><div class='noteText'>So there it was : by 1962 , the notion of human - computer symbiosis was doing OK — but no better than OK . What it had going for it was a handful of activists and visionaries who were willing to work together — except when they weren’t . What it also had was a handful of interesting experiments that could have completely overthrown the conventional wisdom of computing — except that they were always on the verge of fizzling out . But what the vision didn’t have was a single champion , someone with enough resources to make things happen in a big way and enough clout to get people marching in the same direction .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4887</div><div class='noteText'>In one of his few prior forays into artificial intelligence , McCarthy had spent the summer of 1952 working with Shannon at Bell Labs . The main result was a volume of invited papers on the subject , which they jointly edited . It would appear in 1956 as Automata Studies , a title that McCarthy hated . But with contributions from von Neumann and many others it added up to present a greatly enriched understanding of what Turing machine — like automata — that is , computers — can and cannot do . The book is now considered a landmark in computer science .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4907</div><div class='noteText'>By the fall of 1958 , Gelernter , McCarthy , and their coworkers had gotten their Fortran List Processing Language working well enough for Gelernter to use it ; his Geometry Theorem Prover is now considered yet another of the early landmarks of artificial intelligence . In one sense , however , that particular landmark was a little too prominent . By the fall of 1958 , the reputation of the AI work in Poughkeepsie had spread to the point of being featured in the New York Times and Scientific American . Shortly thereafter , IBM president Thomas J . Watson , Jr . , having been personally badgered by stockholders demanding to know why the company was wasting money on frivolous junk like this — and having heard far too many IBM salesmen complain that customers were feeling threatened enough by computers as it was , without artificial intelligence — told Rochester and his colleagues to cease and desist . Thus IBM essentially abandoned artificial - intelligence research , and for another generation , its salesmen could soothingly tell customers that IBM computers would do only what you told them to do .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4934</div><div class='noteText'>Actually , in an even more spectacular exercise in self - reference , the Lisp interpreter itself could be expressed as a Lisp function . In other words , Lisp could be written in Lisp , with only a very small kernel of machine code to keep it moored to the physical operation of the computer . That Lisp kernel , known as apply , thus provided a particularly elegant example of a universal Turing machine : it was the universal function that took the definition of any other function as input and then executed that function . By no coincidence , McCarthy implemented this kind of functional programming in Lisp using the notation of the “ lambda calculus , ” which Alonzo Church had created twenty years earlier to solve the decidability problem , and which had allowed him to beat Alan Turing to the punch .</h3>
<h2 class='sectionHeading'>Chapter 6:      The phenomena surrounding computers</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4967</div><div class='noteText'>Laika .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 4983</div><div class='noteText'>So on November 7 , 1957 , in a solemn address to the nation , Eisenhower announced that he was appointing the president of MIT , James Killian , to the newly created post of presidential science adviser , thereby moving science and technology to the center of U.S . policymaking . He likewise committed his administration to massive new investments in education , research , and development . And in the process , he promised , he was going to clean up the research mess in the Pentagon . A short time later , Eisenhower followed up on that pledge by endorsing a plan to consolidate all the Pentagon’s space research under a new civilian agency reporting directly to the secretary of defense . It would be called the Advanced Research Projects Agency , or ARPA .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5031</div><div class='noteText'>Still , says Ruina , astonishing though it may seem in retrospect , there was one technology that the secretary never asked him about : computing . Why should he ? ARPA wasn’t funding any computer research . And besides , as far as McNamara or almost anyone else on the third - floor E Ring knew , computers were just gadgets to be used for payroll and accounting , plus a few very exotic applications such as the SAGE air - defense system . True , some people down at the working level of the DoD were trying to think more creatively about computers . But they certainly hadn’t come up with anything that Ruina found compelling . “ People saw that something was there , ” he says , “ but they were not prepared to invest big money without knowing quite what that something was . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5092</div><div class='noteText'>In effect , Lick explained to them , everyone at the Pentagon was still thinking of computers as giant calculators and data processors . For that matter , so was practically everyone at IBM and in the rest of the computer industry . And that , he remembered telling Ruina and Fubini , was where ARPA had its real opportunity : “ This kind of [ interactive ] computing almost did not exist . But up in Cambridge everybody was excited about making it exist . [ So ] why didn’t we really develop an interactive computing ? If the Defense Department’s need for that was to provide an underpinning for command and control , fine . But it was probably necessary in intelligence and other parts of the military , too . ” Indeed , he insisted , interactive computing had the potential to transform human life in the civilian sphere as well — everywhere , in fact . “ I was just a true believer , ” he said . “ I was one of the very few people , at that time , who had been sitting at a computer console four or five hours a day , or maybe even more . It was very compelling . I was terribly frustrated at the limitations of the equipment we had , but I also saw how fast it [ was ] getting better . . . . I thought , This is going to revolutionize how people think , how things are done . . . . I thought we were going to double [ human productivity , ] or triple it , or multiply it by four or ten . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5103</div><div class='noteText'>Maybe it isn’t as far afield from command and control as you think . “ Notice that man - computer interaction is heavily involved in the skills and capabilities of the people as well as the machines , ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5107</div><div class='noteText'>By this point , it seems , Ruina was sold . In the normal , bureaucratic course of things , he would have been happy enough to hire a manager whose idea of command - and - control research didn’t go beyond the mainstream — improvements in database management , say , or fast - turnaround batch - processing systems . He never would have known the difference . Instead , almost completely by accident , he’d stumbled upon a visionary , a man who could take this amorphous idea of command - and - control research and put it into the larger context of human destiny . Unlike most visionaries , moreover , Lick had done some serious thinking about how to get from here to there ; in effect , his 1960 “ Symbiosis ” paper was a ready - made research agenda for this whole ARPA program .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5148</div><div class='noteText'>And indeed , says Herzfeld , Lick captured everyone’s attention inside the first few sentences . Many of the ARPA and DDR &amp; E staffers had used batch - processed computers for number - crunching and such . But here was Lick talking about time - sharing , interactive graphics , networking — concepts an order of magnitude further advanced . “ It was a revelation , ” says Herzfeld . “ My first experience with computers had been listening to a talk by von Neumann in Chicago back in nineteen forty - eight . It sounded like science fiction then : a machine that could carry out algorithms automatically . But the next big shock was Lick : not only could we use these machines for massive calculations , but we could make them useful in our everyday lives . I listened . I got very excited . And in a very real sense , I became a disciple from then on . ” Certainly Herzfeld became one of Lick’s closest friends and staunchest supporters within ARPA .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5163</div><div class='noteText'>Meanwhile , Lick was also expanding his network of allies into other corridors of the Pentagon , beginning with his counterparts in the uniformed services ’ own research agencies . This was a matter of some delicacy : until October 1 , 1962 , their leadership in cutting - edge computer research had gone unchallenged — witness the army with ENIAC and EDVAC , the navy with Whirlwind , or the air force with the TX - 0 and TX - 2 . And yet now here was J . C . R . Licklider , invading their turf with a budget that dwarfed the three of theirs put together . The potential for some nasty bureaucratic infighting was all too apparent . But it never happened . “ The people who might have been our competitors were really our agents and our friends , ” Lick explained , referring to a deal struck in ARPA’s tumultuous first year : instead of building a new bureaucracy of its own , ARPA would make use of the ones that already existed . So when Lick wanted to start a new research project , all he had to do was give the formal go - ahead , and one or another of the service agencies would then write the contract , disburse the funds , keep track of progress reports , and so on . This was great for him , because he was terrible at managing that kind of paperwork anyway .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5177</div><div class='noteText'>Quite soon after his arrival , in fact , Lick organized a monthly meeting at which he and his counterparts could bring each other up to date on the research they were funding , eliminate overlaps , and look for new opportunities to collaborate . And very soon after that , Lick expanded the meeting to include funding officers from NASA , the National Science Foundation , the National Institutes of Health , the Atomic Energy Commission , and any other agency around Washington that was putting even a little bit of money into computer research .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5185</div><div class='noteText'>Ivan Sutherland , remembers his first meeting in 1964 : “ These people met , period . The group had no charter , no responsibilities , no budget , no purpose — but it was a great thing . We would discuss what was important , what was current , and what was going on . Precisely because the group had no charter , it was a wonderful way of getting information flow between the agencies . ” And the upshot of all this ? Simply that this dreamy , talkative , hopelessly unfashionable academic had entered into a bureaucracy as tough and as turf - conscious as any in the world , and with little apparent effort had carved out a niche for himself in which he could pursue his agenda with near - perfect freedom ; deal with his natural enemies as a convivial network of friends and allies ; and tend to his real constituency , the researchers , with little or no need to watch his back .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5194</div><div class='noteText'>Lick knew there were scattered groups of people who shared his dream . His job now was to seek them out , nurture their work with ARPA cash , and forge them into a self - sustaining community that could carry on after he was gone .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5216</div><div class='noteText'>Lick had been looking into the SDC command - and - control project since at least May 1962 , months before he officially started at ARPA . And while he’d found a lot to like , including some pioneering work on how to deal with large databases and how to create large , complex programs , he’d found a lot more not to like , starting with the fact that the researchers were using their Q - 32 computer as a batch processor . “ I hated to see it , ” Lick later remembered . So in the fall of 1962 , on his first official visit to SDC , he very courteously made it clear that he was cutting back on its budget a bit and that the command - and - control project would henceforth be an investigation into time - sharing . Reprogramming of the Q - 32 would start immediately . “ I was aware that this was cheating , ” Lick conceded in his 1988 interview , still feeling a little guilty about it more than a quarter of a century later . “ I was insisting on my philosophy , my vision of what I wanted to happen here , and these people had every right to have their own vision . ” But there it was : he was trying to make a revolution , and he couldn’t afford to let 60 percent of his budget be squandered on batch processing .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5258</div><div class='noteText'>Factoring in the small amount of money he’d taken out of SDC , his back - of - the - envelope calculations suggested that he could fund maybe ten separate research groups , large and small . “ It was going to take more than that to make a movement , ” he said . “ But I felt I could settle for it if I just had ten . ” High on his list , for example , was Carnegie Tech in Pittsburgh , where Allen Newell , Herbert Simon , and Alan Perlis had created a movement all by themselves . To bring them into the ARPA orbit , Lick had immediately sent them three hundred thousand dollars out of his behavioral - science budget . Use it however you want , he told them : grad students , machines , programmers — no questions asked . And there would be more to come later , he promised , once they had had a chance to talk . Newell , Simon , and Perlis were startled ; Newell , for one , had never even heard of J . C . R . Licklider . But they took the money .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5267</div><div class='noteText'>Lick knew RAND as the home of JOHNNIAC , the hand - built clone of John von Neumann’s original computer at the Institute of Advanced Study . He also knew it as the place where Newell , Simon , and RAND programmer Clifford Shaw had created their pathbreaking artificial - intelligence programs , Logic Theorist and General Problem Solver . But when he went calling in the fall of 1962 , Lick discovered that RAND had also begun to do some really innovative work in interactive computing . There was JOSS , of course , the mathematician’s “ helpful assistant ” ; Cliff Shaw and his colleagues were getting ready for their first debugging runs , which would start the following spring . But there was also a new project known as the RAND Tablet , a kind of high - tech sketch pad that a user could write or draw on with a stylus , with the results then appearing on a CRT display . Now that , said Lick , was symbiosis . Indeed , in his 1960 paper he’d envisioned a graphical interface very much like this . Lick made it quite clear that he wanted to fund this work , recalls Keith Uncapher , who was director of the RAND computer group in 1962 . And as Lick left , he says , they agreed to keep talking .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5292</div><div class='noteText'>And so it went . Lick seems to have spent most of that autumn of 1962 on airplanes , trying to entice computing’s best and brightest to join in his vision . Of course , he did have to be a little careful about how he made his pitch . Early on , Lick would later remember , some of the old hands at the Pentagon had reminded him sternly that he was now a government employee , which meant that he wasn’t supposed to solicit specific proposals from specific people — a practice that smacked of favoritism , elitism , cronyism , and other undemocratic things . In the name of fairness and equal opportunity , they insisted , a government funding officer had to wait for proposals to come to him .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5297</div><div class='noteText'>Not a chance . Waiting around would spell disaster , Lick realized — so he quickly figured out a way to circumvent the rules without actually disobeying them . “ I took advantage of those other three leftover SAGE computers , ” he later explained . “ I couldn’t ask for a proposal directly , but I could go around and ask people , ‘ Do you want one of these things , and what would you do with it if you had it ? ’ Well , people were pretty sensible . Nobody wanted one . But it did lead to a lot of discussions , and the discussions led to proposals , and so forth . So I was able to get proposals out of quite a few places without ever asking for one . They came pretty fast . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5303</div><div class='noteText'>A few proposals did indeed come looking for him , with perhaps the most notable being a long , visionary document that landed on his desk at the Pentagon almost literally the day he arrived . It made for strange reading , he remembered , as unsolicited proposals often do . But in this case , Lick didn’t automatically dismiss it as the work of a crackpot , if only because he’d met the author once or twice before . At age thirty - seven , ten years younger than Lick himself , he was a handsome , dark - haired , but rather lonely fellow — the quiet sort who ordinarily might not stick in your memory . But then once you got to know him a bit , you saw that much of this man’s quietness came from his habit of listening — deeply , profoundly listening to everything that was happening around him , and trying to work out its most fundamental meaning . And then when he did talk , his soft , diffident baritone somehow managed to be hypnotic in its intensity . His name was Douglas Engelbart .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5316</div><div class='noteText'>And yet , as Engelbart explained to Howard Rheingold for the latter’s 1985 book , Tools for Thought , “ the Monday after we got engaged , I was driving to work when I was hit with the shocking realization that I no longer had any goals . As a kid who had grown up in the Depression , I was imbued with three goals : get an education , get a steady job , get married . Now I had achieved them . Nothing was left . ” 5 Driving onward through the vast prune orchards of what would later be known as Silicon Valley , Engelbart calculated that he had about 5.5 million working minutes remaining in his life . What was he going to do with them ? He’d never much cared about getting rich . And changing careers seemed like too much work . So that just left . . . saving the world ? Well , he figured , the world could certainly use a little saving , what with overpopulation , the nuclear - arms race , the Korean War , and a vast array of other problems . The question was , How ? Engelbart mulled over that question for several months , considering and then rejecting any number of idealistic crusades . But then suddenly , as he wrote in his own memoir , “ up through all this delightful , youthful abstraction bobbed the following clear realization ” : FLASH - 1 : The difficulty of mankind’s problems was increasing at a greater rate than our ability to cope . ( We are in trouble . ) FLASH - 2 : Boosting mankind’s ability to deal with complex , urgent problems would be an attractive candidate as an arena in which a young person might try to “ make the most difference . ” ( Yes , but there’s that question of what does the young electrical engineer do about it ? Retread for a role as educator , research psychologist , legislator . . . ? Is there any handle there that an electrical engineer could . . . ? ) FLASH - 3 : Aha — graphic vision surges forth of me sitting at a large CRT console , working in ways that are rapidly evolving in front of my eyes ( beginning from memories of the radar - screen consoles I used to service ) . 6 The whole idea came together in about half an hour , Engelbart told Rheingold : “ I started sketching a system in which a computer draws symbols on the screen for you , and you can steer it through different domains with knobs and levers and transducers . I was designing all kinds of things you might want to do if you had [ such ] a system . . . how to expand it to a theater - like environment , for example , where you could sit with a colleague and exchange information . God ! Think of how that would let you cut loose in solving problems ! ” 7 Within a few days , he said , the imagery of FLASH - 3 had evolved into a vision of a general - purpose , computer - powered information environment . It would include documents mixing text and graphics on the same CRT display . It would include whole new systems of symbols and methodologies to help users do their heavy thinking . And it would include network - assisted collaborations to allow people to work together in ways that would be more effective than anything anyone had ever seen before . Within a few weeks he had committed his career to this vision , which he now called “ augmenting the human intellect . ”</h3>
<h3 class='noteHeading'>Note - Location 5344</div><div class='noteText'>Interesting thing about this bit is how the notion of &quot;intellect-augmenting&quot; was seen as a task that dealt in documents</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5355</div><div class='noteText'>Engelbart continued to do conventional work at SRI for another year and a half , in the process earning a dozen more patents . Only in 1959 was he able officially to work on augmentation , thanks to a small grant from the air force’s office of scientific research , plus some reluctant support wrangled out of the SRI higher - ups . And even then , he later wrote , “ it was remarkably slow and sweaty work . I first tried to find close relevance within established disciplines [ such as artificial intelligence , ] but in each case I found that the people I would talk with would immediately translate my admittedly strange ( for the times ) statements of purpose and possibility into their own discipline’s framework . ” 9 At the 1960 meeting of the American Documentation Institute , a talk he gave was greeted with yawns , and his proposed augmentation environment was dismissed as just another information - retrieval system .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5362</div><div class='noteText'>No , Engelbart realized , if his augmentation ideas were ever going to fly , he would have to create a new discipline from scratch . And to do that , he would have to give this new discipline a conceptual framework all its own — a manifesto that would lay out his thinking in the most compelling way possible . Creating that manifesto took him the better part of two years . “ Augmenting the Human Intellect : A Conceptual Framework ” wouldn’t be completed until October 1962 . But Engelbart was nothing if not dogged . “ By ‘ augmenting man’s intellect , ’ ” he wrote , struggling to articulate his own gut feelings , “ we mean increasing the capability of a man to approach a complex problem situation , to gain comprehension to suit his particular needs , and to derive solutions to problems . . . . We do not speak of isolated clever tricks that help in particular situations . We refer to a way of life in an integrated domain where hunches , cut - and - try , intangibles , and the human ‘ feel for a situation ’ usefully coexist with powerful concepts , streamlined technology and notation , sophisticated methods , and high - powered electronic aids . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5371</div><div class='noteText'>“ Electronic aids ” meant computers , of course , along with all the associated technologies for information storage and transmittal . But it was no accident that Engelbart started that sentence with words such as hunches and feel . Much of what followed was in fact an extended meditation on the human side of the equation : Precisely what was the nature of this system that he was proposing to augment ? Well , Engelbart wrote , let’s ask ourselves how humans have managed to cope with complex situations until now . Imagine a native of the Amazonian rain forest who is magically teleported into New York City : confronted with taxicabs , pay phones , and delicatessens — phenomena that natives of the urban jungle can handle with ease — he would be helpless as a baby . But wherein lies the difficulty ? Not in the biological “ hardware , ” said Engelbart : at the level of neurons and neurochemistry , all human brains are essentially identical . No , the difference lies in the biological “ software , ” the repertoire of concepts and skills that each of us acquires over a lifetime . The ability to drive a car , the ability to place a telephone call , the very notion of money — these are units of knowledge that can be applied in a wide variety of situations , Engelbart explained , which makes them roughly analogous to data structures and subroutines in a computer program . However , he emphasized , isolated skills and concepts are useless unless they can be organized for a larger purpose : “ Just as the mechanic must know what his tools can do and how to use them , so the intellectual worker must know the capabilities of his tools and have suitable methods , strategies , and rules of thumb for making use of them . ” Again , this is basically analogous to the way low - level subroutines are assembled into larger subroutines , which in turn are assembled into complete programs . In exactly the same way , wrote Engelbart , human capabilities exhibit a whole hierarchy of levels , ranging from the neural routines that are wired into our brains before birth all the way up to the high - level impulses we absorb from the surrounding culture — the commitment to liberty , equality , and fairness , for instance . Indeed , he suggested , this hierarchy is what we’re actually talking about when we use that mystical word intelligence : “ If there is any one thing upon which this ‘ intelligence ’ depends it would seem to be [ the hierarchy’s ] organization . ” And of course , that elaborately organized hierarchy was what Engelbart proposed to augment . All of it — “ the system . . . comprising a trained human being together with his artifacts , language , and methodology . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5401</div><div class='noteText'>With the possible exception of the Expensive Typewriter program being created by the MIT hackers at about the same time , this remarkable passage is the first written description of a modern word - processing system . And for the life of him , Engelbart can’t remember where the idea came from . “ It was just a part of all those years of thinking , ” he says . “ Manipulating words seemed like the obvious place to start because it was a way to manipulate your ideas . That’s the very essence of your knowledge and thinking : the concepts in your mind that you’re converting to words and symbols . And since the computer should be able to manipulate symbols for you , it was ‘ Well , of course . ’ It could just help you in so many ways . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5412</div><div class='noteText'>The second phase had been symbol manipulation , Engelbart continued , when our ancestors evolved the capacity to represent concepts with mental symbols such as words and numbers . For example , this capacity would allow a shepherd to keep track of all twenty - seven sheep in his flock by counting them instead of having to remember what each sheep looked like . Then the third phase was manual external symbol manipulation , he wrote , when our forebears invented a variety of ways to represent their mental symbols graphically : “ a stick and sand , pencil and paper and eraser , straightedge or compass , and so on . ” This allowed us to overcome the limitations of working memory and greatly enhanced our ability to visualize things . But now , wrote Engelbart , thanks to computers that were capable of executing programs on their own , humans were embarking upon a fourth stage : automated external symbol manipulation . “ In this stage , ” he noted , “ symbols with which the human represents the concepts he is manipulating can be arranged before his eyes , moved , stored , recalled , operated upon according to extremely complex rules . . . . In the limit of what we might now imagine , this could be [ done by ] a computer . . . with which we could communicate rapidly and easily , coupled to a three - dimensional color display within which it could construct extremely sophisticated images . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5458</div><div class='noteText'>So by early 1963 , Engelbart had funding for his project . Of course , he didn’t receive a huge amount of money , thanks to Lick’s steadily growing list of academic dependents . But it was a start . And at age thirty - seven , Douglas Engelbart was feeling , well , something this quiet , lonely man hadn’t felt very often before , certainly not in relation to his augmentation ideas . “ Lick was the first person to believe in me , ” says Engelbart . “ And he was the first person to stick his neck out and give me a chance . In fact , if he hadn’t done that , if he hadn’t stuck his neck out and given me money , I don’t think anybody ever would have done so . That was why I trusted him . Lick was like my big brother . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5670</div><div class='noteText'>To keep it all straight , he added , “ I used to draw big sketches on big sheets of paper . Then I would lose the paper . [ So ] I had pretty well wrapped up in me all of the topics that it would take to put interactive computing together . ” But what if he got hit by a bus ? No , Lick realized , if this vision was ever going to outlast his tenure at ARPA , he would somehow have to forge all these groups into a self - reinforcing , self - sustaining community . Putting MIT to work on the summer study had been one big step in that direction . And by the spring of 1963 , he had taken another step by arranging to meet periodically with the leaders of all the groups he was underwriting — people such as Fano , McCarthy , Uncapher , Engelbart , Feigenbaum , and Perlis , who were known as the principal investigators , or PIs . “ [ The idea was that ] we would get our gang together frequently and have special Computer Society meetings , ” Lick said . “ There would be lots of discussion , and we would stay up late at night , and maybe drink a little alcohol and such . So we would have one place interact with another place that way . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5705</div><div class='noteText'>“ I deliberately talked about the Intergalactic Network , ” he would explain in 1988 . “ But I deliberately did not try to do anything about netting them [ the ARPA - funded sites ] together , because it was becoming very difficult for them just to get their main projects to run . ” Besides , the networking technology wasn’t even close to being ready . Lick did fund one small experiment at UCLA , which boasted no less than three IBM 7090 - series computers on its campus , in hopes that the effort to link those machines would provide valuable experience . He also arranged to have Berkeley , UCLA , and SRI form what he called the California Network , tapping into the SDC time - sharing system via phone line . But that was about as far as he went .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5713</div><div class='noteText'>The goal , as Project MAC activists never tired of explaining , was nothing less than the democratization of computing . As Martin Greenberger of MIT’s Sloan School of Management declared in the first written manifesto of the information - utility idea , published in the Atlantic Monthly’s May 1964 issue , “ Computing services and establishments will begin to spread throughout every sector of American life , reaching into homes , offices , classrooms , laboratories , factories , and businesses of all kinds . ” 15</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5720</div><div class='noteText'>Nonetheless , the MIT vision that Greenberger outlined was remarkably prescient in describing how computers would be used . Assuming that Project MAC and the other time - sharing experiments could master the technical and economic challenges , he wrote , “ An on - line interactive computer service , provided commercially by an information utility , may be as commonplace by 2000 A.D . as telephone service is today . ” One major application would be electronic commerce , with on - line catalogs , on - line ordering and billing , and electronic cash . Others would include the routine use of computer simulation and dynamic modeling , “ medical - information systems for hospitals and clinics , centralized traffic control for cities and highways , catalogue shopping from a convenience terminal at home , automatic libraries linked to home and office , integrated management - control systems for companies and factories , teaching consoles in the classroom , research consoles in the laboratory , design consoles in the engineering firm , editing consoles in the publishing office , computerized communities . Different subscribers to the same information utility will be able to use one another’s programs and facilities through intersubscriber arrangements worked out with the utility on a fee basis . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5731</div><div class='noteText'>The only problem , admits Bob Fano , as he looks back on that frenetic first year , was that he and his colleagues were hopelessly naive about how to get there . They really thought that they could create a computer utility through pure engineering . Just set up the terminals , string the wires , and keep that central power plant — um , keep that central computer humming . They found out differently the instant they got real users involved . “ It was a sociological phenomenon , ” says Fano , who has never quite gotten over his sense of amazement . “ All sorts of human things happened , ranging from people destroying keyboards out of frustration , to friendship being born out of using somebody else’s program , [ to ] people communicating through the system and then meeting by accident and saying , ‘ Oh , that’s you . ’ ” 16 True , he adds , this kind of “ virtual community ” has practically become a cliché in the Internet era . But Project MAC was the first . And there’ll never be a first again . The roots of this sociological explosion reached back to July and August 1963 , when a total of fifty - seven people gathered at MIT for various portions of the six - week summer study . “ For many of them , ” Fano later wrote , “ this was their first opportunity to use a time - sharing system and to explore the potential of on - line , interactive computation . The reaction was very favorable in spite of the fact that the system was often overloaded and therefore slow in responding to service requests . ” 17</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5767</div><div class='noteText'>“ One morning I arrived first thing and there was Joe Weizenbaum sitting in my office , mad as a hatter , ” says Fano . Weizenbaum had attended the summer study as an engineer from General Electric , and he had been so inspired by interactive computing that he had started writing a program that could carry on a real - time , interactive conversation in English . Weizenbaum had joined the Project MAC staff that fall and was now busy expanding his program into what would later become famous ( or infamous ) as ELIZA , the artificial psychotherapist . But he obviously wasn’t making much progress that morning , says Fano : “ Dick Mills had come in , too , from his office , and Joe said , ‘ CTSS was not working last night . I was told that it would be working shortly . It is not working this morning . What the hell is going on ? ’ ” Fano and Mills did their best to calm their visitor down , but all the while , says Fano , he was thinking , Victory ! “ Joe spoke like a public utility customer , ” he explained . “ His attitude was just what we wanted ! ” 20 But of course , Weizenbaum’s complaint was no joke , especially since it was only the first of many . Fano and his colleagues were starting to learn their first great lesson about utilities : what begins as a convenience quickly becomes a necessity . People begin to structure their work , their daily routines , even their entire lives around the utility . And as a consequence they become very , very proprietary about it . “ Emotions got very high , ” says Fano .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5791</div><div class='noteText'>Nonetheless , for all its irritations , CTSS was interactive . Make your way up to the public terminal room on the ninth floor of Tech Square , type in a command , and the computer would type out a response ( eventually ) . Type in another command , and the computer would respond again . On and on it would go , in an endless ( and rather Lisplike ) cycle of command and response . Users found the experience eerily seductive , to the point where Fano had to take some steps : “ I was very well aware of how hard the programming staff worked , ” he says . “ They were willing to stay here even in the evening to use the time - sharing system . That inhibited their family life . So I made the decision to provide teletypewriter connections for people at home . I only needed the terminal and a private telephone line to their house . My argument was that the extra work they’d do would very quickly pay back the cost . That was true . But what I didn’t anticipate was that I saved a number of marriages . The staffers were still hunched over their machines , but at least their wives could see their backs ! ” In effect , these terminals were the first “ home computers ” — a notion that would percolate through the computer community for another decade , to emerge in a new guise from the garages of Silicon Valley .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5801</div><div class='noteText'>Corbató and his team were doing their best to work the bugs out of CTSS as they went along , getting the system to the point where it became downright usable . In fact , they would continue that effort well into 1965 , eventually adding some fifteen thousand lines of computer code . And along the way they would produce what was arguably the most influential single operating system in computer history . Simply because they were the pioneers in time - sharing , says Corbató , “ we knew we were laying down a pattern that would probably be emulated and imitated . Indeed , that is the way it worked out . ” CTSS’s fundamental model of human - computer interaction — the notion of a user’s sitting down at a keyboard and having a set of commands at his or her disposal — can still be found today at the heart of MS - DOS , Windows , Macintosh , Linux , and many other operating systems . So can such innovations as CTSS’s “ hierarchical ” file system , a scheme devised by Corbató and his team to enable individual groups and individual users to organize their personal files into “ directories ” and “ subdirectories ” on the 7094 ’ s hard disks . ( In modern - day Windows and Macintosh systems , of course , such directories are called folders . )</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5824</div><div class='noteText'>And yet , says Fano , as gratifying as all that was , it was really nothing more than what they’d expected based on the electric - power analogy . Give people something useful , and they’ll use it . What he found truly fascinating , though , was the second great lesson of time - sharing : in an information utility , the power flows both ways . Unlike a power utility , which basically just provides a resource that people consume , an information utility lets the users give back to the system . It even lets them create whole new resources in the system . “ More than anything else , ” says Fano , “ the system became the repository of the knowledge of the community . And that was a totally new thing . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5829</div><div class='noteText'>Once again , the credit had to go to Corbató’s CTSS . No matter how frustrating the operating system could be , CTSS did have one great thing going for it : Corbató had designed it as an open system , in the sense that users could modify it , tailor it , and extend it however they wanted . As Corbató himself said , “ This open system quality . . . allowed everyone to make the system be their thing , rather than what somebody imposed on them . ” 22 To achieve that quality , Corbató had designed CTSS as an inner core of lower - level functions surrounded by an outer periphery of higher - level commands . The core took care of chores such as reading and writing data to the disk , interpreting user commands , and shifting the machine’s attention millisecond by millisecond from one user to the next — the time - sharing equivalent of unconscious functions such as heartbeat , breathing , and digestion . Corbató and his team took direct responsibility for that part of the system and worked hard to keep it as simple and as comprehensible as possible . “ I was always conscious of how we would explain this to a newcomer in a way where he could understand it quickly , without having to read a manual , ” he said . 23 The periphery , meanwhile , was the user’s software toolbox , the collection of programs that he or she could invoke to rename a file , say , or print out a list of files in a directory . And it was here that creativity reigned . Users could write whatever new software tools they needed for the task at hand . If enough other users liked it , too , it would be placed in the public library ; in effect , it would become a part of CTSS itself . This was a golden opportunity , and the Project MAC community wasted no time before taking advantage of it . Graduate student Jerry Saltzer created the TYPSET and RUNOFF commands to write his thesis proposal ; together they constituted the rudiments of a word processor . “ Practically from the beginning , we started using them to publish all the Project MAC reports , ” says Fano .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5847</div><div class='noteText'>Even more popular was undergraduate Tom Van Vleck’s MAIL command , which allowed users to send text messages to one another — and which thus probably ranks as the world’s first implementation of E - mail . Meanwhile , there was Allan Scherr’s widely used ARCHIVE utility , which would take a bunch of little files and compress them into one big file , with a substantial saving in disk space . And there was the OPS , or the On - line Programming and Simulation system , created by Martin Greenberger and his students at the Sloan School in the fall of 1963 . It offered commands to simulate the stock market , handle accounting , do production scheduling , perform on - line modeling , and do all manner of other things .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5853</div><div class='noteText'>And so it went , leaving Fano and his colleagues to shake their heads in wonder at how fast the sociology of software had turned itself inside out . In the batch - processing world , Fano says , programming had generally been a do - it - yourself affair . Sharing a program with someone else would have meant duplicating a massive deck of punch cards , physically carrying the deck around , explaining how to format the input data on the cards , coaxing the program into running on an alien computer , and so on . Who had the time ? In fact , says Fano , “ in those days programmers never even documented their programs , because it was assumed that nobody else would ever use them . ” Now , however , time - sharing had made exchanging software trivial : you just stored one copy in the public repository and thereby effectively gave it to the world . “ Immediately , ” says Fano , “ people began to document their programs and to think of them as being usable by others . They started to build on each other’s work . ” Indeed , the very existence of that public data repository on the 7094 quickly transformed Project MAC’s central “ power plant ” into the intellectual center of the community . Through E - mail , the exchange of files , and the sharing of programs , it functioned as the town square , the village market , the Roman forum , and the Athenian agora all in one — the place where citizens gathered to talk , to gossip , to conduct business , to propose ideas , and then to argue until they came up with better ideas . Within six months of the system’s November 1963 startup , CTSS and the on - line environment it supported had become , at least in embryo , everything that would later be claimed for the on - line world of the Internet . In fact , it was even more than that . With more than half of its system commands now written by the users themselves , CTSS had proved to be just what Lick had been hoping for in his Intergalactic Network memo , and what Fano had predicted in the Project MAC proposal : a self - guided system .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5912</div><div class='noteText'>But in the early 1960s , with CTSS , Corbató and his colleagues had to pioneer fault - tolerant design even as they were pioneering time - sharing itself . For example , among their early innovations were “ firewalls , ” or software barriers that kept each user’s area of computer memory isolated from its neighbors , so that a flameout in one program wouldn’t necessarily consume the others . Another deceptively simple innovation was the introduction of a clock , which would ( for example ) allow the computer to grab control back from a user’s program if the program hit a glitch and locked up . This sounds obvious enough now , says Corbató , “ but people were very cavalier about time in the early days . Computers didn’t have clocks . There was no way to time - stamp files or to do something automatically after so many seconds . So in the very early days of CTSS , we used just an electronic time - of - day clock kludged in through the printer port . ” Still another innovation was that most elemental of precautions , the backup . “ We were forced into it , ” Corbató recalls , “ because a disk failed fairly frequently , the systems crashed a lot , and so you had to learn to think defensively . Once you start tinkering with a program and you no longer punch out cards [ for backup ] , which people had been used to doing , you are really trapped if the thing vanishes because you can’t re - create the details of even a week’s worth of work . ” So in the beginning , he says , the group spent two hours every day copying the entire disk file on tape . Later they automated the process : “ We had a little software demon that would run in the background , scavenging the disk to look for newly created files , ” says Corbató . “ We’d back files up within a half - hour of [ their ] creation , sometimes less . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5950</div><div class='noteText'>“ Passwords were just a first cut at security , ” according to Corbató . “ They were a reminder to people that if they tried to trick their way past the passwords , they were doing something wrong . ” They were also a reminder that you weren’t just an anonymous set of fingers typing on an anonymous remote terminal . Once you entered that password , says Corbató , the system knew you as a person , a specific human being with a specific identity , responsible for everything you did on - line . Fano backed Corbató wholeheartedly on the password issue . When users complained , the Project MAC director’s standard reply was , “ How would you like someone to write a paper before you , using your material ? ” 26 ( This wasn’t a hypothetical question ; there were several instances of research material’s being stolen at Project MAC , both from offices and from the time - sharing system itself . ) Nonetheless , with Corbató’s attempt to impose a modicum of social order on cyberspace , Project MAC had crossed over from technology into politics , thereby sparking a debate on freedom versus responsibility that was strikingly similar to the one that would roil the Internet in the 1990s . Along the way , prophetically , Project MAC spawned yet another new phenomenon : the hacker as jokester , vandal , and thief .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5970</div><div class='noteText'>To the hackers and their allies , it was all a matter of striking a blow for the People against the System . This was the beginning of the sixties , after all , and the information - wants - to - be - free culture of the hackers had a good deal in common with the property - is - theft counterculture that was just starting to emerge in the outside world . To Corbató , such behavior just proved his point : “ We really did have in mind to build the prototype of . . . a computer utility , ” he says — one that really would be as open , as simple , and as easy to work with as possible . But he and his colleagues also knew that if it was going to make a real difference in the world , this new thing they were creating would have to survive being used by real , fallible human beings . And in order for that to happen , the technology would have to reinforce such unfashionable values as courtesy , trust , and responsibility — not undermine them . The passwords stayed .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 5990</div><div class='noteText'>Finally , she says , even Lick had to admit that it was getting ridiculous . “ Well , ” he suggested , “ I’ve got lots of wall space in the Pentagon . I’ll put some of them up there . ” That had brought a certain peace on the subject . But it was not long after that that Lick had come home chuckling . He’d been working , he explained as he and Louise sipped their drinks , and it had gotten to be later than it should be . As he was finishing up , in fact , he could hear the cleaning woman in the hall . So he opened the door . “ Oh , I didn’t know you were here ! ” she apologized , and turned as if to go . No problem , Lick assured her , saying that he was just about to leave anyway , and urging her to go on with her work . “ You know , Dr . Licklider , ” she said as she was bringing in her brooms and dust cloths , “ I always leave your room till last because I like to have time by myself , with nothing pressing , to look at the pictures . ” Well , Lick told his wife , he was so touched by that that he stayed for a while . He and the cleaning lady went around to the various pictures and talked about them — the play of light , the colors , how they made you feel . Which one do you like best , he asked her ? And to his enormous delight , she chose one by Cézanne , his favorite artist . So , to her enormous delight , he gave it to her . And that was why he was chuckling , Lick told Louise . The thought had struck him on the way home : Computers for the brasses - art for the masses . It one of those lame bits of wordplay that he was forever coming up with . But somehow , something about this one seemed to strike him as hilariously apt . Computers for the brasses — art for the masses .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6044</div><div class='noteText'>At RAND , meanwhile , Lick was allowing the interactive - computing group to learn from its own mistakes — or so he thought . He was dubious about the RAND group’s approach to the electronic “ tablet ” it was designing for freehand drawing and ( eventually ) handwriting input . The user was supposed to write with a pencil - like stylus down here , on the horizontal tablet , yet the digital “ ink ” would appear only up there , on a vertical CRT screen ; the veteran human - factors researcher was convinced that the disconnect would make hand - eye coordination impossible . ( Lick would later have the same concerns about the mouse . What he really wanted was a kind of smart paper — a computer you could physically write on . ) Nonetheless , Lick left the tablet development team free to try it their way — and within a year was back at RAND admitting his error . The group had shown that their “ ink ” did indeed provide enough feedback ; users could train themselves to write on the CRT display almost instantly . “ You were right , ” he told them . “ It works . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6057</div><div class='noteText'>Finally , Lick started funding Carnegie Tech at a rate of some $ 1.3 million per year , even though there were only three major computer researchers in the whole school — Allen Newell , Herbert Simon , and Alan Perlis — none of whom had any particular interest in interactive computing as such . To Lick that was far less important than the fact that Newell , Simon , and Perlis were all smart , tough , independent , and devoted to their own standards of excellence — in short , his kind of people . Moreover , the three men embraced the most expansive definition of their discipline imaginable . Just as botany is the study of plants , they declared in a widely quoted essay , 27 computer science is the study of “ the phenomena surrounding computers ” — all the phenomena , from the physics of integrated circuits and the analysis of algorithms to human interface design , the social ferment bubbling up around the ARPA - funded time - sharing systems , and the impact of information technology on human life in general . Newell and Simon even saw a big overlap between computer science and human cognitive psychology . They had based the design of General Problem Solver , their next program after Logic Theorist , on data gathered from human subjects working on puzzles and games in the lab . And when they later came to publish a retrospective of their research with the program — a 920 - page tome that is now considered a landmark in both AI and cognitive psychology — they would call it Human Problem Solving . 28</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6070</div><div class='noteText'>Perlis , for his part , had already taken the lead in creating computer science as an organized discipline : computing , he argued , was such a novel and complex endeavor that no existing discipline could cover it all . Indeed , he lived that argument . At one point in the early 1960s Perlis was not only teaching Carnegie Tech’s programming course but simultaneously serving as head of the university’s Computation Center ; chair of its mathematics department ; president of the leading professional society , the Association for Computing Machinery ; and editor of that organization’s widely read magazine , Communications of the ACM . In 1965 , moreover , when Carnegie Tech became one of the first universities to organize a separate department of computer science , Alan Perlis would be made the chairman of that . His energy seemed inexhaustible .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6113</div><div class='noteText'>What saved them was an unexpected offer of support from Bob Taylor at NASA . And no one was more surprised by it than Engelbart himself . Long before , he had visited Taylor at the space agency’s headquarters to drop off copies of both “ Framework ” and his proposal . But that , as far as he was aware , had been the end of it . What Engelbart didn’t know was that Taylor had been enchanted by “ Framework ” and had spent the intervening time drumming up support for the project within NASA . Engelbart might or might not be able to make any of his ideas work , Taylor had argued , but he was definitely headed in the right direction . It was an argument that had obviously proved effective ; for many years afterward , Engelbart’s Augmented Human Intellect Research Center would be supported jointly by NASA and ARPA ( and later by the air force as well ) . But the more immediate effect was that he was able to get the equipment he needed , starting with a much more capable computer . Just as important , he was able to get the staff he required , including such notables as Bill English , who joined the project in early 1964 as chief engineer and turned out to have a genius for turning Engelbart’s high - flying abstractions into working hardware . Together they were able to start work on the first version of what they came to call NLS , a slightly skewed acronym for oN Line System .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6131</div><div class='noteText'>But in that initial version of NLS , which the group started working on in early 1964 , the big innovation was to have the computer write the text to a CRT display instead of on a standard typewriter terminal . Such displays were fabulously expensive in 1964 , but Engelbart figured that by the time his group had really worked out how to use them , their price would have fallen considerably . And there was a surprising amount to learn . If nothing else , there was the 2 - D factor — that is , the fact that the computer would now be displaying whole chunks of a file at once , not just one character or one line at a time . So to insert a piece of text , say , you first had to tell the computer exactly where on the screen you wanted it to go . “ We needed a screen selection device , ” Engelbart wrote in his account of the SRI years . “ I wanted to find the best thing that would serve us in the context in which we wanted to work — text and structured items and interactive commands . ” 31 He and his team experimented with every device they knew of — trackballs , light pens , joysticks — but Engelbart wasn’t happy with any of them . So they got more adventuresome , experimenting with foot - operated controls , knee - operated controls , even head - operated controls ( a nod would make the on - screen cursor move vertically , and a glance to the side would make it move horizontally ; users tended to get terrible neck cramps ) . Engelbart still wasn’t satisfied . Finally , as they were all sitting around brainstorming one day , Engelbart came up with the idea of a little gadget that the user could roll around on the desktop with one hand while the cursor tracked its motion on the screen . Since it didn’t seem any sillier than some of the other things they had tried , Bill English went off to the SRI machine shop and made one . It was essentially just a block of wood about the size of a pack of cigarettes , with some rollers set into the bottom and a wire coming out the front end to communicate the motion of the rollers to the computer . Engelbart wasn’t totally satisfied with this contraption , either . And yet when the NLS team hooked up all the selection devices to their computer and gave users a choice , they discovered that people were consistently choosing the little gadget . The preference was so strong , in fact , that they eventually abandoned everything else ; the gadget had become their standard . And by that time , of course — though no one on the SRI team can now remember when , or how , or why it started — they had all taken to calling the thing a mouse . It was more of a joke than a name , really . They would surely find a more dignified term in time . But until then , well , it just seemed to fit .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6138</div><div class='noteText'>He and his team experimented with every device they knew of — trackballs , light pens , joysticks — but Engelbart wasn’t happy with any of them . So they got more adventuresome , experimenting with foot - operated controls , knee - operated controls , even head - operated controls ( a nod would make the on - screen cursor move vertically , and a glance to the side would make it move horizontally ; users tended to get terrible neck cramps ) . Engelbart still wasn’t satisfied . Finally , as they were all sitting around brainstorming one day , Engelbart came up with the idea of a little gadget that the user could roll around on the desktop with one hand while the cursor tracked its motion on the screen . Since it didn’t seem any sillier than some of the other things they had tried , Bill English went off to the SRI machine shop and made one . It was essentially just a block of wood about the size of a pack of cigarettes , with some rollers set into the bottom and a wire coming out the front end to communicate the motion of the rollers to the computer . Engelbart wasn’t totally satisfied with this contraption , either . And yet when the NLS team hooked up all the selection devices to their computer and gave users a choice , they discovered that people were consistently choosing the little gadget . The preference was so strong , in fact , that they eventually abandoned everything else ; the gadget had become their standard . And by that time , of course — though no one on the SRI team can now remember when , or how , or why it started — they had all taken to calling the thing a mouse . It was more of a joke than a name , really . They would surely find a more dignified term in time . But until then , well , it just seemed to fit .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6160</div><div class='noteText'>At issue was the next step in their long - range plan : the creation of an industrial - strength time - sharing system to replace CTSS . Granted , says Corbató , they ultimately got CTSS working fairly well , and they could have gone on tweaking it and adding things to it forever . But it was still fundamentally a kludge , with patches on top of patches on top of a batch - processing operating system that ran on a computer never designed for time - sharing . ( Anyone who ever struggled to run Windows 3.1 on top of MS - DOS will understand the feeling . ) From the beginning , their intention had been to follow it up with a system that would be done right , that would be built around the notion of time - sharing from the ground up . Multics , as this hypothetical system came to be known — short for MULTiplexed Information and Computing Service — would have the ability to run without interruption , spreading its workload over multiple processors so that one would always be ready to take charge if another went down . Like a power utility , the information utility would be available to users day and night . Multics would also have a bulletproof , hierarchical file system so that nothing would ever inadvertently disappear . And it would have built - in security : firewalls , passwords , private directories — the works . Planning for Multics had begun right after the 1963 summer study , with a former Burroughs engineer named Ted Glaser as chief designer . “ He was blind , but an amazing systems architect , ” says Corbató . “ We worked together hand and glove . ” However , the actual programming of Multics wouldn’t get under way until 1965 . In the interim , the group was absorbed by a much more urgent task : finding a computer for Multics to run on .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6190</div><div class='noteText'>MIT had been tight with IBM since the old Project Lincoln days , when the company won the contract to build the SAGE computers . IBM had provided the succession of high - end number - crunchers at the Computation Center , not to mention the souped - up 7094 at Tech Square . IBM’s director of research , Emmanuel Piore , was a veteran of the Rad Lab and RLE , and Fano had made a point of keeping in close touch with him . “ Very early in the planning of Project MAC , ” Fano would write in a June 29 , 1964 , report to MIT president Julius Stratton , “ before a formal proposal was presented , I went to New York to consult Dr . Piore . One of the first copies of the formal proposal to ARPA was mailed to him and he had been constantly kept informed , either directly or indirectly , of the progress and plans of Project MAC . IBM was strongly represented , more than any other manufacturer , among the invited participants to the 1963 Project MAC Summer Study . There is no question that IBM has had a substantially better opportunity than any other manufacturer to become familiar with our work and to understand our objectives at both the managerial and working levels . If there is a misunderstanding of our objective , I am sure it is not our fault . ” 33</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6201</div><div class='noteText'>It was true that IBMers at every level had been friendly and cooperative with the Project MAC team ; MIT was a “ prestige account , ” with a public - relations value to the company that far exceeded the actual dollar value of the machines installed there . It was also true that some IBMers seemed genuinely enthusiastic about what ARPA and Project MAC were trying to accomplish . Nat Rochester at the IBM research lab was a notable example , as were some of the engineers who had helped with the modifications on the project’s 7094 . Nonetheless , Corbató and his colleagues approached the computer giant with decided ambivalence . They couldn’t shake the sense that they were being patronized , that the vast majority of IBMers still regarded time - sharing as academic self - indulgence having no relevance to the real job of computing , which was to build better batch processors . The steadily increasing stream of visitors to Project MAC had included not a single top executive from IBM . “ I think they were very slow in the company to recognize the need for genuine system research , ” says Corbató . “ The exploration of different kinds of designs was not being done ; they thought it was a closed question of how to build machines . They did not recognize that it was an open question . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6246</div><div class='noteText'>Now , the MIT team thought this doubling trick was kind of neat , and it certainly simplified the hardware engineering . But once they began to understand what it meant for software , it became all too clear that the rush to announce the new system had taken its toll . “ An extremely awkward system to program , ” they later called it in their report . “ The entire system is very poorly meshed together . [ All major design decisions have been ] subservient to the demand that the machine language be compatible with the language appropriate for the smallest machine . In spite of this demand , even here the struggle was so great that they did not succeed and many subtleties exist which prevent programs from operating identically on all processors . . . . Finally , the design is an extremely difficult one to learn because of the Byzantine - like detail , exceptions , and ad hoc solutions that exist throughout . ” 34 Building Multics was going to be hard enough in any case ; building it for System / 360 would be a nightmare .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6247</div><div class='noteText'>“ An extremely awkward system to program , ” they later called it in their report . “ The entire system is very poorly meshed together . [ All major design decisions have been ] subservient to the demand that the machine language be compatible with the language appropriate for the smallest machine . In spite of this demand , even here the struggle was so great that they did not succeed and many subtleties exist which prevent programs from operating identically on all processors . . . . Finally , the design is an extremely difficult one to learn because of the Byzantine - like detail , exceptions , and ad hoc solutions that exist throughout . ” 34 Building Multics was going to be hard enough in any case ; building it for System / 360 would be a nightmare . That wasn’t the worst of it , though . “ All through their design , ” they wrote , “ both in hardware and in programming , [ the IBM engineers ] seem to have taken the view that a system is a static thing which is only created once and never modified . ” In particular , IBM had built in the assumption that each computer would have one and only one processing unit sitting at its center like a spider in a web , with all the memory banks and input - output equipment feeding into it . And indeed , for most business applications , that assumption was perfectly adequate . For the Project MAC representatives , however , it was wrongheaded on two counts . First , because they wanted to create an information utility that would be able to grow and evolve in ways they could not anticipate , they needed a machine that could operate with many central processing units at once . Not only would this greatly enhance reliability — since if one processor failed , the others could keep the system running — but it would provide a natural path for expansion : you could just add more processors .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6254</div><div class='noteText'>That wasn’t the worst of it , though . “ All through their design , ” they wrote , “ both in hardware and in programming , [ the IBM engineers ] seem to have taken the view that a system is a static thing which is only created once and never modified . ” In particular , IBM had built in the assumption that each computer would have one and only one processing unit sitting at its center like a spider in a web , with all the memory banks and input - output equipment feeding into it . And indeed , for most business applications , that assumption was perfectly adequate . For the Project MAC representatives , however , it was wrongheaded on two counts . First , because they wanted to create an information utility that would be able to grow and evolve in ways they could not anticipate , they needed a machine that could operate with many central processing units at once . Not only would this greatly enhance reliability — since if one processor failed , the others could keep the system running — but it would provide a natural path for expansion : you could just add more processors . With the System / 360 design , by contrast , there would be no way to upgrade without replacing the whole computer . Second , because the job of coordinating all those processors would have to be handled by Multics itself , which would reside in the computer’s memory banks , Corbató and his colleagues were looking for a “ memory - centered ” architecture . Trying to make the processor - centered architecture of System / 360 work in that fashion seemed like an exercise in futility . “ We were stupefied , ” says Corbató , “ because it was apparent that we were watching a locomotive speeding down the tracks . Nothing we could say or do would cause them to deviate from what they were doing . They had too much at stake . They were not able to change [ System / 360 ] , or were unwilling to change it . And to some extent , they didn’t believe that what we were trying to do mattered that much anyway . ” The upshot was that Corbató , Glaser , Dennis , and Graham politely thanked their hosts for the information and quietly made plans to look elsewhere .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6305</div><div class='noteText'>At the Control Data Corporation in Minneapolis , a six - year - old firm that was then making quite a splash in the scientific number - crunching market , chief designer Seymour Cray walked out of the MIT group’s presentation in contempt . “ We found similar attitudes in most hardware designers , if not quite so extreme , ” says Corbató . “ They all had their own vision of what a computer ought to be , and that didn’t include the social environment of [ multiple ] people trying to use the computer all at once . They really didn’t want to be bothered with somebody introducing new ideas . ” It was beginning to look like IBM or nothing .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6345</div><div class='noteText'>They came back with stars in their eyes : the GE 635 , as it was known , was remarkably close to what they were looking for . Just as important , the company was remarkably receptive to a partnership . “ When we visited GE , ” says Jack Dennis , “ the responsible engineer [ for the GE 635 computer ] was John Couleur , who understood the nature of what we expected from the hardware and realized that the 635 was as close as anything in the industry to it . He was willing almost immediately to start thinking about how they could make the machine better for us , which was very different from IBM’s approach . ” The news put stars in Corbató’s eyes as well . “ They were naive and we were naive , ” he says with a laugh , looking back on his younger self . “ We all thought we could do more than we could . ” Nonetheless , he and Fano could now meet with Piore on May 11 feeling confident that IBM was no longer the only game in town . “ I made a point to convey this fact to Dr . Piore , ” Fano wrote , “ of course without mentioning the company’s name because some of the information I had was still regarded as company - confidential . ” Piore apparently believed that Fano’s alternative was DEC , a company he would have had trouble taking seriously . Nonetheless , he took Fano’s point ; until that moment , he had assumed that the Project MAC account was in the bag . As Fano would later explain to Stratton , Piore immediately ordered his subordinates “ to see to it that an appropriate team would get to work immediately on a specific proposal to meet Project MAC’s needs . ” And that was what happened . In early June , a team of IBM engineers camped out at Project MAC for a week , talking to everybody . Then they disappeared until June 23 , when they submitted their formal proposal . It was the disaster the MAC group had been braced for all along , says Corbató : more of the same , warmed over . Once the IBMers realized they had a competitor , he says , “ their immediate reaction was , ‘ We have got to save this account . ’ But that was one of the problems : they kept thinking of us as an account rather than as a coparticipant in a new kind of product . That reflected the marketing viewpoint of the company . As a result they ordered all the engineers to do something to make MIT happy . So what they did was build a Rube Goldberg — like offering , which they then priced accordingly — namely , pretty high . But what they were shoving at us was just hopelessly flawed , starting with some deep design decisions that had been made inside the 360 . They had been misled by their senior designers to believe that the 360 was good for everything . That just wasn’t true , but the company wanted to believe it . Yet the only way to satisfy us would have been to embark on a new product design which was different from the 360 . So we got into this impasse . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6375</div><div class='noteText'>And within the first decade or so , it would become clear that the introduction of System / 360 had been one of the watersheds of computer history — the beginning of an era that would see computers integrated into every major corporation and every major government operation in the industrialized world . The Dwarfs would prosper as well , of course . But System / 360 and its successors — most notably System / 370 , in 1970 — would become de facto standard architecture for mainframes well into the 1990s , in much the same way that the Macintosh and IBM PC would later become the standard architectures for personal computers . ( Indeed , they would even inspire a market for “ clones , ” work - alike mainframes from other manufacturers . ) And of course , System / 360 would popularize such terms as “ byte , ” along with the convention of encoding data eight bits at a time .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6385</div><div class='noteText'>At the announcement , in April , IBM had promised that the first version of OS / 360 would be available by the end of 1965 , and that through the selective omission of various bells and whistles , it would run on System / 360 processors with as little as sixteen kilobytes of memory . By summer , however , with the programmers falling further and further behind schedule every day , it was clear that the planners had grossly underestimated the magnitude of the task . Indeed , OS / 360 would eventually go down in history as one of computerdom’s classic horror stories , just as project chief Fred Brooks’s rueful meditation on the lessons he’d drawn from that experience , The Mythical Man - Month , 41 would go down as one of the classics of the software - engineering literature .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6429</div><div class='noteText'>In the long rebellion against batch processing , and against the authoritarian mind - set that went with it , Project MAC’s break with IBM was about as close as things ever got to open warfare . Yet J . C . R . Licklider — the commander in chief , so to speak — kept his distance from the fray . The choice of a next - generation computer was Tech Square’s to make , he felt . And besides , why get involved with that battle when he was preparing to infiltrate the enemy lines all by himself ? In mid - 1964 , at about the same time that Fano and company were deciding on the GE 635 , IBM chief scientist Mannie Piore had invited Lick to join IBM’s research division , headquartered at the new Thomas J . Watson Research Center in Yorktown Heights , New York . And Lick had accepted .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6454</div><div class='noteText'>While all these considerations undoubtedly influenced Lick , however , what really seems to have persuaded him was the opportunity : at IBM he could preach the gospel of interactive computing in the very high temple of batch processing . If he could convert IBM to the cause , he often rhapsodized to Louise — if he could get even a fraction of that immense marketing power behind the vision of human - computer symbiosis — then he would be one giant step closer to converting the world .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6462</div><div class='noteText'>Lick was well aware , though , that his own successor was going to have exactly as much freedom as he himself had had — which meant that he had to get the right person in place , or his whole movement could collapse . Fortunately , one of ARPA’s traditions was that outgoing office directors were allowed to recruit their own successors ; all Lick had to do was to come up with an experienced , senior person with good credentials , and everybody would be happy . So Lick , characteristically , nominated a totally inexperienced and very junior candidate whose credentials were about the most awkward and inconvenient conceivable in the Pentagon . He was a skinny , intense fellow named Ivan Sutherland . He was twenty - six years old . And at the time he was a first lieutenant in the army . It wasn’t that he hadn’t tried to find someone more senior , Lick protested in his 1988 interview ; it was just that the answers he’d gotten ranged from “ No ! ” to “ Hell , No ! ” “ Most of my colleagues would much rather spend the government money doing research back in the lab than coast another year or two or three in Washington , ” he said . Still , you have to wonder how hard Lick really did try ; the truth was , he’d had his eye on Lieutenant Sutherland for a long while . When they’d first met , the younger man was still an MIT graduate student finishing up his Ph.D . work under Claude Shannon . The subject of his dissertation was a computer graphics program he had created on the TX - 2 computer out at Lincoln Lab . Sutherland called it Sketchpad . Now , Lick had always loved graphics . Indeed , he considered high - resolution graphics to be as critical to human - computer symbiosis as communications or even real - time interactivity . Humans are visual animals , he would muse to anyone who would listen . Our eyes are “ a high - bandwidth data channel ” capable of absorbing information at the equivalent of millions of bits per second . Our brains are organized to recognize patterns and sense complex relationships at a glance . In fact , as Lick told Oliver Selfridge and Marvin Minsky over dinner one evening , he felt that once they got time - sharing working well , ARPA’s next two major initiatives should be graphics and networking . That was why he had funded the RAND Tablet , and why he had been so adamant that the Kludge and other graphics applications be included in Project MAC . But Sketchpad had been a revelation . “ In 1962 , ” Lick would later write , “ at the Spring Joint Computer Conference in San Francisco , during the discussion period of a session on man - computer communication chaired by Douglas Engelbart , Ivan Sutherland mentioned his Sketchpad program and , at the end of the session , showed to a few lingering enthusiasts the most dramatic on - line graphical compositions that any of them had ever seen . ” 42</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6487</div><div class='noteText'>To modern eyes Sketchpad would look quite familiar — like a computer - aided design system , perhaps , or a high - end drawing package . But that’s only because Sutherland himself single - handedly pioneered most of the techniques that are now used in such programs . Touch two points on the TX - 2 ’ s little display screen with a light pen , and the computer would draw a straight line between them . Draw a rough curve with the pen , and the computer would “ correct ” the curve and smooth it out . Indicate that two components were attached at a given point , and the computer would ensure that they stayed that way , no matter how you moved or rotated them .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6512</div><div class='noteText'>As tangible output , one Teletype terminal wasn’t much , perhaps . But then , Lick never claimed to have accomplished much at ARPA — certainly not much that he could actually take credit for . “ I went for one year and stayed for two , ” he said in his 1988 interview , “ and the time scale for doing anything significant is longer than that . So I had to buy into things and finish them and make them demonstrable , so that there would be something for people to look at without realizing that I didn’t do them . ONR [ the Office of Naval Research ] had had Corby [ Corbató ] started on the time - sharing system and the Computation Center , and then we came along and greatly increased the speed with which that project was going . But we could never have started it and gotten it going . Berkeley hadn’t started time - sharing , but they had a laboratory and a computer and everything else , so the time - sharing part was relatively simple . They had a time - sharing system [ Project Genie ] running before I left . The SDC time - sharing system ran before I left Washington , but they had a hundred or two hundred programmers working before I got there . We were just responsible for channeling that a bit . So I think that there’s nothing I can point to with pride and say , ‘ I did that . ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6524</div><div class='noteText'>“ When you look at Lick’s legacy , two very distinct things stand out , ” says Bob Fano . “ One is that he was a very imaginative , creative psychoacoustics man . That’s the first part of his history , and you shouldn’t overlook that . ” Because Lick had come to computing from psychology , Fano explains — instead of through mathematics and engineering , like almost everyone else — he instinctively saw computers in relation to the workings of the human brain , rather than as an exercise in pure technology . And that , in turn , was why he was so quick to embrace computers as a way of enhancing human creativity and enriching human life . “ It was a vision of man - machine interaction that was often unhampered by practical realities , ” says Fano , who had many an argument with Lick on that very point . “ But he really had an understanding of the role the computer could play . ” Second , says Fano , when Lick was presented with a miraculous , never - to - be - repeated opportunity to turn his vision into reality , he had the guts to go for it , and the skills to make it work . Lick had the power to spin his dreams so persuasively that Jack Ruina and company were willing to go along with him — and to trust him with the Pentagon’s money . Once he had that money in hand , moreover , Lick had the taste to recognize and cultivate good ideas wherever he found them . Indeed , the ideas he fostered in 1962 would ultimately lay the foundations for computing as we know it today . The time - sharing technology he pushed so relentlessly would turn out to be the evolutionary ancestor of both personal computing and local - area networking , as well as a test bed for all the issues of on - line social behavior that would reemerge a generation later .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6539</div><div class='noteText'>Perhaps most important of all , however , Lick had the patience to take the long view . He couldn’t get it all done in one year , or two years , or a lifetime . But by creating a community of fellow believers , he guaranteed that his vision would live on after him . When he arrived at ARPA , in October 1962 , there was nothing more to “ symbiotic ” computing than a handful of uncoordinated development efforts scattered all across the country ; by the time he left , in September 1964 , he had forged those efforts into a nationwide movement that had direction , coherence , and purpose . Moreover , by putting so much of the agency’s money into research at universities , where most of it actually went to support students , he neatly co - opted a substantial portion of the rising generation . “ It seems to me that Licklider and ARPA were mainly about winning the hearts and minds of a generation of young scientists and convincing them that computer science was an exciting thing to do , ” says James Morris , chair of Carnegie Mellon’s computer science department . “ Remember , in the aftermath of Sputnik , the glamour field was physics , not computing . Lots of very smart people made a career decision to go into a field that didn’t exist yet , simply because ARPA was pouring money into it . ” Indeed , in his 1988 interview , that was the one accomplishment for which Lick was willing to take credit : “ I think that I found a lot of bright people and got them working in this area , ” he said . “ I got it moving . [ And it was ] a fantastic community . I guess that’s the word . It was more than just a collection of bright people . It was a thing that organized itself into a community , so that there was some competition and some cooperation , and it resulted in the emergence of a field . ”</h3>
<h2 class='sectionHeading'>Chapter 7:      The intergalactic network</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6621</div><div class='noteText'>The two men hit it off immediately . They were both southern boys , after all . They were both the only children of ministers . They had the psychoacoustics background in common . They even shared a passion for automobiles . “ Lick owned a Messerschmitt three - wheeled vehicle for a while , ” Taylor recalls , laughing . “ He enjoyed unusual cars . ” But most important , they shared a passion for human - computer symbiosis . Robert W . Taylor was easily the most enthusiastic disciple J . C . R . Licklider ever had in Washington , if not in the entire country . It was Taylor who pulled out all the stops to get NASA funding for Doug Engelbart . It was Taylor who put NASA money into a number of specific efforts within Project MAC — and even funded a study of interactive , computer - assisted air - traffic control at BBN . And it was Taylor who was brought over to ARPA in early 1965 — on Lick’s enthusiastic recommendation — to serve as a deputy to Ivan Sutherland .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6642</div><div class='noteText'>Sutherland was also expanding the ARPA orbit to encompass his mentor from the TX - 2 days , Wesley Clark , who had at last led his team to a permanent home at Washington University in St . Louis . ( The fact that it was J . C . R . Licklider’s alma mater was pure coincidence ; Clark and his coworkers on the LINC project had found their Promised Land only after two years of wandering in the wilderness , with a brief , tumultuous stop at MIT . ) Happily , they had thrived there . Soon after arriving , in 1964 , they had completed development on their LINC desktop laboratory computer and started to get the machines out into the hands of working scientists ( eventually there would be some twelve hundred LINCs controlling experiments in laboratories around the world , including a commercial version manufactured by DEC ) . And with funding from Sutherland , they had embarked upon an effort to develop “ macromodules , ” a series of electronic building blocks that would allow users to assemble and reconfigure specialized interactive computers as needed . This was what took Sutherland and Taylor out to St . Louis in 1965 for a site visit . And it was there , Taylor remembers , that he got his first good look at the LINC . It was a revelation . Clark and his followers were as adamant as ever that the real future of interactive computing lay not in time - sharing , which they regarded as a lamentable mistake , but in individualized computing , wherein everyone would have a computer of his or her own . The LINC was their prototype . And in using it , says Taylor , he finally began to understand what they were driving at . “ When I sat down at the LINC it had a little six - inch green and white display that looked like an oscilloscope , and a knob that let you adjust the speed of the machine . So you could turn up the speed , type an A on the keyboard , and the A would appear on the screen very quickly — the A was made of dots , like a dot - matrix printout — or you could turn the speed down , and the A would build up very slowly . Also , you had a loudspeaker : the machine would click slow or fast according to what it was doing . So you had a sense of scale . You could see that this machine was building up a complicated reality through millions and millions of yes - no decisions . ” For the first time , he says , he could really feel the interactivity . “ A Teletype was one kind of interaction , ” he says . “ Spacewar was another . E - mail was still another . But the LINC was somehow more dynamic than any of them . So I’m saying to myself , ‘ If something like this could be this entertaining and exciting all by itself , just imagine what it would be like if numbers of folks could have it . Then they could be playing together in this medium . ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6665</div><div class='noteText'>Yet Taylor had increasingly come to believe that communication was the heart of human - computer symbiosis — as important as , or perhaps even more important than , interactive computing per se . The on - line communities that had sprung up around the time - sharing systems at SDC , Berkeley , and Project MAC absolutely fascinated him . “ As soon as each time - sharing system became usable , ” says Taylor , “ the individual people who were interested in computing began to know one another . They began to share a lot of information , and to ask of one another , ‘ How do I use this ? Where do I find that ? ’ It was really phenomenal to see this computer become a medium that stimulated the formation of a human community . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6688</div><div class='noteText'>Wasn’t that the whole point of ARPA , after all — to invest in research that could change the status quo by an order of magnitude ? Lick had made that kind of investment with time - sharing . Sutherland had done it with the Illiac IV and his initiatives in computer graphics . So what was Bob Taylor going to do ? Networking , obviously . But the question was , how ? Should he just go the standard route and put money into small - scale networking experiments scattered around the country , with maybe a pilot project or two ? Not a chance . For one thing , Lick had already gone the small - scale route with the networking experiment he funded at UCLA , where three computer centers were supposed to link up into a campus - wide community . Sutherland had enthusiastically continued that experiment . And they had all watched in disgust as the project fell victim to academic bickering : none of the three UCLA centers really wanted to work with the others , and certainly none wanted to take direction from ARPA . Then , too , IPTO had just finished up a second experiment demonstrating that long - distance networking was technologically feasible , if damnably difficult . In the fall of 1965 , Taylor and Sutherland had commissioned an experimental hookup linking the TX - 2 computer at Lincoln Lab to the Q - 32 computer at SDC in Santa Monica . With nothing more than an ordinary commercial line rented from Western Union , the bits had flowed — barely — and the computers had indeed talked to each other . So forget the experiments and pilot plants , Taylor decided ; he was the kind of guy who liked to drive fast , on the outer edge of being in control . If you’re going to do it , he reasoned , do it . Link all the IPTO contractors — all sixteen of them . Take interactive computing to the next level . Make computers into a medium for worldwide communication . Create an integrated ARPA community . Build the Intergalactic Network</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6715</div><div class='noteText'>The upshot was that Taylor’s pitch for a nationwide network was met with little more than cool politeness . Of course , being Bob Taylor , he insists that none of this fazed him . But even so , he was reassured to find that two of the most respected figures in the community were solidly behind him . One , surprisingly enough , was Wes Clark . The creator of the LINC stand - alone computer wasn’t particularly enamored of the network idea , not if it meant building some kind of vast , centralized time - sharing machine and forcing everyone to use it . But if it meant thousands or millions of machines linked to a nationwide communications system that would allow them to function as equals , then great ! Give all those machines some autonomy !</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6721</div><div class='noteText'>the only reason Lick hadn’t tried to build the Intergalactic Network himself was that the technology wasn’t ready when he was at ARPA . “ So when I told Lick what I wanted to do , he said , ‘ Go for it . ’ ” Indeed , says Taylor , he and Lick went through any number of bull sessions as they tried to imagine what people could do with such a network . On - line collaboration ? Digital libraries ? Electronic commerce ? The two of them had such a marvelous time that they wrote up their speculations as a joint article entitled “ The Computer as a Communication Device . ” 1</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6731</div><div class='noteText'>he would not only have to build up a brand - new organizational structure within IPTO to do it , but find a brand - new pot of money to pay for it . ( Although Taylor’s budget was a bit bigger than Licklider’s had been — at some $ 15 million per year — most of it was already committed to big - ticket projects such as SDC , Project MAC , and the Illiac IV . ) So there was no way around it . To get the extra money he needed , Taylor was going to have to go to the head of ARPA , the formidable Charles Herzfeld .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6750</div><div class='noteText'>In that kind of environment , under a different kind of director , ARPA’s little program in computer research might have vanished without a trace ( “ American boys are dying , and you’re spending money on mice ? ! ” ) . Fortunately , however , Herzfeld was not that kind of director . He did have to ask the various ARPA offices to “ help out ” wherever they could , which is why one office found itself developing laser - guided smart bombs , another went to work on acoustic sensors for monitoring troop movements on the Ho Chi Minh Trail , and so on . Nonetheless , through sheer bureaucratic bullheadedness , Herzfeld was able to keep such depredations to a minimum . He deeply believed in what ARPA stood for . And most especially , he believed in what the Information Processing Techniques Office was doing in computer technology . After all , he was something of a Licklider disciple himself : the two men had been the closest of friends and allies during Lick’s time there .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6773</div><div class='noteText'>Sutherland himself rated Larry Roberts as one of the smartest people he’d ever met . And indeed , to most observers it was a toss - up as to which of the two young men was the greater genius at computer graphics . As an MIT undergraduate in the late 1950s , for example , Roberts had discovered the TX - 0 shortly after Wes Clark and his group sent the machine down to campus in 1956 , and had promptly set to work devising a program to recognize handwritten characters using what would now be called a neural - network algorithm . It had worked quite well , considering the limitations of the hardware , and had served as the subject of Roberts’s first published research paper .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6789</div><div class='noteText'>Indeed , Roberts’s group at Lincoln Lab quickly emerged as the leader of Sutherland’s new computer - graphics initiative , much as Project MAC had become the flagship for ARPA time - sharing . Among other things , Roberts and his colleagues worked on what is now known as data visualization — the displaying of large masses of statistical data in visually meaningful ways — as well as graphical programming , or controlling a computer through drawings . ( After Sutherland left ARPA for Harvard , moreover , Roberts would start a collaboration with him on what would now be called virtual reality , complete with the world’s first 3 - D virtual headset . ) Ironically enough , it was the graphics research that finally triggered Roberts’s shift into networking — graphics , that is , plus a timely push from J . C . R . Licklider .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6867</div><div class='noteText'>Even with the TX - 2 and the Q - 32 making the connections automatically , said Roberts , “ the system was so slow , with so many restrictions , that we just couldn’t do all that we would have liked . ” Fortunately , he added , this was one problem that could be solved through the simple application of money : in effect , ARPA would make a series of massive long - distance calls and just never hang up . More precisely , the agency would go to AT &amp; T and lease a series of high - capacity phone lines linking one ARPA site to the next . A diagram of the resulting network would thus look something like a road map of the interstate highway system , with the leased lines corresponding to the highways , and the various ARPA computers that sat at the intersections or “ nodes ” of the network corresponding to the cities . Dial - up delays would be nonexistent in such a scheme because the computers would always be connected . A second conclusion was a bit more esoteric , said Roberts , but less of a surprise : digital messages could not be sent through the network as a continuous stream of bits . Instead , they would have to be broken into segments , with some fixed number of bits in each one ( think of a long letter written on a series of postcards ) . The problem was noise , he explained . Continuous signals were fine for voice communications , and even for logging into a nearby time - sharing computer through a modem . But continuous signals were not so effective for delivering bits across the country . The farther a message traveled , the greater the chances that one or more bits would be garbled by static and distortion on the line . And in the digital world , one erroneous bit might easily spell disaster .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6900</div><div class='noteText'>once you abandoned the telephone system’s “ circuit switching ” architecture for the network’s open - highway model , the packets most assuredly could get lost , and be left to wander through the network forever . One way to keep that from happening was a kind of Grand Central Terminal strategy : connect every machine on the new ARPA network to one gigantic computer in , say , Nebraska . That way the packets could flow straight in , get sorted , and then flow straight back out to their respective destinations . The “ highway map ” of the resulting network would just be a continent - sized star , with all the rays converging on that one central point . This Grand Central Computer scheme had a glaring drawback , however : one blown transistor and the machine could go down , taking the whole network with it . For that reason , said Roberts , his preferred alternative was a digital variation on the old “ store and forward ” technique used in the early days of telegraphy . ( Telegraph lines were so noisy that transmission was limited to short hops ; the clerks in each telegraph office had to write down messages as they arrived , then key them in again to send them farther down the line . ) The idea was to keep the complex , highway - map structure of the network , with lines running every which way and an ARPA site sitting at each intersection . But the individual sites would share routing responsibilities equally . That is , the computer at each site would first read the digital address on each packet as it came in . ( The packets would actually carry the digital equivalent of an entire bill of lading , with destination address , return address , error - checking codes , message identifiers , and so forth . ) Then the site computer would either accept the packet , if the address was local , or send the packet off again on the next stage of its journey . The result would be a network that operated collectively , with little or no central control . So in sum , said Roberts , that was the plan : full - time access , messages divided into packets , and distributed control . Now , who wanted to help ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6932</div><div class='noteText'>“ I was thrilled , ” Engelbart remembers . “ We had just been given the OK from ARPA to bring up a real time - sharing system at SRI , which meant that we could finally get multiple people working together . So at that point we were really oriented toward this ‘ groupware ’ idea . ” The new system would consist of a brand - new computer running a copy of the Project Genie time - sharing software developed at Berkeley . With it , Engelbart says , he wanted to explore on - line collaboration at every level . He envisioned on - line reference libraries , on - line address books , online technical support services , on - line discussion centers , on - line transcripts of decisions and debates — a massively cross - linked record of all the collective knowledge amassed by the collaborators over time . And as usual , his imagination didn’t stop with the different groups in an individual workplace . “ My whole thought was , How do we get a big community connected to experiment with ? Well , here we were at this meeting in Michigan , and oh gosh , they’re going to make one ! The other guys were negatively excited , but [ it ] was very exciting to me . ” So after listening to the grousing for a while , Engelbart got up and volunteered to make SRI the home of groupware — or , as it was later known , the Network Information Center ( NIC ) — for the net as a whole .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6956</div><div class='noteText'>Clark’s point was simple , once he’d caught his breath : all the PIs back there had been upset about the problem of programming their machines for the network because it really was a problem . Roberts was proposing to run the packets right through their main computers , which was like trying to run an interstate highway right through the main street of every little town in its path . All you’d get that way would be havoc in the towns and nonstop traffic jams on the highway . “ That was the wrong way to go about it , ” Clark remembers saying . “ So my idea was simply to define the network to be something self - contained . ” That is , make the ARPA network into the digital equivalent of a limited - access highway , with an “ interchange ” located just outside each town . Each of these digital interchanges would actually be a small computer , of course , separate from the main computer . But like its asphalt counterpart , the digital interchange would handle all the routing chores . It would provide an on - ramp to the network for new packets coming out of the main computer ; an off - ramp for incoming packets addressed to the main computer ; and traffic directions for packets passing through on their way to other computers . Now , said Clark , the beauty of this scheme was that it would simplify life for everybody . ARPA could take responsibility for designing and implementing the network proper — meaning the information highways and the digital interchanges — without having to worry that some contractor somewhere would mess up his site’s programming and thereby bollix up the whole system . And the contractors , for their part , could focus on one comparatively simple task — establishing a link from their central computer to the routing computer — without having to worry about all the ins and outs of all the other computers on the network . So , said Clark , that was the idea : small , independent routing computers . Roberts liked it . And not for nothing was Larry Roberts known as the fastest man in the Pentagon . By the time they got to the airport , his decision had been made : the ARPA network would be based on small routing computers à la Wes Clark . Interface Message Processors , they came to be called , or IMPs .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 6983</div><div class='noteText'>The story , as Scantlebury would explain it to the disconcerted Roberts later that day , was both ironic and sad . The irony was that Donald Davies had gotten his original inspiration when he was hosting a conference on time - sharing back in late 1965 and fell into an impromptu discussion about networking with J . C . R . Licklider and Roberts himself . Almost immediately after that , Davies had been struck by the notion that a store - and - forward system with very short message segments would be perfect . By June 1966 he had expanded this idea into a formal proposal , calling for a United Kingdom — wide digital network running at speeds of up to 1.5 megabits per second . This paper was where he introduced the concept of an “ interface computer , ” the equivalent of Wes Clark’s IMP , and coined the term “ packet ” to describe the message segments ( at that point Roberts and his ARPA colleagues were still calling the segments blocks ) . Davies’s name for the scheme as a whole was “ packet switching . ” From there , said Scantlebury , Davies and his group at Teddington had continued to develop the packet - switching idea with computer simulations . They had even scraped together enough money to build a “ one - node ” network , consisting of a single Honeywell computer connected to a lot of terminals through a special interface . It wasn’t much , admittedly . But it did demonstrate the switching principle : you could type in text on one terminal and have it print out on any other terminal you specified . And that , explained Scantlebury , was the sad part of the story : the powers - that - be at the British Postal Service , which had absolute control over the U.K . telecommunications system , had flatly refused to fund Davies’s vision of nationwide packet switching . They couldn’t even see the point of a demonstration . So , said Scantlebury , having gotten there first , the NPL group would now have to sit back and watch as the Americans did a packet - switched network for real . That hurt — and Roberts could certainly sympathize . Still , the frustrations weren’t personal . Scantlebury and his companions from the NPL group were happy to sit up with Roberts all that night , sharing technical details and arguing over the finer points . Take this business of the data rate , Scantlebury said at one point : why on earth are you bothering with a crummy 9,600 bits per second ? Why not slam them through at ten times that rate , or a hundred times ? The phone lines could handle it .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7011</div><div class='noteText'>While the NPLers were doing their homework , they had come across the work of an American who had — again — invented the packet network independently . Baran was his name ( pronounced to rhyme with “ Sharon ” ) — Paul Baran , out at RAND . Oops . Roberts knew Baran slightly and had in fact had lunch with him during a visit to RAND the previous February . But he certainly didn’t remember any discussion of networks . How could he have missed something like that ? As soon as he got back to the Pentagon , Roberts dug out the office copy of Baran’s final network design , which had been circulated as a RAND report in August 1964 , just before Roberts’s own shift to networking . The “ report ” proved to be a small library : eleven volumes that covered everything from routing algorithms to estimated cost . ( Two other volumes , dealing with cryptography and vulnerabilities to the network , were classified . ) Reading through it , Roberts found that Scantlebury was right . True , his plan and Baran’s did have many differences in technical detail , stemming largely from the fact that Baran had put more emphasis on digital voice communications than on computer communications . Moreover , their motivations were very different . Whereas Roberts was designing a civilian network that would connect the ARPA research centers , Baran had been after a nationwide command - and - control system that could survive a thermonuclear war . ‡ But Roberts could see that the essence of Baran’s network — packets , a decentralized architecture , computer routing — was the same as his . So why hadn’t Baran’s plan been adopted already ? Because it was too far ahead of its time , apparently . AT &amp; T engineers , most of whom had spent a lifetime perfecting their circuit - switching network , found Baran’s packet - switching concept ludicrous ( “ Son , ” Baran remembers one telling him with exaggerated patience , “ this is how a telephone works . . . ” ) . Worse , Pentagon politics dictated that the network would have had to be implemented by the newly organized Defense Communications Agency , which was also staffed by old - line telephone engineers and which simply did not have the technical competence to pull it off .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7087</div><div class='noteText'>Certainly Lukasik was intrigued by the network project , albeit for reasons that weren’t quite the same as Taylor and Roberts’s . “ Why did ARPA build the network ? ” Lukasik asks . “ There were actually two reasons . One was that the network would be good for computer science . We were going to share files , wire ourselves together , and so forth . Now , this rationale leads in a more or less linear way to the Internet as we understand it today . And it was true : this was by far the dominant reason among the researchers . But there was also another side to the story , which was that ARPA was a Defense Department agency . And after Eb [ Rechtin ] came in , defense relevance became the dominant notion . Everybody was writing relevance statements . Besides that , we did not have a lot of money . Johnson was funding the war without doing anything different on the surface , which meant that every time you turned around , they were raiding you for another ten to fifteen million dollars . So in that environment , I would have been hard pressed to plow a lot of money into the network just to improve the productivity of the researchers . The rationale just wouldn’t have been strong enough . What was strong enough was this idea that packet switching would be more survivable , more robust under damage to the network . If a plane got shot down , or an artillery barrage hit the command center , the messages would still get through . And in a strategic situation — meaning a nuclear attack — the president could still communicate to the missile fields . So I can assure you , to the extent that I was signing the checks , which I was from nineteen sixty - seven on , I was signing them because that was the need I was convinced of . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7100</div><div class='noteText'>“ The best way to develop the network for the Defense Department was to develop it for the IPTO guys , ” he argues . It was a notion he pushed hard whenever he was making the case to Rechtin , Foster , and the other higher - ups . “ So , how do you build a technology like this ? ” he would ask them , echoing Taylor’s original thinking . “ Just build some phony terminals and send dummy traffic around ? That’s pretty stupid . You don’t really test a network until you have real users . But who ? You aren’t going to have real military users fiddling around with this stuff , because they’re too busy doing real missions to worry about testing things for ARPA . Oh ! Brilliant management move ! We will use our principal investigators . They will generate a lot of traffic . They will do all the screwball things real users do . And they have a lot of motivation to solve all the problems , because their operation is going to be enhanced . So it’s really a very interesting bootstrap management scheme . ” Rechtin and the higher - ups bought it . At a time when most other ARPA offices were being cut , restructured , or spun off — ballistic - missile defense was finally transferred to the army in 1968 , instantly cutting ARPA’s overall budget by half — IPTO’s budget steadily , miraculously kept rising . By the end of the decade it would stand at something like $ 30 million a year , double what it had been when Taylor took over . Indeed , says Taylor , his budget reviews with Rechtin and Lukasik were a walk in the park . “ Steve would take the lead , ” he says , “ and Eb would just sit in the background , occasionally asking a managerial question . But it was almost pro forma . I can recall defending a twenty - five - million - dollar budget in a thirty - minute meeting . We were doing important stuff , and when we needed money , we got it . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7117</div><div class='noteText'>In a decade that was justly famous for turmoil , the years that brought the ARPA network into being — 1966 through 1969 — were enough to make one wonder what shreds of the social fabric could possibly survive . The summer of 1967 , when Larry Roberts was drafting his preliminary plan for the network , was the Summer of Love for the hippies in San Francisco’s drug - soaked Haight - Ashbury district . But it was also a Long , Hot Summer of rioting in the black ghettos of Newark , Detroit , and more than a hundred other cities ; the National Guard was called out for the first time since World War II . October 1967 , the month when Roberts announced his network plan in Gatlinburg , was also a month that saw some fifty thousand antiwar demonstrators rally at the Pentagon , where protesters in psychedelic face paint stuck flowers in the gun barrels of guardsmen sent to control them . By that December , some 486,000 U.S . troops were in Vietnam ; nine thousand had been killed in that year alone , and many others were mired in the siege of Khe Sanh . And 1968 , famously , was even worse , from the Tet Offensive on January 30 to the assassination of Dr . Martin Luther King , Jr . , on April 4 to the assassination of Senator Robert F . Kennedy on June 5 . Taking these events together , the era was like a giant primal scream , the sound of a nation tearing itself apart . On the face of it , there seemed every reason to believe that the ARPA community , too , might tear itself apart . ARPA was an arm of the Department of Defense , after all , in a period when academics had begun to use the word Pentagon as an expletive . And while it was true that computer researchers in general were notoriously apolitical , they were hardly unconcerned about the war . Many of the students were eligible for the draft , if nothing else , and at least some of them were vehement activists . The question was heard again and again : Is it right to take this money ? And yet the answer was almost always yes . To senior researchers such as Fano , Newell , and Feigenbaum , IPTO was not part of some abstract military machine , but an extension of the research community itself . Licklider , Sutherland , Taylor , Roberts , even Lukasik — these guys were peers , colleagues , people they had known and worked with for years . The students , meanwhile , felt much the same way . Given the nature of interactive computing , in fact , even the fieriest activists among them could argue that they were co - opting the Pentagon , and not vice versa . They were striking a blow for intellectual freedom . They were liberating human potential . And not incidentally , they were liberating a few dollars that might otherwise be spent on B - 52s . “ That was the lie we told ourselves , ” recalls a wry Bob Metcalfe , then an undergraduate computer - science major at MIT : “ Our money was bloody on only one side . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7140</div><div class='noteText'>The obsessive techno - weenies who haunted the terminal rooms of Project MAC and the other ARPA sites were children of the sixties , all right . But the worlds they were creating for themselves had less in common with the angry antiwar movement out on the streets than with the psychedelic , peace - and - love communes of Haight - Ashbury . Their passion for a newly popular epic fantasy called The Lord of the Rings was equaled only by their obsession with science fiction — and with the ubiquitous computer game Spacewar , which sprang into existence wherever there was a PDP machine to run it on . For most of them , “ ARPA ” didn’t mean “ Pentagon . ” It was more like a magic word that opened a door into the Land of Faerie itself , a magical realm full of machines that could do anything their imaginations could contrive , while providing a refuge from the all - too - real tumult around them . In any case , the upshot was that the ARPA community stayed together through the Vietnam era — with the rising generation in particular beginning to coalesce as never before . Not only were they not alienated by ARPA’s Pentagon connection , but they were becoming exactly the kind of community that Lick had envisioned from the beginning . Of course , it didn’t hurt that Bob Taylor was doing his behind - the - scenes best to foster that development . The idea had come up in late 1967 , Taylor remembers , when the principal investigators were meeting in Alta , Utah . Now , the meeting wasn’t held there because it was ski season , he hastens to add — or not entirely , anyway . Mostly it was because of Alta’s proximity to Salt Lake City and the University of Utah , where Dave Evans was rapidly building his new computer - science department into a powerhouse . Indeed , Taylor had already given Utah formal designation as a Center of Excellence for graphics . “ So anyway , ” says Taylor , “ in the Alta meeting I invited some of the Utah grad students to observe . Then at the end , I asked the grad students for suggestions . It was John Warnock who asked , ‘ Why not have a meeting for the grad students the way you do for PIs ? ’ Well , I thought , That’s a great idea ! ” In short order Dan Slotnick , head of the Illiac IV project at Illinois , had volunteered to host the meeting at that university’s Allerton conference center , outside Champaign - Urbana . Each of the contractors had picked out two of its best students to send to the meeting , at ARPA expense . And the master - of - ceremonies role had fallen to the twenty - four - year - old Barry Wessler , an electrical - engineering student who had come down from MIT in the fall of 1967 to serve as Taylor and Roberts’s assistant in IPTO . ( “ I said I wouldn’t go [ to Allerton ] because I was over thirty ! ” jokes Taylor , who was then an old man of thirty - six . ) The grad - student conference started in July 1968 , with no one knowing quite what to expect . “ It turned out to be a really amazing group of people , ” recalls Steve Crocker , who was just in the process of returning to UCLA after eighteen months in Minsky’s AI Lab . “ It was probably the smartest , most intense group of young computer scientists who had ever gotten together up until that time . We just cooked for about three days . We sized each other up . We got to know who was working on what . And at the end of those three days , we all knew each other very well . ” Vinton Cerf , Patrick Winston , John Warnock , Danny Cohen , Bob Balzer — the roster of that meeting would eventually read like a who’s who of modern computing , and many of the friendships they forged in the cornfields would endure down to the present day . But for those three days in the Illinois summer , they were young , wild , and crazy . And by all accounts the wildest of the bunch was Utah’s Alan Kay , a guy who was so far out in the future that not even this crowd could take him seriously — yet so funny , so glib , and so irrepressible that they listened anyway . When it was his turn to give a presentation , Kay told them about his idea for a “ Dynabook , ” a little computer that you could carry around in one hand like a notebook . One face would be a screen that would display formatted text and graphics and that you could draw or write on as if it were a pad of paper . The Dynabook would communicate with other computers via radio and infrared . It would be so simple to program that even a kid could do it . And it would have lots and lots of storage inside — maybe even a hard disk !</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7196</div><div class='noteText'>Still , says Wessler , there was one sense in which the meeting fell short . Bob Taylor had had two goals in sponsoring it . One — to make the young researchers feel like they were part of an ARPA community — had been fulfilled beautifully . But the other — to drum up enthusiasm for the ARPA network — had gone precisely nowhere . Wessler had tried at every opportunity to get the participants talking about it , but he had found no takers . True , agrees Crocker : the young hotshots in Wessler’s audience were bored stiff by networking . “ The thing I always have trouble explaining to people nowadays is how intense all the other stuff was , ” he says . “ AI . Graphics . Time - sharing . Architecture and distributed processing . Programming languages , with Lisp being the core of a lot of things . Experiments with high - level languages that eventually transformed the way we were programming . ARPA was sponsoring all these vibrant activities that were deep and transformational in their own right . Networking came across to us as only one of many activities — and a rather pale and dry activity , at that . The network itself was only a piece of connective tissue . ” The irony , Crocker adds , is that so many of the participants at that first grad - student meeting , himself included , would eventually discover that this little piece of connective tissue had defined their professional lives . They would likewise find that the very act of building the network had done more to forge them into a real community than any number of bull sessions in the cornfields . But then , he says , that wasn’t clear until later . And in the meantime , being the arrogant young know - it - alls they were , they needed a good swat with a two - by - four to get their attention . It wasn’t long in coming .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7246</div><div class='noteText'>The meeting itself was almost surreal , he remembers . What the participants knew was that the winner of the contract , whoever it might be , would install an IMP at each of the first four sites and make the bits flow between them — period . But what they were now having to face was that bits alone weren’t communication , any more than the letters of the alphabet alone were communication . Before anything meaningful could be communicated with those letters , everyone first had to agree on a vocabulary : how letters were formed into words . Then everyone had to agree on a grammar : how words could go together to form sentences . Then everyone had to agree on rules of discourse — appropriate ways for sentences to be used in making a request , say , or framing a reply . And it continued from there , through level after level of convention and protocol . Clearly , says Crocker , an analogous set of protocols had to be agreed upon at each level of digital communication . Or rather , that was clear in retrospect . At the time , about the only thing he and the others really knew was that they were facing chaos . How would the IMPs and hosts be connected ? What sort of applications would run on the network ? How would those applications interact with what was already going on in the various operating systems ? “ We just started asking some very basic questions , ” says Crocker . “ But the answers were not forthcoming in any way . In fact , my recollection is that not only weren’t there any answers , but there wasn’t even a strong acknowledgment that this was the set of questions that we needed . ” Worse , he says , they couldn’t even be sure that there was any real point to it anyway : “ We had gotten no external directive [ from ARPA ] , and that was an absolutely central concern . We had no idea whose toes we were stepping on , if anybody’s . In fact , I envisioned that a group of professionals from ‘ the East ’ would come along by and by to tell us how it was supposed to be done . We had this sort of magical view of ‘ the East . ’ ” Still , two things were apparent to the group . One was that the prospects were fantastically interesting , now that they had actually taken the time to think about the network . “ We found ourselves imagining all kinds of possibilities , ” Crocker says . “ Interactive graphics , cooperating processes , automatic database query , electronic mail . ” The other thing was that they were having a great time . “ There was a kind of cocktail - party phenomenon , ” he says , “ where you find you have a lot of rapport with each other . ” So in the end , the Santa Barbara participants reached no conclusions whatsoever , other than that they wanted to keep on meeting . “ Over the next several months , ” says Crocker , “ we managed to parlay that idea into a series of exchange meetings at each of our sites . We met at SRI , at Utah , and at UCLA . We said that the first effect of networks , which were designed to make it possible to collaborate at a distance without all this travel , was to increase travel enormously ! ” It was a blast , he remembers , and they let their imaginations run riot . What did it matter , after all ? They were just grad students ; professionals from the East would come around to tell them about the real protocols soon enough . So they started fantasizing about things like mobile interfaces , little chunks of software that would migrate through the net and allow you to interact with an application on a remote machine as if it were right in front of you ( nowadays such mobile programs would be called applets or agents ) . Crocker and his companions even started playing around with programming languages that would make it easy to write such applications . And as is the way of such things , without ever quite deciding to do so , they found themselves beginning to take it seriously . In the spring of 1969 , in fact , after a particularly delightful meeting in Utah , they decided that they’d better start transcribing their discussions .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7278</div><div class='noteText'>“ I was most concerned that we not tread on someone’s toes — someone who’d been officially assigned to oversee these things . So I used humble wording such as , ‘ These notes are unofficial , and they are just to stimulate conversation , and anybody is able to write down anything , and they have no status . ’ There was also an issue as to whether these were formal publications , and so we said they were not . ” And then , of course , there was the question of what to call the notes . Crocker struggled for a while , trying to think of something that would emphasize the informality and not seem too presumptuous to the real authorities . Finally , somewhere deep in the night , he typed a title he hoped would work : Request for Comments .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7290</div><div class='noteText'>This , everyone could tell , was not going to be your standard presentation . Down on the right - hand side of the stage , all alone , sat Douglas Engelbart . He was wearing a fresh white shirt and tie for the occasion , plus a set of headphones that made him look for all the world like a NASA launch - control officer . Across his lap — pivoting from the arm of his chair , actually — he had a kind of console that featured a built - in keyboard in the middle , a tray on the right for holding an odd little box with some buttons on top and a cord coming out the end , and an identical tray on the left for holding an equally odd gadget with five metal keys . Looming over Engelbart’s right shoulder , dominating the stage , was a twenty - two - by - eighteen - foot display screen that magnified his every expression to the proportions of the Jolly Green Giant . And behind that , invisible to the audience but very much a part of the show , was a jury - rigged chain of cameras and video links and telephone lines stretching thirty miles down the peninsula to Menlo Park . With a setup like this , no one knew quite what to expect . But Engelbart definitely had their attention . “ The research program that I’m going to describe to you , ” he began in that soft , strangely compelling baritone , “ is quickly characterizable by saying , ‘ If , in your office , you as an intellectual worker were supplied with a computer display backed up by a computer that was alive for you all day , and that was instantly responsive to every action you had , how much value could you derive from that ? ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7405</div><div class='noteText'>Indeed , mainstream computer manufacturers had begun to take time - sharing seriously as far back as 1964 , thanks in large measure to the publicity surrounding Project MAC and its vision of information utilities — not to mention its dramatic announcement of a partnership with General Electric . By 1965 , DEC had debuted its PDP - 6 machine , the first general - purpose time - sharing computer on the market ; IBM had declared its intention to build a time - sharing computer compatible with its System / 360 line ; and similar announcements had come from Control Data Corporation , Sperry Rand , Burroughs , and Scientific Data Systems . From there it was just a short step to computer service bureaus , or “ computer utilities ” that sold computer processing by the minute to small users that couldn’t afford their own machines . Before 1965 was out , GE was offering just such a commercial time - sharing service based on the Dartmouth College system , which included the new interactive programming language BASIC . IBM was likewise offering a commercial time - sharing service based on Quiktran , an on - line version of Fortran . And Datamation magazine had concluded that “ the broad acceptance of time - sharing ” was perhaps the most important trend of the year . 3 In practice , it’s true , computer utilities hadn’t always lived up to glowing expectations . The bulk of their market was actually in batch processing , for the simple reason that their business customers needed it for payroll and accounting jobs . Moreover , the time - sharing services that the utilities did offer were almost always limited , special - purpose systems along the lines of Dartmouth BASIC : many users could tap in and work interactively , but they had access to one and only one program . “ Real ” computer utilities , in which many independent users could run whatever programs they liked , remained a dream for the future .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7429</div><div class='noteText'>In short , the success of the computer utilities had long since convinced most of the computer professionals in Engelbart’s audience that time - shared , interactive computing was a legitimate activity . The utilities boom had likewise popularized the notion that computers — or at least terminals — might one day have a place in the home . As Lick himself would write in 1970 , he’d already been hearing for years about “ home information systems ” that would be linked to data centers via telephone lines or antennas . “ The picture that has been built up in my mind is a montage of television , hi - fi , and microfilm . . . . Through the home information system , the family receives its news and entertainment , does its shopping , browses the library , makes reservations for travel and theatre , and so on . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7436</div><div class='noteText'>perhaps most important of all in the long run , the utilities had offered thousands of nonprofessionals a glimpse of what it meant to interact with a computer . Just a few months before Engelbart’s presentation , for example , in the fashionable Seattle suburb of Lakeside , Washington , the local mothers ’ club had used some of the proceeds from its annual rummage sale to buy computer access for the science and math students at the Lakeside School . The system was rudimentary : just an ASR - 33 Teletype terminal that could dial in to a nearby GE Mark II time - sharing system , which offered little more than GE’s version of BASIC . But the kids loved it . And one of the most ardent was an undersized , freckle - faced eighth - grader who taught himself BASIC as fast as he could . Bill , his friends called him — William G . Gates III .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7580</div><div class='noteText'>Bob Kahn played a somewhat similar role , notes Crowther . As the group’s resident theorist , he focused on the global , architectural issues of networking . “ But he wasn’t really interested in the implementation , ” says Crowther . “ So he was like a consultant : we talked to him a lot and had grand little fights about how things should be done , but then we actually implemented it . ” Happily for Crowther and Walden , the two main programmers , that implementation was comparatively straightforward . “ It had become an engineering problem as opposed to a theory problem , ” says Walden . “ The computers had now gotten fast enough and had good enough memories and were cheap enough that you could actually implement packet switching in software algorithms that ran fast enough to get the job done . ” At one point , adds Crowther , “ Dave and I sat down , worked out the algorithms , and figured out that it was only going to take a hundred and fifty lines of code to process a packet through one of these switches ! Of course , there [ was ] a whole lot of other stuff that you [ had ] to have , too . But this was the kernel , the part that really mattered , the thing that took in a packet , figured out what to do with it , and pushed it back out the line . ” That “ other stuff , ” it goes without saying , still gave Crowther and Walden plenty to worry about . How could they incorporate measurement software , for example , so that network operators could monitor the flow of packets and keep track of how well the system was working ? How should they write the code so that users could hook up more than one host computer to a single IMP ? And speaking of hookups , exactly how much processing should they allot to the IMP , and how much should be left up to the users and the host computer ? “ There wasn’t much theory for how you build a packet - switching network , ” says Walden . “ So we just got out there and did it . All the stuff that is now taught in courses about networks and protocols and all of that , I would say we were mainly inventing it . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7622</div><div class='noteText'>Out at UCLA , Steve Crocker was watching the calendar , too , and if anything , he was even more apprehensive than the BBNers . To begin with , he explains , there was this business of the user protocols . He and his fellow grad students from the first four sites were still groping in the dark , with only the vaguest idea of what they were doing — or even if they were supposed to be doing it . They still had not heard from the Wise Men of the East about the official plan . And they were beginning to have a horrible suspicion that there really was no official plan — that it was entirely up to them to formulate it . It was a realization that dawned in stages , says Crocker . The first clue came on Valentine’s Day of 1969 , when representatives from the first four host sites were invited to BBN to meet the people who had just won the bid to build the network . “ I don’t think any of us were prepared for that meeting , ” Crocker later wrote in his retrospective of those days , circulated as Request for Comments ( RFC ) 1000 . “ The BBN folks , led by Frank Heart , Bob Kahn , Severo Ornstein and Will Crowther , found themselves talking to a crew of graduate students they hadn’t anticipated . And we found ourselves talking to people whose first concern was how to get bits to flow quickly and reliably but hadn’t — of course — spent any time considering the thirty or forty layers of protocol above the link level . ” Clearly , says Crocker , the Wise Men of the East had to be somewhere else , and would announce themselves soon enough . But then came the second clue : in April , Crocker and his ad hoc group released that first , ever - so - carefully - worded Request for Comments circular about the brainstorming they’d done to date — and no Wise Men rose up to complain . Nor was there any protest in response to RFC 2 , or RFC 3 , or any of the numbers that followed . “ We just got more people wanting to play on our team , ” says Crocker . Soon , in fact , as the RFCs spread the word , meetings of their group were drawing upward of fifty people . Finally , says Crocker , at about that same time , BBN released its internal report number 1822 , the document that formally defined what the IMP software would and would not do . Specifically , it stated that the software would do as little as possible . The network as installed by BBN would deliver the packets , period . Everything else would be the responsibility of the host computer . Now , admittedly , says Crocker , this did make for a clean interface , with minimal complication for BBN . Crowther and Walden could program the IMP side of the interface without having to worry about the vagaries of the various host computers . ( In that sense , the IMP would function a bit like a standard electric wall socket , delivering AC power at a standard 110 volts and sixty cycles per second , regardless of whether the user plugs in a lamp or a toaster . ) “ But that left a total vacuum on the protocols , ” explains Crocker . In short , Crocker and his contemporaries were the grown - ups . Sobering thought . Suddenly , what they did mattered . “ Over the spring and summer of 1969 , ” he would write for RFC 1000 , “ we grappled with the detailed problems of protocol design . . . . It was clear we needed to support remote login for interactive use — later known as Telnet — and we needed to move files from machine to machine [ later known as File Transfer Protocol , or FTP ] . We also knew that we needed a more fundamental point of view for building a larger array of protocols . Unfortunately , operating systems of that era tended to view themselves as the center of the universe ; symmetric cooperation did not fit into the concepts currently available within these operating systems . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7743</div><div class='noteText'>There is no way to sugarcoat this : Lick’s tenure at IBM had been a disaster . “ He knew it was not a good match almost as soon as he arrived , ” says Louise Licklider , remembering their move to Westchester County and the Thomas J . Watson Research Center . He couldn’t even get the executives at the lab to call him Lick , for example ; they insisted on Joseph , or Joe , a name he hadn’t used even as a boy . ( “ That one , ” he would whisper to Louise at parties , pointing out one or another of the glad - handers who were forever trying to hustle their way to the top without knowing a thing . “ That one’s a ‘ Joe . ’ ” ) Then there were the pictures , she says . “ They asked him , ‘ Which do you want hanging in your office : the “ Think ! ” sign , or the portrait of the chairman ? ’ There were only two choices . ” Well , she says , Lick thought to himself , You’ve got to be kidding ! But he mulled it over , perhaps remembering the Impressionist prints he had hung in his Pentagon office , and finally he said , “ I guess I’ll take the portrait . ” But when the portrait was hung , he couldn’t help noticing that there in the picture behind chairman Thomas J . Watson , Jr . , as big as if he’d hung the thing separately , was a one - word sign : “ Think ! ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7810</div><div class='noteText'>“ Now , in the fall of ‘ sixty - eight , this was a pretty radical idea . MIT was famous for computation , but as an undergraduate , you just couldn’t get your hands on the machines . So we started going around , meeting all of the senior faculty , and trying to persuade them to do something . And somehow , by the luck of the draw , I was one of two students who were supposed to see the head of Project MAC . ” They certainly weren’t planning to present nonnegotiable demands or anything like that , says Burmaster ; radical confrontation had never been his style ( by 1968 standards , in fact , his shoulder - length hair and earnest , dark - rimmed glasses made him seem downright clean - cut ) . Still , in the fall of 1968 you couldn’t be twenty - one years old without harboring at least a few stereotypes about the over - thirty crowd , most of whom seemed exceedingly confused and angry about the sixties , not to mention reactionary . And at first glance , this Professor Licklider appeared to fulfill every one of those stereotypes . “ He was an old guy — maybe fifty - five or sixty — and he was sitting behind his desk wearing a coat and tie , ” Burmaster remembers . ( Lick was then fifty - three . ) “ He was a big man — I’d say six feet one or two , maybe . And he was sort of portly , or heavy — certainly not trim . Basically he had that rumpled , professorial look . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7892</div><div class='noteText'>In the ninth - floor machine room of 545 Technology Square , he recalls , the Multics computers were on one side and the AI computers on the other , with a door in the middle — “ and you were either a winner or a loser , depending upon which side of that door you were on . ” What characterized the “ winners , ” of course , was their fervent , almost religious conviction that they were on the verge of creating truly intelligent machines — not just understanding intelligence , or modeling intelligence , but creating it . It was a belief that flowed from Minsky himself , says another graduate student of that era , Patrick Winston , who would later succeed Minsky as the director of the lab . “ I think he wanted to make a contribution as fundamental as Darwin’s and Freud’s . So everyone had a mission , everybody worked hard , everybody stayed up all night . ” They never doubted for a minute that they could do it , agrees Winograd , who has since come to entertain a great many doubts . Like their counterculture contemporaries out on the streets , they felt that the wisdom of their elders was old , dead , out of date ; the future was what they were inventing right there in Tech Square . “ It was very much of an attitude — and I think Minsky still has this to a large extent — that nothing that anybody had ever done before would be relevant to your research , ” says Winograd . “ Everything would have to be invented from scratch , and if you were smart you could do it . Background wasn’t relevant ; it was pure cleverness that counted . ” But that , of course , was precisely why everyone who wasn’t a winner was a loser : to Minsky and his followers , the “ computer utility ” vision that animated the rest of Project MAC was boring . At best it was a means to an end , a way to get the computer power they needed for their real work . Likewise this stuff about on - line communities : if the outside world was full of losers , why bother talking to it ? And as for Lick’s vision of human - computer symbiosis , what was the point ? Why waste your time augmenting human intelligence , when humans were virtually obsolete ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7925</div><div class='noteText'>Fundamentally , says Corbató , Multics was just too complicated . In their näiveté , he says , he and his colleagues had drawn up specifications that called for everything an information utility might conceivably need , from elaborate security schemes to an ability to coordinate multiple processors and multiple memory modules . “ We were top - heavy with too many ideas , ” says Corbató , “ and we failed to recognize that they would not always go together . So a lot of the rewrite process consisted of pruning things down to the bare essentials and trying to find a more elegant way of doing things . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7953</div><div class='noteText'>Shared naïveté or no , however , Lick had begun to see Multics as a horrendous opportunity cost for Project MAC , a diversion of talent and effort that had left the actual users in limbo . He also knew that ARPA’s patience wasn’t going to last forever , given the new emphasis on “ relevance . ” Indeed , he could foresee Multics ’ dragging down the whole ARPA dream with it . “ The present time is . . . a critical one in the history of digital computing , ” he had declared in an unpublished speech he gave at the Technical University of Berlin in August 1968 , just a few weeks before he took over at MAC . “ Many are waiting to see how the second generation of general - purpose multiaccess systems [ that is , Multics and TSS ] turns out . [ If they ] turn out to be too complex to implement , or to operate efficiently , there may be a general retrenchment to noninteractive applications . . . . That would be a great loss , I think , to the universities and , indeed , to all who want to use computers as aids or partners in learning , experimenting , modeling , solving problems , making decisions , and other intellectual activities . ” Given that latter scenario , the new director of Project MAC had to wonder if Multics was still worth it . After all , it wasn’t the only game in town anymore . The time - sharing system developed at Project Genie might have been somewhat less ambitious , but it was very capable nonetheless : just look at what Engelbart and his crew had done with it . Then there was DEC’s big PDP - 10 , which came with a time - sharing operating system that was likewise workable , if not great . And if those systems were available now , one had to wonder , was there any real point in waiting for Multics ? Was this just another case of “ perfect ” being the enemy of “ good ” ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 7984</div><div class='noteText'>And while some customers did indeed buy it — an eventual total of seventy - seven copies were sold worldwide , which was fairly respectable for such a major installation — most people in the ARPA community ended up turning to the PDP - 10 and Tenex , a new time - sharing system created for that machine by BBN . And then , of course , came the microcomputer revolution of the 1980s , which made Multics look like a complete dinosaur . If Multics became a dinosaur , however , it was a remarkably influential one . Witness the fact that the Association for Computing Machinery would award Corbató its 1991 Turing Award , computerdom’s most prestigious honor . For all its complexity and delay , Multics gave living proof that a grown - up operating system was possible — that sophisticated memory management , a hierarchical file system , careful attention to security , and all the rest could be integrated into a single , coherent whole . In that sense , Multics was a prototype for virtually all the operating systems to follow . And along the way , not incidentally , the project became a model of planning and documentation . At the 1965 Fall Joint Computer Conference in Las Vegas , Corbató and his team spelled out their preliminary designs for Multics in unprecedented detail , giving six separate papers that would occupy some sixty pages of the proceedings volume . Once the project was history , moreover , they would be equally open about the painful lessons they’d learned . In that sense , Multics was a significant contribution to the emerging discipline of software engineering . “ I think we probably got people to think at a more sophisticated level about systems design and the need to articulate the design process , ” says Corbató . “ And to some extent I think it’s been a consciousness - raising experience for them to realize the kind of problems and hazards you can get into in building systems . ” If nothing else , he adds , the Multics project was the training ground for a cadre of top - notch students who would soon be taking the lessons they’d learned to DEC , Data General , Prime , Apollo — all the leading - edge companies of the 1970s . And then , of course , there were two young Multicians , named Dan Bricklin and Bob Frankston , who would go on to galvanize the emerging microcomputer industry with a little program called VisiCalc , the first electronic spreadsheet . So Multics definitely had an impact . And that’s not even counting its biggest , if least direct , legacy , which came in the form of a backhanded compliment .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8009</div><div class='noteText'>But then a funny thing happened : two of Bell’s former Multicians , Ken Thompson and Dennis Ritchie , began suffering from withdrawal pangs . As baroque as Multics was , it was responsive , interactive , alive . And once they no longer had it , Thompson and Ritchie found themselves craving that interactivity . So , good hackers that they were , they decided to write a little time - sharing system of their own . They had to sneak it in on the side , since their superiors weren’t about to OK another time - sharing project , and they had to make do with a discarded , obsolete PDP - 7 computer that Thompson had scrounged from somewhere . But they persevered , taking some ideas from Multics , others from Project Genie — Thompson had graduated from Berkeley in 1965 — and adding a good many of their own . Their prime criterion was that the result had to be lean , clean , and simple , with none of Multics’s gargoyles and gingerbread . By mid - 1970 , they had a preliminary version up and running . Somewhere along the way , moreover , their homebrew operating system had acquired a name . According to one version of the story , the name signified “ one of whatever Multics was many of . ” According to another , it stood for “ Multics without balls . ” But either way it came out the same : Unix .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8070</div><div class='noteText'>No matter what the project was about , it seemed , and no matter how many programmers were assigned , deadlines continued to slip , costs continued to skyrocket , and bugs continued to proliferate . “ The presence of such errors in a program is not evidence of poor workmanship on the part of the programmers , ” he wrote . “ [ The fact is ] that no complex program can ever be run through all its possible states or conditions in order to permit its designers to check that what they think ought to happen actually does happen . ” 6 To Lick , of course , the obvious solution to the software crisis was to apply more and better interactive computing , à la Dynamic Modeling . But to programmers who worked in the commercial sector — which was to say , most programmers — the answer was very different . In their world , software was a product to be gotten out the door , on time and within budget . So their instinctive reaction was to adopt an industrial approach , with an ever - increasing emphasis on planning , discipline , documentation , coordination , and control . Perhaps not surprisingly , this instinct also fitted in perfectly with the batch process - oriented , think - it - through - ahead - of - time school of programming . By the early 1970s , moreover , it would be enshrined in the doctrine of “ top - down ” programming , which was pretty much what it sounds like : Start from the top , getting the overall design of your program right before you do anything else . In particular , strive to divide your programs into modules , or subroutines , that can operate more or less independently and that can be written by separate teams . Then , once that’s done , look at each subroutine and get its structure right , and so on down . The actual programming code should be the last thing you write . Meanwhile , by no coincidence , the top - down philosophy was being enshrined even further in “ structured ” computer languages such as Niklaus Wirth’s Pascal , which were designed to make it hard to write programs in any other way .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8085</div><div class='noteText'>Lick himself didn’t really seem to have any objection to this approach ; to his mind , top - down programming was simply a commonsense method of delegating responsibility . He just didn’t think it should be the only approach . Before you can delegate responsibilities , he argued , you have to figure out precisely what those responsibilities are and how you should carve them up . And when you’re really out there on the edge , as he knew after a professional lifetime of research , that process is anything but clear - cut . “ On the frontier , ” he had written in 1965 , “ man must often chart his course by stars he has never seen . Rarely does one recognize or discover a complex problem , formulate it , and lay out a procedure that will solve it — all in one great flash of insight . ” 7 When the systems are truly complex , in short , programming has to be a process of exploration and discovery . That had been the whole point of interactive languages such as Lisp , as well as interactive - design tools such as Sketchpad : they made it easy to explore new solutions by making it easy to formulate and then reformulate ideas on the fly . And that was the whole point of Lick’s Dynamic Modeling project : he wanted to push exploratory programming as far as he could in every direction .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8095</div><div class='noteText'>As Bob Fano explained it in a 1998 biographical memoir8 of his friend , “ Lick’s goal was a self - contained , coherent , interactive computer system that could be used by researchers with moderate computer skills to investigate the behavior of a variety of models with little programming required on their part . [ So ] the software scheme conceived by Lick was very different from any existing problem - oriented language . Briefly , it was akin to a software Tinkertoy , based on a vast library of software modules that readily could be assembled into specific models and programs for investigating them . New modules could be constructed and added to the library by users to meet their special requirements , so that the library would eventually become the repository of the work of the community . . . . The implementation effort started in 1969 , and Lick personally developed a significant fraction of the library , which grew over time to some 2,000 modules . ” Granted , Lick’s software Tinkertoy scheme was wildly impractical for the hardware of the day ; he was basically gambling that computer speeds and memory capacity would increase rapidly in the coming decade — as they did . Nonetheless , his approach anticipated the “ run - time libraries ” of subroutines that are now a standard part of programming languages such as C + + . Moreover , because users could add modules at will , his scheme had some of the same open - system quality that had made Corbató’s CTSS such a success . And , of course , he hoped to make the assembly of those modules as intuitive and as transparent as possible : “ Users were to interact with the computer system mostly through visual displays with light pens or similar input devices , ” Fano explained .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8126</div><div class='noteText'>But then , just as their counterparts at IBM had discovered some half a decade earlier , Lick’s students were learning that this boss was not your ordinary boss . He could definitely expand your mind , says yet another former student , Christopher Reeve . “ For example , he thought that computers should have unlimited amounts of memory . Now , this was way back when memory was very expensive , and a computer with a megabyte was very uncommon . But Lick always had a certain level of enthusiasm that was quite contagious . ” “ Lick was always ten steps ahead of everybody else , ” agrees Al Vezza , a young Project MAC staffer who was now Lick’s deputy on the Dynamic Modeling project . And that was especially true when it came to the Arpanet , which Lick regarded as central to his vision of an on - line community . When the Arpanet started expanding , in early 1970 , Lick immediately took on the responsibility of getting MIT connected . Never mind that it gave the rest of Project MAC one more thing to be irritated about . The AI Lab , the Multics team , and all the others were welcome to drag their feet if they wanted . Lick was quietly determined to get his PDP - 10 on the network now .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8169</div><div class='noteText'>Even as the IMP guys at BBN were struggling to get those software problems fixed , unfortunately , they also found themselves dealing with the site representatives , who were more frantic than ever : not only were more sites being added to the Arpanet all the time , but Larry Roberts was putting considerable pressure on them to start using the thing . BBN did its best . After all , as Frank Heart points out , “ it was in our interest to have them have a happy connection . ” Nonetheless , the role of Arpanet facilitator increasingly fell to Crocker , Metcalfe , and the other students in what was now being called the Network Working Group .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8177</div><div class='noteText'>The Network Working Group would continue to be a big part of Crocker’s workload even after he moved to ARPA in July 1971 ( Barry Wessler had left to finish his Ph.D . work at the University of Utah , and Crocker got his wish : Wessler’s job ) . He didn’t get to work in the Pentagon building itself , as it happened ; a year earlier , having lost out in the DoD’s never - ending office - space wars , ARPA had been relocated to an anonymous glass tower in Rosslyn , Virginia , a high - rise office district just across the Potomac from Georgetown . But Crocker rarely got to sit still anyhow . “ I had a set of things that I wanted to do at ARPA , ” he says . “ The AI program , the speech - understanding programming , and so forth . I was trying to extricate myself from the day - to - day business of the network . But the Arpanet was growing during this period of time , and it was a lot of work to add each node to the network . So because of the time I had spent in the field , and the expertise I’d developed , I continued to work with a lot of the new host sites to give them advice , help get them connected , and so forth . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8204</div><div class='noteText'>everyone else’s . It was Al Vezza who suggested the solution : a software “ fly - off . ” On a given date , he said , everyone should come together in one place — at MIT — and try to log into everyone else’s site . Then they would each pound on the implementation software until it worked . ( Lick was happy to go along with his deputy’s idea , of course — but then , by that point he was a much happier man in general . Having recognized that his effectiveness as director of Project MAC was approaching zero , and that his colleagues were simply going around him , he had resigned earlier that same year . Much to everyone’s relief — including his own — he had handed over the reins to his onetime protégé Ed Fredkin and gone back to running his research group full - time , which was all he’d really wanted to do in the first place . ) The date for the fly - off was accordingly set for October 1971 : one solid week of hacking in the warrens of Tech Square . “ We invited them all down to the bullpen on the second floor , where they could use the IMLACs , ” says Vezza . “ And that workshop was really a critical turning point in ironing out the difficulties , because everyone was right there together . People could shout down the hall — ‘ Why doesn’t your program do this or that ? ’ — and get an answer right away . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8254</div><div class='noteText'>Tomlinson had accordingly packed up the results of his experiment into an elegant little utility program he called sndmsg , for “ send message . ” Invoke it , and the thing would ask you for a To : field , a From : field , and a Copy : field , plus a few other options . Then you would type your message and hit Control - Z , and off it would go . At the other end , the recipient could see what you’d sent by invoking a companion utility that Tomlinson called readmail . In writing these utilities , moreover , Tomlinson had come up with an elegant way to define E - mail addresses : take the “ user name ” that the person typed when logging in to his or her host computer , and simply link it to that computer’s “ host name ” on the network with an “ at ” sign : username @ hostname . But the bottom line , said Roberts , was that Arpanet E - mail was here . So if Lukasik was willing to try it . . . Lukasik knew exactly what Roberts was up to with his invitation . “ Larry wanted me to experience the Arpanet , ” he says . “ He knew that you could explain it , wave your arms , show charts , and so forth . But until you experience it , you don’t know . ” And more than that , he says , Roberts wanted him to bear witness . “ Larry knew that his researchers had done a wonderful thing in creating the Arpanet , ” he says , “ and that it was something that could be very important to the DoD . But he also knew that the researchers could go only so far in penetrating the defense community . So he wanted me to be the central interface with the military . That’s what was really going on — not just getting the boss playing with your toy . ” In any case , continues Lukasik , “ within a day or so , a model 33 Teletype terminal appeared behind my desk . It had its own stand . There was a roll of paper coming out the back . And I was on E - mail . ” Of course , as Larry Roberts would soon have cause to know , it wasn’t a completely great idea to get Lukasik up and running on an Arpanet that was still so experimental . If the software utilities were bug - ridden hacks , the boss knew about it . If the documentation was miserable , the boss knew about it . And if the network crashed in flames , the boss really knew about it . “ I’d immediately be on the phone complaining to people , ” says Lukasik , who admits that he’s never been noted for his patience or his sweet temper in such situations . “ Larry subsequently said that he’d probably made a mistake — that he’d put me on the net six months or so too early — because I saw all of the flakiness ! ” Flakiness or no , however , the ARPA director was soon firing off messages to Roberts and anyone else with a terminal . He was the first person outside of IPTO and the research centers even to be on the Arpanet , and he had fallen in love with E - mail . He loved it so much , in fact , that he quickly decided to bring ARPA itself on - line : from now on , he decreed , everybody at the agency would have a terminal . This move did not exactly meet with universal acclaim at ARPA . Even in so technocratic an agency as this one , there were a fair number of technophobes who loathed E - mail , not to mention the Teletype terminals . But no matter : “ The way to communicate with me was through electronic mail , ” says Lukasik . “ So suddenly the Strategic Office understood its utility , and the Tactical Office understood its utility , and my old Nuclear Monitoring Office understood its utility . Almost all the offices got on the net . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8293</div><div class='noteText'>“ Remember , before the network was built , people in the computer - science community didn’t necessarily know one another . It seems hard to believe , but at that time , if you would ask the MIT faculty who’s on the computer - science faculty at Stanford , I bet you some of the names would have been a blank . It was not a tightly knit community because there was not much basis for interaction . ” That’s why the idea that you might want to send E - mail across the country hadn’t really entered into the discussion of the Arpanet , he says . But once E - mail was there , the process that had started in the 1960s with the PI meetings and the graduate - student meetings suddenly accelerated enormously . Because of Arpanet and E - mail , the ARPA community was rapidly transformed into a community in fact as well as in name .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8361</div><div class='noteText'>Of course , Cerf adds , the unsung heroes were the BBN guys , who kept the network up and running through the entire ICCC meeting with only one brief crash — though that one failure did manage to leave Bob Metcalfe twisting in the wind . Metcalfe remembers it well . As editor of the demonstration handbook , he explains , he became the designated “ demogod , ” the guy who gave the tour to visiting VIPs during the meeting itself . “ So picture this grad student with his huge red beard and Birkenstocks , ” he says . “ And now picture these ten pinstripe - suited AT &amp; T executives who arrive in a group . They were in the land of packet switching , which was viewed as the opposite of the phone companies ’ circuit switching , and there was definitely a technological animosity . So I started walking them through the ballroom doing demos . At one point they were clustered around looking at the screen as I typed , and the damn thing crashed . The only time the Arpanet crashed in the whole three days of that meeting was right then . “ Well , I sat there for a moment like you always do , hoping that something would actually work . But it never does . So I looked up at the guys in the pinstripes , and I found them all smiling . They were happy that it crashed . And it came alive for me in that moment : they were hostile . In fact , from that moment forward I carried a grudge against guys in pinstripes . I did eventually learn to wear pinstripes myself — but I still carry that grudge . ” Happily , however , the glitches didn’t really matter in the end . The ICCC demonstration did what it was intended to do , which was make the world sit up and take notice of packet switching . It was what Metcalfe calls the Arpanet’s debut — its coming - out party , its coming of age . “ Up until that point you couldn’t see it anywhere , ” says Kahn . “ All you could do was read an arbitrary abstract paper somewhere that said , ‘ Here is this new way to do computer communications . ’ But ICCC was the watershed event that made people suddenly realize that packet switching was a real technology . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8387</div><div class='noteText'>leadership of ARPA , notably Charles Herzfeld and Steve Lukasik at the agency director level and John Foster at the DDR &amp; E level . These men not only understood the vision that animated their computer office but protected and encouraged what that office was trying to do . And perhaps most important , they continued to foster ARPA’s extraordinarily un - federal - government - like management style — one that might be summarized as allowing “ the freedom to make mistakes . ” An even larger share of the credit goes to the successive directors of IPTO itself : J . C . R . Licklider , Ivan Sutherland , Bob Taylor , and Larry Roberts . Although the ARPA management style granted them enormous , almost unfettered authority to dictate the course of research , they all almost invariably exercised that authority with taste , tact , and restraint . To the researchers , they were not dictators so much as protectors , intermediaries who would keep inquisitive congressmen , senators , and generals out of their hair — not to mention paperwork off their desks . “ They wanted progress , ” notes Kleinrock , “ not progress reports . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8404</div><div class='noteText'>Through his support for the working group , in short , Roberts was coaxing the people who used the Arpanet to take charge of their own destiny , to learn how to govern themselves . And almost without realizing it , the young researchers who heeded the call ended up creating a parliament that was about as democratic as anyone could imagine : if you wanted to be a member of the Network Working Group , you were . Almost by accident , moreover , they created a transnational forum for comment and debate , in the form of the RFC series , which was soon being promulgated around the world over the Arpanet itself . Their parliament was in session everywhere , all the time . And yet by technological necessity , they almost inevitably found themselves arriving ( eventually ) at a consensus ; they knew full well that a protocol had to be universal to be a protocol at all . They had to agree , or the bits wouldn’t flow . “ There was a mixture of competitive ideas , ” says Steve Crocker as he thinks back on those meetings . “ But people were also talking to each other . There weren’t armed camps saying , ‘ You’ve got to do it my way or not at all . ’ And all this was happening without anybody having to summon people to a meeting or let formal contracts . ” Indeed , this brand of hyperdemocratic , bottom - up decision making proved to be so effective that it would later become the model for the governance of the Internet . Contemporary standard - setting bodies such as the Internet Engineering Task Force are essentially the Network Working Group writ large .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8416</div><div class='noteText'>So Roberts was definitely that exception . And in proving the rule , not incidentally , he opened the way for the group that deserves perhaps the largest share of the credit for the Arpanet’s success : the rising generation of researchers who participated in the Network Working Group , who built the hardware , who debugged the software , who got their hands dirty , who made it happen . Like their parents in the World War II generation , they had a sense of participating in epochal events . “ One thing that Roberts , Kahn , and those people who are real thinkers realized early on , ” says Dave Walden , “ and what the rest of us certainly realized quite quickly , was that putting in this infrastructure would change the way the world worked — not just the communications world , but the way people worked . From the first time we sent a message across the network or wrote a paper across the network , none of us had any doubt that what you are seeing today with the thousands of distribution lists and virtual networks and worldwide queries was going to happen . ” Like their parents before them , moreover , the members of this Arpanet generation often found themselves exercising responsibility at a remarkably early age . And perhaps that is why so many of them became major figures in the later development of the network .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8428</div><div class='noteText'>After half a decade of obsessing about networks night and day , says Kahn , he was getting a little sick of the subject . Going to work for Roberts seemed like a chance to try something new . “ I went there intending to make a clean break , ” he says wryly , knowing how ironic this sounds in retrospect . “ In fact , the agreement I had with Larry was that I would set up a program in flexible automation in manufacturing . ” That sounded good to Kahn ; he left BBN for ARPA almost immediately after wrapping up the ICCC demonstration . His buddy Vint Cerf , meanwhile , was on much the same schedule : as soon as the demonstration was over , he left UCLA to take a faculty position at Stanford . And Bob Metcalfe . . . Well , Metcalfe had left Harvard quite a while back , as it happened . He had gone out to the West Coast to work for — of all people — Bob Taylor . In fact , a truly amazing number of ARPA alumni had been doing the same thing of late ; Taylor was snapping them up for a brand - new laboratory funded by — of all places — Xerox , the copier company . PARC , they called it : the Xerox Palo Alto Research Center .</h3>
<h2 class='sectionHeading'>Chapter 8:      Living in the future</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8494</div><div class='noteText'>for all its meteoric rise , Xerox was still a one - product company , a fact that had long troubled its former president Joe Wilson , now chairman of the board , as well as its current president , C . Peter McColough , who had masterminded the equally explosive expansion of Xerox’s sales and service forces . Both men feared that the company’s days of glory might be very short - lived indeed unless it moved now to diversify , to transform itself into a much more broadly based communication business . And the key to that , they believed , was computing . Xerox would use its prodigious cash flow to create the electronic office of the future — or , as McColough would put it in March 1970 in a speech to the New York Society of Security Analysts , it would pioneer the “ architecture of information . ” Having decided to get into computers , moreover , Wilson and McColough had been determined to do so as quickly as possible , which meant buying an existing computer company instead of developing the machines on their own . They had begun to put out feelers as early as 1965 . And after establishing that several likely firms were not for sale at any price — DEC , for one — they had finally reached an agreement in 1969 to buy SDS for $ 900 million in Xerox stock . So indeed , says Goldman , the deal made perfect sense on paper . What troubled him about it was the reality . For one thing , this was the first he had heard of it . The Xerox top brass had just spent nearly $ 1 billion for a computer company without even mentioning their intentions to him , their own vice president for research . “ They used management consultants , ” he says , making the term sound like a swearword . But let that go . He was the new kid on the block ; he’d started at Xerox only the previous December . His real concern was that SDS was a turkey , the Edsel of computer firms . The world was shifting toward the small , inexpensive “ minicomputers ” being pioneered by companies such as DEC and Data General , yet those guys out in El Segundo were still obsessed with making mainframes , mainframes , and more mainframes .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8515</div><div class='noteText'>In short , Goldman could see , Xerox’s move into computers was shaping up to be the blind leading the blind . Not good . So he fired off a memo to McColough that very day . Yes , he wrote , Xerox did indeed need to go digital , and maybe something could even be made of SDS . But to accomplish either of those objectives , he insisted , Xerox needed a research center that could attract the new breed of computer guys — the kind of people who understood computing , who could really make progress in computing , who could carry Xerox to the forefront of computing . It was chutzpah , admits Goldman , but he sent the memo anyway . Whatever mistakes they’d made in buying SDS , he reasoned , McColough and Wilson had gotten the essentials exactly right : computers were the future . Moreover , they seemed like just the kind of people who could tackle that future head - on . “ Joe Wilson was one of the great men of the world , ” he says , “ just a very forward - looking individual . In those days , Xerox was a rare company . ” And indeed , says Goldman , even though his proposal did catch a bit of flak from the new Xerox board members from SDS — “ They wanted to use the money to build another Sigma mainframe , like the ones that weren’t selling , ” he says — Wilson and McColough liked the idea ; they had been a bit troubled by SDS’s mainframe mentality themselves . Go for it , they told Goldman . And that was pretty much that , he says — except for a few zillion details , such as figuring out how this new center would be organized , where it would be located , and who would run it .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8528</div><div class='noteText'>The corporate world was full of executives who believed that everything came down to numbers on a spreadsheet , and were convinced that a tough - minded guy who knew how to work those numbers could equally well run an automobile manufacturing plant , a copier company , a research lab , or anything else . That had been the attitude Robert McNamara promulgated at Ford when he headed the company in the 1950s . That was the attitude his protégés had retained throughout the 1960s , after McNamara went off to Washington to apply the numbers mentality to the Vietnam war , with such brilliant success . And that was the B.S . they were forever trying to impose on their corporate research labs . In company after company , you saw the numbers guys trying to justify the cost of research by demanding results in the form of new products this quarter , next quarter , and every quarter after that . And that was fine , says Goldman , if all you cared about was calculating cost / benefit ratios and building a slightly better widget . But if the medical community had tried to conquer polio that way , we wouldn’t have gotten a vaccine that stopped the epidemic in its tracks , because that vaccine was discovered only after years of failure , frustration , and blind alleys , none of which could have been justified by cost / benefit analysis . Instead we would have gotten the best iron lungs you ever saw .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8538</div><div class='noteText'>if Xerox really wanted to change the equation , then he had to find a lab director who really understood how to make that happen . In his own experience , the prescription was simple enough : hire the smartest people you can find and give them their head — but let them know who’s paying the bills . Putting that formulation into practice , however , was hard , expensive , and risky . It wasn’t enough just to hire a bunch of supersmart individuals . You had to build a community , a culture , an environment of innovation . You had to give your people the kind of challenge that would light a fire in their eyes , that would generate an atmosphere of nonstop intellectual excitement , that would let them feel in their gut that this is where the action is . You had to provide them with lavish resources — everything they needed to do the job , without stinting . And through it all , most important , you had to keep the bottom - line guys at bay so your guys could have the freedom to explore and make mistakes . Somehow you had to make the higher - ups accept that none of this would necessarily result in products the following year , or maybe even in five years . But in ten years you might just change the world .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8573</div><div class='noteText'>In any event , George Pake was Goldman’s man , and Goldman meant to get him . He sensed that the real problem , other than the fact that Pake really did love St . Louis , was that other recent offer from Ford : the bureaucratic miasma in Detroit had left Pake feeling leery of the whole idea of industrial research . “ So my purpose was to assure him that the attitude at Xerox was different , ” says Goldman . “ I told him that we had a much more progressive group of leaders . ” Well , maybe . As they parted — Goldman had to get on to Chicago — Pake did promise to think about it . A few weeks later , in fact , he even agreed to let Goldman fly him back to Rochester to meet McColough in person . “ McColough and I interviewed each other , ” Pake remembers with a laugh , “ and I guess we each passed ! ” Indeed , the CEO used all the right words : Xerox wouldn’t expect a product tomorrow , he promised . Nor would the lab be treated like the corporate fire department , with researchers ’ constantly being asked to drop everything and cope with crises elsewhere in the firm . Pake’s job would be to invent the company’s future .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8581</div><div class='noteText'>Once he was back home , says Pake , he “ did a lot of soul - searching over the Christmas holidays . ” He certainly didn’t want to leave St . Louis — but then , he says , “ how many chances do you get in a lifetime to found a new institution ? Especially when it seemed at the time to have very enlightened corporate support ? ” Not many , he realized . Then , too , he was forty - five years old already . “ I had just finished six or seven years as provost and executive vice chancellor of Washington University , and I was starting to receive feelers for university presidencies . That was flattering , but I didn’t want to go that direction — it would mean living in an academic - political goldfish bowl . ” But if not that , Pake wondered , then what ? Go back to hands - on research ? Presumably , though that’s not so easy when you’re in your midforties . Or he could say yes to Xerox . “ So I said yes . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8589</div><div class='noteText'>Pake and Goldman hit the road almost immediately , looking for a place to locate the new center . That was priority number one , says Goldman , even ahead of hiring the researchers : the kind of topflight people they hoped to recruit weren’t about to cut themselves off from their profession for the sake of Xerox . Unless the area around the new center featured a heavy concentration of cutting - edge computer firms , plus easy access to at least one major university that was strong in computer science , they simply wouldn’t come . Unfortunately , as Goldman had pointed out in his original memo , that criterion eliminated Rochester , New York , which wasn’t a computer center , as well as Goldman’s own favorite university choice , Yale , where the lab would have been right next door to Xerox’s brand - new headquarters in Stamford , Connecticut . In 1970 , the Yale computer - science department didn’t have anything like the strength it would later attain . Of course , that still left MIT , Princeton , and many other institutions nearby . But Pake felt strongly that the lab should be on the West Coast , if only to be within easy commuting distance of the company’s new computer division down in the Los Angeles Basin . Besides , Pake argued , the more he thought about it , the more he liked the idea of Palo Alto , California , and the area around Stanford University . For one thing , he had been a professor of physics at Stanford from 1956 to 1962 , and he still had good contacts on the faculty . But much more important was the industrial ferment just south of Palo Alto : down in “ the Valley of Heart’s Delight , ” as the Santa Clara had once been known , the prune and apricot orchards were sprouting semiconductor companies on every side . True , the area wasn’t yet a major computing center in a class with , say , Cambridge . But in the coming age of integrated circuitry , Pake maintained , it would become the epicenter of computing . “ Now , here’s where you have to give George credit , ” says an admiring Goldman . “ He really saw the Silicon Valley phenomenon emerging . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8619</div><div class='noteText'>So in 1957 , having had their fill of Shockley , and convinced that they could do far better working with a more tractable material , silicon , eight of his brightest young associates left to form a company of their own : Fairchild Semiconductor . They were right . Fairchild didn’t invent the integrated circuit itself ; that honor goes to Jack Kilby of Texas Instruments , who demonstrated his first device in Dallas on September 19 , 1958 . But less than a year later , in mid - 1959 , Fairchild cofounder Robert Noyce did devise a way to mass - produce integrated circuits by etching thousands of transistors simultaneously onto the surface of a single silicon wafer . This was the invention of the “ chip ” as we know it today . Fairchild prospered accordingly , especially after NASA selected its chips for the on - board computers in the Gemini spacecraft . By 1967 the company had twelve thousand employees and revenues of $ 130 million per year . Along the way , moreover , Fairchild achieved an even greater significance as the seedbed of Silicon Valley . Thanks to some overly meddlesome management by the company’s parent firm , Fairchild Camera and Instrument Corporation of New York , one group of employees after another started striking out on their own , eventually creating some fifty spin - off companies . Among these émigrés was Noyce himself , who teamed up in 1968 with another Fairchild cofounder , Gordon Moore of Moore’s law , to found a company they called Intel , short for “ integrated electronics ” ( fortunately for posterity , they rejected other candidate names such as Elcal , for Electronics of California , and Ectek , for Electronic Computer Technology ) . Intel’s first product , a sixty - four - bit solid - state memory chip , was not quite cheap enough or compact enough to compete seriously with magnetic - core memory — yet . But by the end of 1970 , the firm would come out with a 1,024 - bit memory chip that would be a very serious competitor indeed . And that was clearly just the beginning ; the way was open for a revolution in the economics of computing .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8648</div><div class='noteText'>Now — who was actually going to do the research at PARC ? The answer depended on which part of PARC you were talking about . Pake and Goldman had already agreed to organize the center into three separate laboratories , with the expectation that each would eventually grow to include about fifty people . And in the first lab , at least , Pake felt he knew what he was doing . The General Sciences Laboratory , or GSL , as they called it , would focus on basic research into magnetism , materials science , semiconductor physics , and the like — the experimental foundations of computer technology , which was Pake’s home turf . He knew exactly what kind of staffers he wanted there , and better still , he had a ready supply of them from within Xerox itself . When word had gotten back to the Rochester lab that the company was planning a new research center in a place that did not know the meaning of the word snow , there had been a sudden wave of enthusiasm for transfers .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8656</div><div class='noteText'>However , that still left the other two divisions of PARC , both of which would be devoted to computing itself . The idea was to have one of them — the Computer Science Laboratory , or CSL — concentrate on the deep principles and theoretical foundations of the field , and the other — the Systems Science Laboratory , or SSL — focus on the creation of large - scale applications . Now right away , stresses Pake , you can see how naive he actually was about computer science . When he used the word system , for example , he was still thinking in terms of something like a space shuttle or a jetliner : a complex , interdependent assemblage of hardware . It would be a long time before he understood that computer systems were critically dependent on software as well . Worse , says Pake , in trying to divide the two labs between basic and applied computer research , he was being led badly astray by his background as a physicist . At the time , he remembers , “ I was a bit baffled . I kept looking for these underlying principles of computer science ” — the analogs of Newton’s laws of motion , say — “ and I couldn’t find them . There were certainly some deep ideas — for example , information theory , or the Turing machine . But those ideas had not led to a large body of theory as there was in physics . ” The upshot was that his plan for the separation of the two labs just didn’t work , because “ both ended up doing applications . ” And in the long run , he admits , that confusion of responsibility would lead to some of his worst administrative headaches .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8700</div><div class='noteText'>Taylor was only slightly more inspired by the new laboratory’s director - designate . Judging from their earlier conversations at Washington University , Pake did seem to have a reasonably good understanding of the hardware aspects of computing . But Taylor wasn’t at all convinced that Pake understood the other half of the story , which was , well , not software exactly , but systems — how people actually used computers . “ I always thought that the physical side of computing was so damn boring because it was so predictable , ” says Taylor . “ Even in nineteen sixty - nine , you could know with great accuracy what the cost of an integrated circuit would be in ten years . But you couldn’t predict with any accuracy what you could do with it . ” That was what people like Vannevar Bush , J . C . R . Licklider , Wes Clark , and Doug Engelbart had always perceived so well , he thought . The real significance of computing was to be found not in this gadget or that gadget , but in how the technology was woven into the fabric of human life — how computers could change the way people thought , the way they created , the way they communicated , the way they worked together , the way they organized themselves , even the way they apportioned power and responsibility . That was what had resonated so deeply in Taylor’s mind . And that , in the end , was why he now found himself hoping against hope that this interview with Pake would work out . If this new laboratory could be kept from a fatal infection of SDS - itis , and if Pake could be made to understand what computing was really about , then there could be a tremendous opportunity here to make the dreams into something real .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8717</div><div class='noteText'>But if he had to name any one thing that did it , says Taylor , it would have to be the sight of those three typewriter terminals in his office at ARPA . “ You already had your very own terminal behind your desk , ” he explains , “ so why not your own small computer on top of your desk ? I started thinking about this around nineteen sixty - five or nineteen sixty - six . From the vantage point of the midsixties , you could already see computers getting faster , bigger , and , for a given size , less expensive . So the notion of sitting down and having your own machine was not a big leap . ” Indeed , Wes Clark had made that leap a long time before — as had Lick , Engelbart , and Vannevar Bush in their own ways , and no doubt many others as well . Even so , this notion of individual small computers wasn’t one that Taylor wanted to push very hard just yet . For one thing , in those ARPA days he was having enough trouble pitching his network idea . For another , he could remember twenty years back , when pundits were predicting that every garage would soon house a personal airplane ; twenty years from now , he figured , personal computers might sound just as silly . After all , falling hardware prices didn’t necessarily mean small computers ; they might just as easily mean million - dollar computers that were very large indeed . In twenty years we might even all be tapping into the giant computer utilities that Project MAC was dreaming of . And in all honesty , Taylor had to admit that that might make more sense . A world of desktop computers would sacrifice what he considered to be the very heart of interactive computing : connectivity , and the kind of on - line community that time - sharing provided for free .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8731</div><div class='noteText'>Once you got the network up and running , he wondered , why couldn’t you tie in desktop machines just as easily as you tied in big time - sharing mainframes ? That would give you back the connectivity you’d lost . And in the meantime , since you would no longer have to have all your computing done on a central mainframe , you could be giving every one of those desktop computers a powerful graphics capability , like the Kludge terminal up at MIT , or the IMLACs , or the displays that Evans and Sutherland were building in Utah . You could begin to get the kind of “ high - bandwidth , ” graphical interface that Lick was always talking about , along with quick response times , private storage space , and all the other advantages of stand - alone machines . So that was how the idea had grown , says Taylor — still nebulous , still a fantasy , but somehow getting more and more real all the time . While he was at Utah , in fact , he did a few back - of - the - envelope calculations : if you really took Moore’s law seriously , then computers small enough to sit on a desktop would be affordable in , what — ten years ? Soon , at any rate . Then how long after that before you had a computer small enough to sit on your lap ? Another ten years ? How long before there was one small enough to fit in your hand ? And how long before time - sharing was totally obsolete ? The exercise was an eye - opener , says Taylor . Individual computers with high - resolution graphics , connected by a network — this could really be the future . You just needed someone to take the lead and make the huge commitment of time , money , and manpower it would require . But it could be done . And this new research center at Xerox , if only the company could be kept from squandering the opportunity , might be just the place to do it .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8751</div><div class='noteText'>Gunning would be heading up the applications - oriented Systems Science Lab , said Pake , after he explained to Taylor about PARC’s three - part organization . Pake himself , for the time being , would be in charge of the physicists at the General Sciences Lab . And they wanted Taylor for the Computer Science Lab — but not , Pake emphasized , as its director . Without a research record of his own , Pake told him , he just wouldn’t command the necessary respect and authority . So instead , Pake proposed , why didn’t Taylor come to PARC as the associate director of CSL , and then help recruit his own boss ? While he was at it , in fact , why didn’t he help recruit the computer research teams for both his lab and Gunning’s ? Pake stressed that the position would give Taylor a big influence on the research at PARC , especially since he would be there long before his boss was . And then , he added , once the lab was up and running , he could start building up that elusive track record by starting a little research group of his own in , say , computer graphics . Now once again , says Pake , this proposal looks incredibly naive in retrospect . Quite aside from the implied insult to Taylor — that he was good enough to recruit the team members but not good enough to lead them — it promised to be extremely awkward for his eventual boss . People tend to be loyal to whoever hired them , not to “ outsiders . ” Still , it seemed like a good solution at the time . And in any case , Pake adds , “ my recollection is that Bob had no problem with it . ” No , he didn’t — though , as is so often the case with Bob Taylor , the reasons were more complex than they seemed on the surface . To begin with , while he very much liked the idea of having a big influence on PARC’s research , he considered Pake’s notion of a “ graphics research group ” a complete nonstarter . Sure , graphics technology was a critical part of this whatever - it - was he wanted to create . But so were text display , mass - storage technology , networking technology , information retrieval , and all the rest . Taylor wanted to go after the whole , integrated vision , just as he’d gone after the whole Intergalactic Network . To focus entirely on graphics would be like trying to build the Arpanet by focusing entirely on the technology of telephone lines . And yet Pake did have a point , damn it . At age thirty - eight Taylor had spent his entire adult career funding computer research , but he had never actually done computer research . And that mattered . Just look at what had happened back at ARPA : he had hired an “ assistant ” — Larry Roberts , Ph.D . — and then watched the whole community defer to Dr . Roberts as the Boss . So Taylor knew that he would have to bow to the inevitable on this one . He would come to PARC as associate director of CSL or not at all . On the positive side , he realized , there was a lot to be said for being the power behind the throne . After all , Taylor points out , “ if I were perceived as the lab manager , I would then have to spend a lot of my time with visitors and Xerox management — people from outside the lab . And in the early years I didn’t want that ; I knew I was going to have a lot to do , and many pieces to put in place . So if I could hire a manager for the Computer Science Lab , then I would be left free to work on issues that I cared about which were internal to the lab . ” Besides , Taylor reasoned , if he chose the right kind of manager , meaning one with ambitions to rise within Xerox , then the problem would solve itself in a few years . The guy would step up , and the mantle would fall to — well , by that point it wouldn’t matter whether or not Bob Taylor had a “ research track record . ” His team would have done such fabulous things that even Pake would see who the real leader was . And in the meantime , all he had to do was quietly recruit the right kind of people , set the right kind of agenda , and make PARC into the right kind of laboratory . His kind of laboratory . So Pake and Taylor shook on it . They had a deal — albeit not quite the same deal in each man’s mind .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8815</div><div class='noteText'>Number 3180 Porter Drive wasn’t much to look at . It was just a small , rented office building “ with rented chairs , rented desks , a telephone with four buttons on it , and no receptionist , ” remembers David Thornburg , who had just been recruited to the General Sciences Lab . The place was pleasant enough , in a California - modern kind of way ; the offices and conference rooms formed a rectangle that surrounded an interior courtyard and an attempt at a garden . But with the new recruits from Rochester and BCC only just now beginning to straggle in , PARC was empty . Too empty for Gary Starkweather . He’ll never forget that first day , he says , when he found himself standing alone in a vacant room , staring at the bare cinder - block walls , and wondering if he’d just made the biggest mistake of his life . Back in Rochester , after all , he’d had friends , family , and roots , not to mention a beautifully equipped optics lab . Here in Palo Alto he was three thousand miles from where he’d grown up . His wife and their two little children were strangers in the community . They were still in shock from the housing prices . And now here he was in this barren “ laboratory ” with the reality hitting him square in the face : he was going to have to rebuild everything . From scratch .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8826</div><div class='noteText'>Still , as Starkweather kept reminding himself , his prospects back in Rochester hadn’t exactly looked brilliant . When he’d first arrived there about a decade earlier , he’d been an eager twenty - something with a brand - new undergraduate degree in physics from Michigan State and a brand - new job with Bausch and Lomb , the optical company . “ I found out I was in a world of sophisticated optics technology I hadn’t imagined , ” he remembers . He found optics so fascinating , in fact , that he went back to school at the University of Rochester to get a master’s degree in the field . “ Then about a year into it , ” he says , “ I went over to work at this little start - up copier company called Xerox . ” He found plenty to fascinate him there as well . From the outside , the operation of a photocopying machine is simplicity itself : just place an original document facedown on the input glass , press the button , and out come the copies . On the inside , however , the machine is an elaborate system of lights , lenses , moving mirrors , and stationary mirrors , all working together to project an image of the original document onto the surface of a metal drum , the internal “ printing press ” that actually produces the copies . * So an optics maven like Starkweather could have a marvelous time in there , endlessly crafting new ways to make the optical system faster , better , cheaper , and more robust . And then when he wasn’t busy with that , he could pitch in on the long - range projects , where he could really get creative .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8897</div><div class='noteText'>On one issue , though , there was virtually unanimous agreement : with no terminals , no time - sharing system , no Arpanet connection — nothing but those bare , rented desks — PARC needed to get a PDP - 10 time - sharing system , and fast . Now , that does sound a little strange from the modern perspective , admits Lampson , especially when you consider what PARC would later accomplish . “ But we felt — I think correctly — that in order to do computer research in the nineteen - seventies , you really had to have time - sharing . There was already a sizable computer - research community supported by ARPA , with essentially everybody on PDP - 10s running the Tenex operating system . We felt it was very important to be part of that community . There was also a sizable base of software written for Tenex : networking , standard mail software , AI . We needed that base . So there was no significant debate about this . ” Not at PARC , perhaps . But when the folks at Xerox’s new computer subsidiary down in El Segundo heard that Lampson and company were about to buy a big - time computer from their arch rival , DEC , the screams could be heard all the way back east at Xerox headquarters . And in short order , the inevitable edict was heard out west in Palo Alto : no PDP - 10 . It didn’t help when Pake , under what he described as strong political pressure , suggested that they buy a Sigma 7 from SDS — which was now , significantly , known as XDS : Xerox Data Systems . Lampson and the other Berkeleyites gagged at the thought . The Sigma 7 couldn’t run Tenex or any of the Tenex software ; they’d be isolated . Sure , they could probably kludge together some kind of Tenex - compatible operating system . But that would take years . You could build a PDP - 10 faster than that ! You could start from scratch and — Well , why not ? The more Lampson , Thacker , and the others thought about it , the more the idea made sense . Having recently built one computer , the BCC 500 , they felt they could do a PDP - 10 clone pretty quickly . And by doing it at PARC , they would simultaneously be creating the in - house infrastructure they would need in any case . Machine shops , test equipment , well - stocked laboratories , a network of suppliers — they couldn’t do anything until they had all that in place . So they decided to forge ahead . They would soon take to calling the new computer MAXC , which officially stood for Multiple Access Xerox Computer , but which they deliberately pronounced with a silent C , in a not - so - subtle dig at SDS head Max Palevsky .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8933</div><div class='noteText'>Bob Taylor has often been described as a complex man , which is an understatement . But for someone who was admittedly feeling his way as a manager , making it up as he went along , he was a remarkably quick study . Those who found themselves under his wing at PARC almost universally remember it as the warmest , most supportive , and most exciting research environment they’ve ever experienced . “ Bob did have an enormous desire for control , ” says Gary Starkweather . “ Yet he was also one of the best managers I ever knew , because unlike some half - time researcher with a yen for power , he realized that his job was management . He took it seriously . And he knew how to handle people . ” Indeed , he says , even after Jerry Elkind arrived to take over formal control of the lab in July 1971 , it was abundantly clear that the CSL crew still regarded Taylor as their leader . They liked Elkind well enough , but they were Bob’s people . And it was equally clear that Bob Taylor took care of his own . If he liked you — and that could be a very big “ if , ” says Starkweather ; either you bought into his vision or you were an outsider — he would go to the wall for you . Resources , money , equipment , fierce advocacy before the higher - ups — they were yours .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8944</div><div class='noteText'>“ Taylor had a magical effect on the scientists — they cooperated and thrived in an environment they suspected could not exist without his leadership , yet they had difficulty articulating how and what Taylor did to keep the enterprise together . ” 1 Certainly that was Butler Lampson’s impression : “ Taylor is very good at getting . . . a collection of extremely intelligent and opinionated egomaniacs to work together reasonably well without fighting each other , ” he noted . “ Damned if I know how ! I can’t do it , but he does . ” 2 In fact , Taylor did it in part by knowing when to keep quiet . The kind of people he was hiring needed lots of room ; witness their determination to go ahead with MAXC regardless of anything he could say . “ Bob didn’t want people who had to be managed , ” says Alan Kay , who had served as a consultant to PARC since the previous fall . “ He liked people who were outspoken , who were very confident , who would argue back with him . And true to his word , he did not meddle with people’s technical decisions . His idea was that he was there essentially to manage the personalities , to keep people from killing each other . ” In practice , this meant a management style so carefully noninterventionist that visitors were often mystified by it — especially visitors used to the cool order of the executive suite . Under Taylor , the CSL wing of PARC sometimes seemed to have no organization whatsoever . There was no such thing as a standard workday , for example ; many of his recruits had immediately reverted to hacker’s hours , so that the building was sometimes as busy at 4 : 00 A.M . as it was at 4 : 00 P.M . Nor , for that matter , were there any ID badges in the Computer Science Lab ( Pake’s physicists had them ) . And there most certainly was no CSL organization chart , with formal team leaders and explicit lines of authority ; everybody was equal and reported directly to Taylor . What PARC had instead was posters and cartoons on the doors , rock tunes in the air , and ten - speed bicycles in the hallways — dozens of bicycles . As Richard Stroup would later recall , “ I would ride up to the lab and down the sidewalk and right in through the front door . Still on my bike , I would ride down the hall , park outside my office , work for the day , then get on the bicycle and ride down the hall and out the front door . ” 3</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8965</div><div class='noteText'>Taylor’s hands - off approach was just the most visible element of an exquisitely delicate balancing act , modeled on the one practiced by Lick and all his successors at ARPA . Yes , went the argument , people needed the freedom to create . But their creations had to add up to something — and not just another bunch of unconnected new gadgets , either . At ARPA that “ something ” had been human - computer symbiosis , broadly defined . Now , at PARC , it was the “ electronic office , ” whatever that might turn out to be . Yet in either case the goal was a system of information technology , a whole new way for human beings to work together . All of the various gadgets had to be part of that system . And to achieve that goal , Taylor knew , he somehow had to get all these maverick geniuses moving in the same direction , without forcing everyone to move in lockstep . Somehow he had to give them a sense of purpose and group cohesion , without crushing spontaneity and individual initiative . Somehow , in short , he had to set things up so they would freely follow their own instincts — and end up organizing themselves . This is arguably the fundamental dilemma of modern management , not to mention the fundamental political challenge in any democracy ; leaders have been grappling with it for centuries . Fortunately for Taylor , however , he had just spent the better part of a decade at NASA and at ARPA , which had provided him with any number of models . “ I’d traveled a lot , ” he says , “ talking with people , studying the culture of different sites , and learning how they functioned . I’d especially spent a great deal of time talking to the youngest people in the ARPA groups — the ones who were doing the work and who had most of the ideas . I had learned about their values , about what worked and what didn’t . So at Xerox , I put into practice what I liked and threw away the rest . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8979</div><div class='noteText'>One thing he definitely liked and put into practice was a style of research that could be paraphrased as , “ Don’t just invent the future ; go live in it . ” This had been the philosophy , too , behind Projects MAC and Genie , in which the time - sharing system was supposed to be simultaneously the main research tool , the primary object of experimentation , and the tangible product . For that matter , it had been Taylor’s own philosophy in pushing for the full - fledged Arpanet instead of just a few demonstration projects . By all means , Taylor told his recruits , let’s get way out in front of the curve — five years for sure , ten years if we can . And forget about the cost : Xerox is signing the checks for now , and Moore’s law will solve the problem soon enough . But whatever you build , use it . In fact , get everybody in PARC to use it . Get them pounding on the technology every day , writing reports , writing programs , sending E - mail — anything and everything , so they can see for themselves what the problems and the possibilities are . And then use what they learn to build better technology .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8988</div><div class='noteText'>That philosophy also reinforced another of Taylor’s initiatives : ARPA - style communication . Back when he’d taken over IPTO , in 1966 , Taylor explains , the challenge had been to maintain a sense of common purpose among research groups scattered across a continent . His solution then had been to revive Lick’s idea of the principal investigators ’ meetings , and later to expand it to include the graduate - student conferences . And his solution now , at PARC , was to do the same thing , but more frequently : once a week the computer group would assemble , someone would talk about his work for an hour or so , and then the others would have at him . Taylor considered these meetings so important , in fact , that he made them mandatory , the one thing that CSL members actually had to do . Visitors from the other labs were welcome , but for CSL , Tuesdays at 11 : 00 A.M . were sacrosanct .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 8995</div><div class='noteText'>Taylor also tried to keep the proceedings as easy and as informal as possible , to the point of having the conference room furnished with beanbag chairs . He even let the speakers set the rules for how each meeting would proceed , much as a card dealer could call the game in Las Vegas ; thus their nickname , Dealer Meetings . And when the arguments got heated , which they often did , the minister’s son would do his best to convert a “ class - one ” disagreement — one in which the combatants were simply yelling at each other — into a “ class two ” disagreement , in which each side could explain the other side’s position to the other side’s satisfaction . You don’t have to believe the other guy , he would tell them . You just have to give a fair account of what he’s saying . And it worked . As one CSL member later explained it , Taylor’s class one / class two exercise was amazingly effective at clarifying unspoken assumptions and ferreting out facts that one person knew and another didn’t . “ So by the time you get done , ” he said , “ you all know the same set of things , and you end up concluding the same thing . ” 4</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9019</div><div class='noteText'>Meanwhile , Jerry Elkind was joining in the spirit of the thing . As soon as he arrived , in July 1971 , he started recruiting a strong contingent from BBN , among them language maven Danny Bobrow ; Interlisp developer Warren Teitelman ; and eventually Bert Sutherland , the older brother of Ivan and successor to Bill Gunning as head of the Systems Science Lab . Elkind was also instrumental in luring Carnegie Mellon’s Allen Newell to PARC as a part - time consultant to the Systems Science Lab , where Newell began laying the foundations for a real science of computer - user interface design : What principles , he asked , what design techniques , what facts about human beings should designers take into account that could make computers easier to use ? In 1972 , moreover , Newell’s students Stuart Card and Tom Moran arrived at PARC with their freshly minted Ph.D.s and went to work in Bill English’s group , doing human - factors studies of the mouse , the graphics displays , and much else — and in the process pioneering the discipline now known as human - computer interaction .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9092</div><div class='noteText'>“ Head whirling , ” he continued , “ I found my desk . On it was a pile of tapes and listings , and a note : ‘ This is the Algol for the [ UNIVAC ] 1108 . It doesn’t work . Please make it work . ’ ” This was another Utah tradition , Kay learned . The newest graduate student got the latest dirty task to do . “ The documentation was incomprehensible , ” he wrote . “ Supposedly , this was the Case - Western Reserve Algol , but it had been doctored to make a language called Simula ; the documentation read like Norwegian transliterated into English , which in fact it was . . . . Finally , another graduate student and I unrolled the program listing 80 feet down the hall and crawled over it yelling discoveries to each other . ” Eventually they figured out that Simula’s authors — Kristen Nygaard and Ole - Johan Dahl , of the Norwegian Computer Center in Oslo — had designed it as a means to make it easier to create computer simulations , just as its name suggested . Their design incorporated two key ideas . First , like Sketchpad , Simula allowed the programmer to define data structures in terms of templates , or “ masters , ” that could then be used to produce as many special “ instances ” as needed — without the code’s having to be rewritten for each one . ( Think of the master plans for a Boeing 747 , say , which can be used on the assembly line to turn out specific aircraft outfitted for United , All - Nippon Airways , and so on . ) Second , like that unknown genius of an air force designer , Simula put each of those data structures together with all its procedures in a tightly integrated package , so that each structure “ knew ” how to respond to commands . In practice , this meant that a Simula programmer could model an oil refinery , say , in much the same way that he or she thought about a real refinery : not as a list of abstract data structures and equally abstract procedures , but in terms of valves , pipes , tanks , and whatever — tangible objects that had well - defined properties and characteristic behaviors . The potential gain in conceptual clarity was enormous . In a purely technical sense , of course , neither idea changed anything ; down at the level of bits and bytes , the computer would still have to grind through binary commands one step a time , just as computers had always had to do . To Alan Kay , however , Simula was a revelation — a whole new way to think about computation . “ For the first time , ” he recalled , “ I thought of the whole as the entire computer and wondered why anyone would want to divide it up into weaker things called data structures and procedures . Why not divide it up into little computers , as time - sharing was starting to ? But not in dozens . Why not thousands of them , each simulating a useful structure ? ” 9 Simula was not just a better old thing , Kay realized . It was almost a new thing — an entirely new way to structure computations . True , several more years would pass before he could clearly define what that “ new thing ” was , and how to make it real . But “ object - oriented programming , ” as Kay came to call it , was already there in embryo .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9129</div><div class='noteText'>But that just led to an even more electrifying thought . Two years earlier , said Kay , he had read ( and promptly forgotten ) Gordon Moore’s original article about the exponentially falling price of integrated circuits . But now Moore’s insight came rushing back , and “ for the first time , ” Kay wrote , “ I made the leap of putting the room - sized interactive TX - 2 . . . on a desk . I was almost frightened by the implications ; computing as we knew it couldn’t possibly survive — the actual meaning of the word changed . ” Instead of a world in which there existed at most a few thousand mainframe computers , all controlled by large institutions , Kay could now envision a world boasting computers by the millions . Computers under the control of no one but their owners . Personal computers . “ It must have been the same kind of disorientation people had after reading Copernicus , ” Kay wrote , “ [ when they ] first looked up from a different Earth to a different Heaven . ” 10</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9147</div><div class='noteText'>Kay wrote . “ I realized that the FLEX interface was all wrong . ” 11 So , more changes . And in the meantime , said Kay , his brain was taking still another direct hit . This one came about a month after he first saw Grail , when he paid a visit to Seymour Papert and his colleagues at the MIT AI Lab . The South African - born Papert , a disciple of the pioneering child psychologist Jean Piaget , was in open rebellion against the then - prevalent doctrine that learning had to be a matter of endless drill and rote repetition , as per the behaviorists . He likewise rejected the Industrial Age notion that education could be accomplished by systematically pouring knowledge into an empty vessel , as was implicit in the assembly - line organization of most American public schools . True learning , he insisted , required the active participation of the learner . True learning was a matter of curiosity and exploration — and the joy of discovering how each new experience fitted in with the web of memories , ideas , feelings , and sensations already in the mind . True learning , he was convinced , was what computers could bring to everyone . “ The computer is the Proteus of machines , ” Papert later asserted in his 1980 book , Mindstorms . “ Its essence is its universality , its power to simulate . Because it can take on a thousand forms and can serve a thousand functions , it can appeal to a thousand tastes . ” Indeed , he argued , with enough processing power and the right kind of interface , a computer could simulate marks on paper , paint on canvas , the “ motion ” encoded in film and television — any medium of expression that humans had yet devised . But much more than that , the computer could be dynamic and responsive in a way that no other medium had ever been . It could execute programs . It could respond to questions and experiments . It could engage the user in a two - way dialogue . To prove that assertion , Papert and collaborators in the BBN education - research group had devised a Lisp - like computer language known as Logo , which included commands to guide a robot “ turtle . ” The turtle’s great talent was to draw lines as it rolled around on a big sheet of paper ; the idea was to write a program telling it how to turn this way and that and thereby generate a picture of a house , say , or a flower . Logo also had commands for guiding a screen version of the turtle — less chance of a mechanical breakdown there — as well as for operating a simple music generator . By the time Kay came to visit , in fact , Papert and his colleagues were teaching Logo to elementary school children in the Lexington , Massachusetts , system . Kay , the lifelong rebel against convention , authority , and schools run like factories , was enthralled , especially when he saw how the kids were actually responding to Logo . “ First , ” he would write in a 1977 article coauthored with Adele Goldberg , even though computing is supposed to be a quintessentially “ grown - up , ” intellectual activity , “ the children really can write programs that do serious things . Their programs use symbols to stand for objects , contain loops and recursions , require a fair amount of visualization of alternative strategies before a tactic is chosen , and involve interactive discovery and removal of ‘ bugs ’ in their ideas . Second , the kids love it ! The interactive nature of the dialogue , the fact that they are in control , the feeling that they are doing real things rather than playing with toys or working out ‘ assigned ’ problems , the pictorial and auditory nature of their results , all contribute to a tremendous sense of accomplishment to their experience . Their attention spans are measured in hours rather than minutes . ” 12</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9177</div><div class='noteText'>By now , said Kay , his epiphany was upon him full force : “ As with Simula leading to OOP [ object - oriented programming ] , ” he wrote , “ this encounter finally hit me with what the destiny of personal computing really was going to be . Not a personal dynamic vehicle , as in Engelbart’s metaphor . . . but something much more profound : a personal dynamic medium . ” † And that , in turn , led directly to a “ clear romantic vision ” of what a personal computer should be . The Dynabook , he called it . “ I remembered Aldus Manutius who forty years after the printing press put the book into its modern dimensions by making it fit into saddlebags , ” he wrote . By the same logic , the Dynabook would have to be no larger than a notebook . “ Now it was easy to know what to do next . I built a cardboard model of it to see what it would look and feel like , and poured in lead pellets to see how light it would have to be ( less than two pounds ) . I put a keyboard on it as well as a stylus because . . . there still needed to be a balance between the low speed tactile degrees of freedom offered by the stylus and the more limited but faster keyboard . Since ARPA was starting to experiment with packet radio , I expected that the Dynabook , when it arrived a decade or so hence , would have a wireless networking system . ” 13 Kay’s direction was set . FLEX , alas , was only the first tiny step . ( Or maybe not so tiny ; Kay’s “ self - portrait ” drawing of the FLEX , circa 1968 , looks like a slightly overweight version of the Apple II microcomputer that would debut a decade later . ) But no matter . Once Kay had completed his 1968 master’s thesis and his 1969 Ph.D . dissertation at Utah — both devoted to FLEX — he went off to the Stanford AI Lab , where he spent far more time thinking about Dynabooks than he did about artificial intelligence . And then in September of 1970 , when he already had a deal about where to go next — Allen Newell and Gordon Bell had invited him to come build Dynabooks at Carnegie Mellon — he received a visit from an old Utah buddy named Bob Taylor .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9203</div><div class='noteText'>By this point , however , Kay had also had to admit to himself that he wasn’t going to get anywhere with his Dynabook notion until he’d gathered a group of researchers who could help him ; left to his own devices , he just didn’t have the temperament to finish up one idea before going charging off to the next . Fortunately , Bill English took him under his wing that summer and helped him recruit a team that would eventually include such stalwarts as Dan Ingalls , Adele Goldberg , and many others . The goal , Kay told them , was to design a programming system in which simple things would be simple , and complex things would be possible . “ I called it the Learning Research Group ( LRG ) to be as vague as possible about its charter , ” he explained . “ I only hired people who got stars in their eyes when they heard about the notebook computer idea . . . . When anyone asked me what to do , and I did not have a strong idea , I would point to the notebook model and say , ‘ Advance that . ’ ” 14</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9211</div><div class='noteText'>During that same summer of 1971 , meanwhile , Kay was refining his KiddiKomp idea into a new interim Dynabook design that he called the miniCOM . Among other things , it would feature a brand - new object - oriented programming language that Kay now called Smalltalk ( as in “ programming should be a matter of . . . ” and “ children should program in . . . ” ) . Thanks once again to Bill English , moreover , Kay and his brand - new group were also able to start experimenting with the miniCOM software without even having to build the corresponding hardware . It turned out that the émigrés from SRI were already working on their own vision of the electronic office . POLOS , as they called it — the PARC On - Line Office System — was partly a next - generation version of Engelbart’s NLS and partly an experiment in the use of video as a display medium . But the really great thing about the system , from Kay’s point of view , was that the POLOS terminals were actually high - resolution graphics consoles , modified by the addition of “ character generators ” that Butler Lampson and SSL’s Ron Rider had designed to produce text in a form suitable for a laser printer . Kay and his team soon learned that with a little creative hacking , the terminals could be tricked into generating a “ character ” that was actually a complex graphic image . So they plunged in gleefully and , during the fall , winter , and spring that followed , laid the foundations of the entire graphical user interface that would later be made famous by the Apple Macintosh and Microsoft Windows .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9228</div><div class='noteText'>Kay and POLOS’s Jeff Rulifson began kicking around ideas for “ iconic ” programming languages , which would allow kids to write their programs in terms of graphical symbols instead of as text . And to keep the screen from getting too crowded , the team found a way to let documents appear in separate but overlapping “ windows ” — a brainstorm that had hit Kay one day while he was in the shower , his favorite place to think . By May 1972 , in fact , Kay was so enthused by their progress that he wrote a proposal arguing that the time had come for PARC to build some interim Dynabooks for real ; he wanted to take them into classrooms and start working with actual children . Much to his dismay , however , the answer was no , on the grounds that a ) the concept was still too nebulous , and b ) MAXC still wasn’t finished . The PDP - 10 clone was costing a fortune , said the higher - ups , and PARC’s budget was only generous , not infinite . So Kay crawled away — “ licking my wounds , ” as he put it — and instead made plans for his group to keep on doing as much as they could with the POLOS machines . And that was still pretty much where things stood in September 1972 , he says , when Butler Lampson and Chuck Thacker dropped by one day from CSL .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9253</div><div class='noteText'>So it wasn’t until the summer of 1972 , when MAXC was pretty much done , that they had had a chance to look up , take a breath , and think about how they were actually going to achieve the electronic office . And in surprisingly short order , they found themselves in broad agreement : the electronic office should consist of small personal computers , running high - resolution graphics and linked together with high - bandwidth network connections — essentially the very same vision that Bob Taylor had been pushing from the start , the one they had once found so incomprehensible . This had largely been Taylor’s doing , says Lampson , though not through any obvious , do - it - my - way - or - else nonsense . Instead , Taylor had just subtly , but profoundly , shaped the whole context of their work . He had seeded PARC’s computer - science labs with products of the ARPA culture , people who felt the urge toward human - computer symbiosis in their bones . He had continued to expose them to provocative ideas ( “ Bob was always foisting Licklider’s papers on us , ” says Chuck Thacker . “ So by the time we finished MAXC , I had read the ‘ Symbiosis ’ article , which was where Lick had said it all , and which was probably one of the things that made Bob’s idea less inscrutable ” ) . And then , having done all that , Taylor was content to sit back in the Dealer Meetings and elsewhere and let his people function as a kind of self - exciting system . As Stu Card remembers it , “ There was this thread of ideas that led from Vannevar Bush through J . C . R . Licklider , Doug Engelbart , Ted Nelson , and Alan Kay — a thread in the Ascent of Man . It was like the Holy Grail . We would rationalize our mission according to what Xerox needed , and so on . But whenever we could phrase an idea so that it fell on this path , then suddenly everybody’s eyes would light up , and you’d hit this resonance frequency . ” Take graphics , for example : everybody resonated with graphics . They had Alan Kay right there , after all , constantly preaching his gospel of computers as the most richly expressive medium humans had ever known — and more to the point , showing them his group’s prototype font editors , drawing programs , on - screen document windows , and iconic programming systems . It was living proof of what you could really do with computer graphics . They likewise had Gary Starkweather and his laser printer : living proof that you could build up any image you wanted just by arranging tiny dots on a piece of paper — or on a computer screen . And they had the living example of Doug Engelbart’s NLS . “ You got this feeling sitting in front of one of Doug’s screens , and looking at his displays , that the computer image was as good as paper , ” says Lampson . “ And that was a revolutionary idea at the time . ” In the electronic office , whatever that turned out to be , the computer screen would have to be able to display text , diagrams , formulas , annotations , doodles — anything paper could display . If , of course , they could figure out how to make it do all that . This was in fact the challenge that had eventually led them to the idea of small , personal computers — albeit with a heavy emphasis on “ eventually . ” Although they’d all had a fine time listening to Alan Kay talk about Smalltalk and his Dynabook idea , says Lampson , “ we saw it as interesting from an intellectual point of view , not for building systems . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9288</div><div class='noteText'>Yet for all of that , says Lampson , it was MAXC as much as anything else that pushed them away from time - sharing . “ Here we had a state - of - the - art central computer of the day , ” he says , “ and it was perfectly obvious that it couldn’t do what we wanted it to do . ” The computational muscle required for high - quality graphics just wasn’t there , not when MAXC had to parcel out its memory and processing power to dozens of users at a time . In fact , says Lampson , he and his colleagues were increasingly coming to realize that the decision to focus on graphics displays undermined the most fundamental premise of time - sharing — namely , that computers are fast and humans are slow . As he would express it in a later account , “ [ This ] relationship holds only when the people are required to play on the machine’s terms , seeing information presented slowly and inconveniently , with only the clumsiest control over its form or content . When the machine is required to play the game on the human’s terms , presenting a pageful of attractively ( or even legibly ) formatted text , graphs , or pictures in the fraction of a second in which the human can pick out a significant pattern , it is the other way around : People are fast , and machines are slow . ” 15 And once they had realized that , says Lampson , the conclusion was all but inescapable : the only way the machine could hope to keep up with its user was by devoting the bulk of its computational power to running the display . Thus one computer per person .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9316</div><div class='noteText'>By the summer of 1972 , says Thacker , “ it was personal - computer time , just like it was railroad time in the eighteen - fifties . ” So : low cost , good performance , high - quality graphics . How were they going to do all that ? Once he’d finished his work on the MAXC hardware , says Thacker — Lampson and the others were still wrestling with the MAXC software — he set out in earnest to find some answers . His first step had to be graphics , he knew , since they were clearly the key to everything else . The distressing thing was that PARC was already full of graphics terminals — “ All of them expensive , ” he says , “ and all of them , in one dimension or another , crummy . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9350</div><div class='noteText'>Thacker remembers that it was Kay’s trick with the graphics on the POLOS terminals that suddenly brought it home to him . Yes , the cost of magnetic - core memory was prohibitive . But Thacker had just finished building a whole new computer , MAXC , using Intel’s new solid - state memory chips . And the cost of solid - state memory was going to fall fast , thanks to Moore’s law . “ That was the biggest ‘ Aha ! ’ experience about this , ” says Thacker . “ The realization that this semiconductor memory was inexpensive enough to devote a bit to every pixel and not go bankrupt . ” But that wasn’t the end of it . Having now produced an enormous simplification in the graphics with that first revelation , Thacker almost immediately experienced a second epiphany that would greatly streamline the basic computing hardware . In conventional machines , he explains , most of the complication came not from the guts of the computer itself — the central processor and the memory banks — but from peripheral devices such as the keyboard , the tape reader , the hard disk , and the display , those gadgets required for getting data in and out . Furthermore , much of their complexity lay in the elaborate interface devices , or “ controllers , ” that allowed each peripheral to communicate with the interior . But was all that specialization really necessary anymore ? Thacker wondered . Given the way prices were falling and processor speeds were rising , why not just build a bunch of very simple controllers and then let the computer’s central processor use software to do all the really hard work of input and output ? The result would be a kind of internal time - sharing , Thacker realized . The processor would still cycle very , very quickly among all its users , but now only one of those users would be human ; the rest would be input / output devices . “ The payoff , ” he explains , “ would be an enormous simplification of the machine . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9366</div><div class='noteText'>“ Once Chuck came up with the whole idea for the bit - mapped display , and how the machine could work as a stand - alone thing , ” he says , “ we couldn’t wait . It was just so obvious to us that this was the way to go , that this was the future . We didn’t care about time - sharing anymore . ” Alan Kay thought so , too . When Thacker and Lampson came by that September offering to collaborate on an “ Interim Dynabook , ” he didn’t hesitate for a minute . Here was the “ vector sum ” of his own dream of a graphical notebook computer , Lampson’s vision of a five - hundred - dollar PDP - 10 , and Thacker’s quest for a ten - times - faster Nova , all in a single , beautifully simple package . “ It was perfect , ” he said of Thacker’s elegant design . And Bob Taylor really thought so . “ As soon as I heard about the bit - mapped display , ” he recalls , “ I said , ‘ Yes ! That’s it ! ’ ” Of course , they were going to have to sell the idea to George Pake . And Jerry Elkind , for one , wasn’t at all sure how warmly Pake would receive it . After all , Bill English and his group in SSL were going full blast with their POLOS project , which wasn’t cheap . CSL itself had just dropped a bundle on MAXC . And now they wanted Pake to authorize twenty or thirty of these new personal computers at a cost of what , ten thousand dollars apiece ? Twenty thousand ? Add in network connections , laser printers , and all the rest , and you were looking at an outlay of around a million dollars . Personally , Elkind maintains , he was all for it . § But he insisted that the CSL crew had better be prepared to make a very strong case . Fair enough . To do that , however , they would first have to get a real machine designed and prototyped . They would have to develop a clear idea of what kind of applications could run on the thing . And they would most definitely have to come up with a better name than Interim Dynabook . That last point was one of Taylor’s particular obsessions . “ Good names for prototypes are very important , and very difficult to choose , ” Taylor explains . “ They should be familiar , easy to pronounce , easy to spell , have a broad theme , and conjure up pleasant feelings . ” In fact , he says , he’d never found a better source for prototype names than the Sunset Western Garden Book . In this case , moreover , he thought it might be nice to give their new computer an association with their home in Palo Alto . So . . . Well , that was easy . The Alto it was .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9404</div><div class='noteText'>in truth , Thacker admits , what he sketched out in that memo wasn’t a high - performance computer even by 1972 standards — especially not with only 128K of memory , which would later impose some pretty severe constraints on software for the machine . ¶ But then , it didn’t have to be high - performance . The Alto simply had to respond to its user faster than a time - shared PDP - 10 — which , for most problems , it would . Because it was a stand - alone machine , moreover , the Alto would be predictable , in the sense that you would never have to worry about too many users ’ logging on and slowing the machine to a crawl . As Jim Morris put it , the Alto was wonderful because it wouldn’t run faster at night .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9410</div><div class='noteText'>best of all , the simple , straightforward Alto hardware would be “ cheap . ” The initial estimate was that each new machine would cost about $ 10,500 , which was about half what PARC had already spent on MAXC per CSL member . So everybody in CSL could , indeed , have one . Once the memo started to circulate , the comments around PARC were favorable , if a bit lively . But Thacker was unfazed . “ I was an old pro , ” he says with a laugh . “ I had been in the field for five years ! ” He was also in a hurry : he had bet a bottle of wine with a vice president of XDS that he could get the new computer up and running within three months — and the clock had started ticking on November 22 , the date of his memo . Happily , however , Lampson , Ed McCreight , and several others volunteered to help , and by December they were well along with the detailed designs . By early 1973 they were hard at work with their soldering irons — all the laboratory facilities and technology they’d developed for MAXC paid off handsomely ; the MAXC memory boards , in particular , went straight into the new machine without modification — and as winter turned into spring , the first two Alto prototypes were taking shape with astonishing speed . True , admits Thacker , he didn’t quite win his bet — there was some debate about when the machine actually booted up — and he never got his bottle of wine . But he came pretty close . On April 1 , 1973 , as GSL physicist David Thornburg would later tell the story , “ I walked into the basement where the prototype Alto was sitting , with its umbilical chord attached to a rack full of Novas , and saw Ed McCreight sitting back in a chair . ” In the upper - left - hand corner of the new machine’s display , said Thornburg , in small type , were two words : Alto lives .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9442</div><div class='noteText'>Still , when it came to more substantive applications such as text editors or graphics packages , progress was slow ; no one wanted to start writing code until there was some real hardware to run it on . Lampson wouldn’t even have the initial Alto operating system ready until the autumn of 1973 , almost six months after the first two prototypes , and its first formal release wouldn’t come until March 1974 . And as for communications — well , Thacker concedes , he , Lampson , and McCreight hadn’t really focused on that aspect of the system . They did have some vague idea of linking the Altos eventually , if only to give individual users a way to fire off files to the laser printer . And of course , connectivity had always been another of Bob Taylor’s obsessions . The CSL deputy director kept insisting that their goal was not just personal computing but personal distributed computing : a web of interconnected machines that could support communication , collaboration , and the sharing of programs and resources — the kind of on - line community that had always been the best part of time - sharing . Somehow , Taylor told his people , you have to network these machines together ; otherwise , you’ll be taking a giant step backward , graphics or no graphics . Fortunately , however , Thacker and his colleagues didn’t really have to focus on communications . For something like six months now , PARC had had an experienced networking hotshot hard at work on the problem — a relatively new recruit by the name of Bob Metcalfe .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9455</div><div class='noteText'>In an odd sort of way , admits Bob Metcalfe , a lot of the credit for the network he developed at PARC has to go to the applied - mathematics department at Harvard University : he hated it . In fact , he’d spent his entire graduate career there staying as far away as possible — which was why he’d actually done his Ph.D . research for money , working on the Arpanet as a full - time staffer for J . C . R . Licklider’s group at Project MAC . And in the spring of 1972 , with his Ph.D . dissertation ready for Harvard’s formal approval , he thought he might finally be seeing the last of the place . Since graduation was slated for June , Metcalfe remembers , “ I went job - hunting . I got nine job offers , because I was in tight with ARPA and everybody wanted ARPA’s money . But I didn’t get the one I really wanted , which was to be an assistant professor at MIT . So instead I accepted an offer from Bob Taylor and Jerry Elkind to come out to PARC and put them on the Arpanet . My then - wife began ramping down her job . We went house - hunting in Palo Alto . We started packing for the move . My parents started planning to come see their son get a degree from Harvard . And then I went in to defend my thesis before my Ph.D . committee . ” To his utter horror , the committee rejected it . The professors wanted theory : mathematics , equations , lots of Greek symbols . What he had given them instead was practice : in effect , his subject was “ How We Built the Arpanet . ” Did he mention how much he hated Harvard ? Why had they waited until now to tell him there was a problem ? But there was nothing for it . He would have to start over , and he would most definitely have to forget about graduating in June . “ I had a lot of very embarrassing phone calls to make , ” says Metcalfe . “ The worst was to my parents . But the easiest was actually the one to Bob Taylor . He just said to come on out to PARC and finish my thesis there . ” At PARC , happily , the twenty - five - hour days left him no time to brood . “ So here I am , ” he says . “ As of July nineteen seventy - two , I’m the networking guy at PARC . I’m trying to write a new thesis . I’m putting MAXC on the Arpanet . I’m helping put together the ICCC Arpanet debut for October nineteen seventy - two . And I’m continuing to act as an Arpanet facilitator , helping other sites get on the Arpanet . ” This last task , especially , kept him in a more or less constant state of jet lag , which was how he happened to find himself in Steve Crocker’s guest room one night during a swing through Washington , D.C . , tossing and turning on the sofa bed . Desperate for something to put him under , he happened to catch sight of a thick blue volume on the bookshelf next to the bed : American Federation of Information Processing Societies Conference Proceedings , volume 37 , fall 1970 . Perfect . Metcalfe started reading “ The Aloha System , ” a paper by Norman Abramson of the University of Hawaii . It did not put him under .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9481</div><div class='noteText'>The Aloha system , he learned , was an experimental , ARPA - funded network that transmitted computer data via radio waves , instead of via the telephone lines used in the Arpanet . The University of Hawaii , he also learned , was a natural setting for such an experiment : its campuses on the various islands were separated by large stretches of open ocean , which made for telephone connections that were noisy , unreliable , and very expensive . Abramson’s paper accordingly described a network in which the main IBM System / 360 computer on Oahu sent packets of data back and forth to terminals out on the island campuses via radio . Serving as a front end to the 360 was Menehune , a small , packet - switching computer that handled the actual radio connections and that was similar in function to an Arpanet IMP . ( In Hawaiian legend , the menehune were strong , skillful imps who would work all night without stopping . ) Now , on the surface , Metcalfe could see , this was a matter of straight substitution : anywhere Arpanet had a wire , Alohanet had a radio link . Beneath the surface , however , when you got down to the nitty - gritty of how the packet transmissions were regulated , the differences were much more interesting . On the Arpanet , where the bits flowed through telephone lines , an IMP with packets to send could wait for a break in the traffic , so to speak ; that way , the packets never collided with one another . But on the Alohanet , where the bits were carried by staticky , interference - prone radio waves , a terminal with packets to send had no way of knowing what the traffic was like . It could transmit back and forth to Menehune ( with luck ) , but it probably couldn’t even hear what the other nodes in the network were sending . So , since waiting would be pointless , Alohanet allowed each terminal to fire off a packet to Menehune whenever it needed to , regardless of what the others were doing . If the terminal heard Menehune acknowledge receipt of that packet , then fine . But if it didn’t — meaning that another terminal’s packet had arrived simultaneously and turned the bits into gibberish — the first terminal would just back off , wait for a random interval of time , and then transmit its packet again . Since the second terminal would also be retransmitting , but with a different random interval , both packets now had a reasonable chance of arriving unscathed . Beautiful ! thought Metcalfe . It was control without control : the terminals were completely free agents , unregulated and unsynchronized by Menehune . And yet the packets got through anyhow . Or did they ? Alas , wrote Abramson , the system’s beauty came at the price of instability . Using a branch of mathematics known as queuing theory , he argued that Alohanet couldn’t use more than about 17 percent of the total capacity in its radio channel without causing a kind of chain reaction . Push it past that point , and each collision of packets would trigger the transmission of replacement packets , which would increase the probability of more collisions , which would generate more replacements — on and on until every packet was statistically guaranteed to hit another packet . The system would grind to a halt . By now , recalls Metcalfe , he was wide awake : this couldn’t be right . As he wrote about it later , “ The Abramson paper . . . made two assumptions about the computer terminal user behavior that , on Steve Crocker’s sofabed late at night , I found totally unacceptable . Abramson’s model assumed that there were an infinite number of terminal users , and that each of them would go on typing whether or not they received answers to earlier inputs . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9516</div><div class='noteText'>in November 1972 , with MAXC securely on the Arpanet , the coming - out party over , his thesis under control , and Chuck Thacker finishing his preliminary designs for the Alto , “ I took on the job of building a local network for the Alto . ” The requirements were straightforward enough , if a bit daunting . The new local network had to be fast , simple , and reliable . It had to be available everywhere in the building , without turning offices and hallways into a spaghettitangle of thick cables . It had to cost no more than 5 percent of the price tag of the Altos themselves . And it had to fit all its electronics on one of the Alto’s plug - in adapter cards . The most promising idea was to adopt the Arpanet packet - switching technology , as modified for coaxial cable . ( This was the same cable that would later become familiar to millions of cable - television subscribers . ) Not only was coax cheap , thin , and flexible , but it was much better suited to digital transmissions than long - distance telephones lines , which should translate into much higher data rates . True , noted Metcalfe , the modifications would have to include a replacement for the standard Arpanet control scheme , which had “ too many moving parts ” to work well at tens of millions of bits per second . But then it occurred to him : why not use the Alohanet scheme ? After all , he reasoned , a coax cable is essentially just a pipe that carries radio waves ( or TV signals ) , in much the same way that an ordinary pipe carries water . “ [ So ] instead of using thin air , ” he explained , “ or the ether as physicists used to call it , what if we used a long [ coax ] cable strung all over the building in an Alto Alohanet ? Any personal computer wishing to be on the network would simply tap into the cable and transmit its data packets into the cable’s ether . ” Moreover , it could do so at data rates of up to ten megabits per second , more than a thousand times faster than Alohanet itself . And if two or more computers found themselves trying to transmit packets at the same time , then they could do exactly what the Alohanet terminals did in that situation : they could each back off , wait a random interval , and try again — thereby resolving the conflict all by themselves . Indeed , Metcalfe realized , such an Alto Aloha Network could operate without any central control at all . It would have no central host computer , no network controller , no overall authority — just hundreds of personal computers , laser printers , servers , and other devices , all linked into a network by that “ one reliable , unpowered , ubiquitous medium , the ether . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9537</div><div class='noteText'>All through the ensuing winter and spring , while Thacker and McCreight were assembling their first two Alto prototypes , Metcalfe polished his new Ph.D . dissertation , continued with his Arpanet facilitator duties , and refined the design of his Alto Aloha Network to make it even more stable and even more efficient than it already was . Then finally , he wrote , “ on May 22 , 1973 , using my Selectric typewriter with its Orator ball ( which I then used instead of word processing to dash off short items ) I wrote up all this in a thirteen - page ( starting at 0 ) Xerox Sensitive memo . ” His memo was heavy with hand - drawn diagrams and handwritten annotations — one of them being “ ETHER ! ” — and it dropped the old name , Alto Aloha Network , in favor of a new phrase : the “ ETHER Network . ” “ If Ethernet was invented in any one memo , by any one person , or on any one day , ” says Metcalfe , “ this was it . ” Time to build a prototype . Along with David Boggs , a ponytailed Princeton graduate who was working part - time at PARC while he pursued his Ph.D . in electrical engineering at Stanford , Metcalfe went to work . Their goal was to get a one - hundred - node experimental Ethernet up and running within a year , he wrote : “ Dave and I were called the Bobbsey Twins . We used to work until we were exhausted , and would sleep until we woke , without regard for alarm clocks or the sun . ” Boggs , for one , became so absorbed by the challenge that he took a leave of absence from Stanford that fall ; he wouldn’t get back to earn his Ph.D . until April 1982 . And Metcalfe himself ? Well , he says , at least he was free of one distraction : in June 1973 , Harvard had finally accepted his heavily revised Ph.D . thesis ( “ without enthusiasm , ” he adds ) . But then he had quickly gotten caught up in another distraction : right down the hill , on the campus at Stanford , Vint Cerf was organizing a series of networking seminars that Metcalfe did not want to miss . The impetus had come from Bob Kahn at ARPA , who wanted Cerf and his fellow network mavens to figure out how packets could flow back and forth among Arpanet , Alohanet , and all other packet - switching networks that were beginning to spring up around the world . Kahn wanted these systems to connect with one another so seamlessly that they would form one gigantic , worldwide network of networks . Internetworking , he called the idea — a term that would later be shortened to “ Internet . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9563</div><div class='noteText'>Having already uprooted his life , moved , and bought a house in Washington , Kahn now found himself sitting in his brand - new ARPA office and wondering if there was any point in his even staying . And Roberts apparently felt almost as bad about the situation as he did . “ I remember Larry coming to me and saying ‘ Look , I know you didn’t want to work on networking anymore . But you know more about it than anybody else around , and that’s where our main efforts are going to be for the next several years . So why don’t you just go do that ? ’ ” Kahn shuddered at the thought . The compliment was kindly meant , he realized , if patently untrue ( “ Larry Roberts knew more about networking than anybody , ” he says ) . Still , he had to admit that Roberts did have a point . The Arpanet wasn’t unique anymore ; ARPA’s networking research had already started to embrace new media and new technologies . Packet - switched radio networks were one example , as in Alohanet . Packet - switched satellite links were another , as in a contract that Roberts had recently signed with BBN to create an orbital connection with Arpanet nodes in Europe . Moreover , there seemed every reason to believe that these could grow into major ARPA programs in their own right . After all , if the Arpanet could be sold to the Pentagon as an experiment in survivable , land - based command - and - control systems — a subject of deep and perennial interest to the military — then packet radio and packet satellite could just as easily be sold as experiments in survivable command and control for mobile forces . Hmm . Kahn began to get interested almost in spite of himself . “ So in the end , ” he says , “ I told Larry I would do it — but only the new stuff . Somebody else would have to handle the Arpanet . ” Done , said Roberts . And Kahn plunged in . He mapped out new initiatives on security and voice transmission . He started expanding the packet satellite program , to a point where it would ultimately include an international partnership beaming packets back and forth through the Intelsat IV satellite . He likewise planned a major expansion of the packet radio program , which would later encompass portable terminals that may have been the very first application of microprocessors in a military system .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9581</div><div class='noteText'>in very short order , he found himself tripping over one of those trivial - seeming things that start as afterthoughts and end up being the most profound and far - reaching issues of all : How was he going to get all these satellite networks and radio networks talking to one another and to the Arpanet ? How could he make the packets flow freely wherever they needed to go ? It certainly sounded easy enough . If you wanted to add a new packet satellite system , for example , all you had to do was connect a few ordinary Arpanet IMPs to satellite dishes , have the BBN team add a little bit of extra code telling the IMPs how to communicate with the satellites , and there you’d be , trading packets back and forth through the heavens . Indeed , this was essentially what Larry Roberts had had in mind when he commissioned BBN to do that first experiment with satellites . But then , Kahn wondered , what about packet radio links , as in Alohanet ? What about local networks , fiberoptics cables , infrared transmissions , and the whole vast array of communications technologies that no one had thought of yet ? Was he supposed to go back to BBN every time and ask for yet another software add - on ? Not if he could help it , thought Kahn . He could just imagine each new technology languishing in limbo until the BBN programmers got around to patching it in . The bottleneck would be horrendous . Worse , he knew , the various networks were optimized for very different environments . Arpanet , for example , lived in a world of comparative stability , with its packets flowing over fixed , reliable , land - based telephone lines . But packet radio lived in a world of chaos , with mobile transceivers forever moving in and out of range , getting cut off by hills and tunnels , and generally losing packets at every turn . The two systems had major incompatibilities in transmission speed , packet length , and almost any other parameter you could name . And even if the programmers could overcome such differences , the accumulating patches would only make the basic Arpanet software grow bigger , slower , more complicated , and more prone to bugs and failures — in short , everything it shouldn’t be . Imagine what automobiles would be like if we’d tried to integrate our transportation system this way : they’d be vehicles with rubber tires to drive down the highway , wings to fly through the air , streamlined , waterproof hulls to cut through the water , steel wheels to move along railways , on and on . It would be a Rube Goldberg mess . So no : total integration of the networks was bad management and bad engineering . Instead , Kahn realized , the right way to proceed was to disintegrate the networks . Start with the satellite portion , say , and carve it out completely . Make it into a separate network , in much the same way that air traffic is completely separate from the highway system . Give it its own IMPs , its own software , its own transmission protocols , everything . Then take that special satellite IMP that BBN was building and split it down the middle . On one side , put a standard Arpanet IMP , containing nothing but the standard Arpanet software . On the other side , put a new satellite IMP , containing nothing but the satellite software . And in between , put a “ gateway , ” a third computer whose sole job would be to translate Arpanet packets into satellite packets and vice versa . Think of it as being something like an airport terminal , whose main purpose is to help passengers transfer back and forth from highway travel to airline travel .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9608</div><div class='noteText'>More complicated ? In some ways , yes , says Kahn . “ There were lots of good reasons not to do it this way . With three boxes instead of one , the network would be less efficient , since each packet would have to go through three stages of processing instead of one . It would be more fragile , since now there would be three things to break instead of one . It would be more complex , more expensive — everything . But by doing this , you could constitute the satellite system as a separate network , which could be built , controlled , and operated by a separate entity . ” So long as both sides met the interface standards ( which were still to be defined ) , neither would have to know anything at all about the internal details of the other . You could simply plug them together through a gateway — much as you’d plug an appliance into a standard electric socket — and the packets would flow as needed . Moreover , you could just as easily plug in a third network — packet radio , say — and a fourth , a fifth , ad infinitum . Instead of a closed system , Kahn realized — that is , a single Arpanet dependent on a single operator — you would now have an open system , a network of networks that could , in principle , accommodate anyone .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9617</div><div class='noteText'>It would be several years yet before anyone actually used the word Internet , says Kahn ; at the time his phrase was “ interconnected network , ” or “ internetworking . ” And even in retrospect , he says , he has no idea when or how the notion hit him . Maybe it was just something in the air . After all , he had recently helped build the Arpanet , which was already an open system with respect to individual computers . As long as you had an IMP and met the 1822 interface specification ( written by one Robert E . Kahn ) , you could plug into the Arpanet with any computer you wanted , running any operating system you wanted , and the bits would still flow . A network of networks was the same principle , just one level up . Perhaps the idea also resonated with the open - software architecture of operating systems such as CTSS , Multics , and Unix , which gave users a standard interface for writing their own programs . Or perhaps it even resonated with Alan Kay’s notion of software objects , which would present a standard interface to the world while doing their own thing inside . But wherever the idea came from , it was an exceedingly potent one — as potent , in its own way , as the idea of an open marketplace guided by Adam Smith’s Invisible Hand , or the idea of an open democracy in which all human beings are created equal . If you wanted to be a part of the Internet , you could be : it would be open to anyone willing to deal in the common currency and / or speak the common language , as defined by the interface standard . It was this architecture of openness that would enable the Internet to undergo its explosive growth in the 1990s , when it would expand from a handful of users to uncounted tens of millions in less than half a decade . And it was this same architecture of openness that would continue to allow the Internet to flourish with minimal central authority . But all that would come later .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9671</div><div class='noteText'>Kahn and Cerf continued to hammer out the details of TCP / IP all through the spring and summer of 1973 , remembers Kahn . “ Then at one point during the summer of nineteen seventy - three we sat ourselves down for an entire weekend , working in a little room at what was then the Cabana Hyatt in Palo Alto , and just wrote the paper . ” “ The paper , ” which would eventually be published in 1974 as “ A Protocol for Packet Network Interconnection , ” 16 gave the first architectural description of how the Internet would function as a network of networks , with TCP / IP as the glue holding it all together . Indeed , “ the paper ” is why Kahn and Cerf are so often hailed today as the inventors of the Internet , to the extent that any two people can be singled out for that honor : this was pretty much where the Internet began .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9684</div><div class='noteText'>By December 1974 , Cerf and his group had turned the long deliberations into a detailed design for TCP / IP , which they circulated over the Arpanet as Request for Comments 675 . Shortly thereafter , Kahn awarded formal ARPA contracts for three independent implementations of TCP / IP : one to Cerf and his students at Stanford ; a second to Peter Kirstein and his students at University College , London ; and a third to Ray Tomlinson and his colleagues at BBN . And by the end of 1975 , all three versions were sending packets to one another without a hitch . True , nearly a decade would pass before TCP / IP was stable enough for ARPA to shift the whole Arpanet over to it . Then even more time would pass before the Internet truly began to take on a life of its own . But it was definitely a beginning .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9746</div><div class='noteText'>Indeed , computing on the Alto was computing as no one had ever experienced it before , except perhaps those lucky few who had used Sketchpad , or Grail , or one of their siblings . The combination of Alto’s wonderful graphics screen and its strange little “ mouse ” took the arcane abstraction known as software and transformed it into something visible , tangible , almost tactile . Users had the weird and eerily seductive sensation of reaching into the computer , of being able to grab what they saw there and manipulate it by hand . Thanks to the programmers , moreover , they found plenty to manipulate : icons , pop - up menus , drop - down menus , scroll bars , and windows - even overlapping windows that seemed to be stacked on top of one another like real , 3 - D objects ( “ I was in the seminar in which Dan Ingalls from the Smalltalk group demonstrated overlapped windows for the first time , ” says Stu Card . “ We all said OOOH ! ” ) . Smalltalk , not surprisingly , was far and away the sexiest piece of Alto software anywhere . It was more than just a programming language , after all ; it was the prototype interface for Alan Kay’s Dynabook , the complete environment for exploiting this miraculous new medium to its fullest . It was also quite explicitly intended for children . “ Early on , ” Kay noted in his history of Smalltalk , “ this led to a 90 - degree rotation of the purpose of the user interface from ‘ access to functionality ’ to ‘ environment in which users learn by doing . ’ ” The resulting user interface grew in fits and starts , as the programmers juggled the various tasks of “ feeding Smalltalk itself , designing children’s experiments , trying to understand iconic construction , and just playing around . ” Practically everybody at PARC offered opinions at one time or another . So did outsiders , so many of whom were intrigued by the software that Kay and his crew in the Learning Research Group had to cut back on the Smalltalk demonstrations just so they could get their work done . Adele Goldberg counted more than two thousand visitors in 1975 alone . Nonetheless , said Kay , the end result — Smalltalk - 76 — was a marvel : “ It was fast , lively , could handle ‘ big ’ problems , and was great fun . ” 17 It also looked fabulous . Smalltalk’s overlapping windows , its icons , its menus , and its mouse pointing device constituted a user interface that was more unified and more tightly integrated than that in any other Alto application — and that , moreover , would soon become very , very familiar to the rest of us . To see what it looked like , just glance at the screen of any Apple Macintosh , or any PC running Microsoft Windows : the descendants of that Smalltalk interface can now be found on tens of millions of computers worldwide .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9838</div><div class='noteText'>In fact , given Bob Metcalfe’s participation in the TCP / IP seminars down the hill , and his subsequent development of the PUP internetworking system in collaboration with Dave Boggs , it’s even possible to argue that PARC helped pioneer the Internet . But either way , a good case can be made that nothing fundamental about computing really changed between PARC’s 1970s golden age and the end of the 1990s , when the explosive growth of the Internet and mobile computing finally began a new paradigm shift . The intervening years brought drama and upheaval , yes , not to mention a very real revolution in our ability to deliver high - powered computing to a mass market . And yet for all the onrush of technology over that quarter century , and for all the many refinements and extensions of the basic ideas , there was very little fundamental innovation involved . The personal - computer revolution was mostly about mass - market technology’s catching up with the Alto - Ethernet — laser printer — GUI system that PARC had in place by 1975 . For the PARC researchers themselves , meanwhile , their vow to live in the future had paid off better than they could ever have imagined . And so by the mid - 1970s , with the Alto - Ethernet — laser printer — GUI system fundamentally developed , their main concern was , What’s next ?</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9870</div><div class='noteText'>On December 7 , 1972 — coincidentally , just a few weeks after Chuck Thacker had started work on the prototype Altos — Rolling Stone magazine ran a banner headline : “ SPACEWAR — Fanatic Life and Symbolic Death among the Computer Bums . ” In the article that followed , a thirty - three - year - old counterculture guru named Stewart Brand , the founder and publisher of The Whole Earth Catalog , recounted a wild - eyed night of Spacewar competition at the Stanford AI Lab , and then went on to proclaim the revolution . “ Ready or not , computers are coming to the people , ” he declared . “ That’s good news , maybe the best since psychedelics . ” Spacewar , Brand contended , was not just fun ; it also symbolized a profound shift in the nature of technology . Instead of continuing to be oppressed by remote , cold mainframes grinding out data for the establishment , he said , we were now moving into an era of humane computing . Playful computing . Spontaneous computing . Even subversive computing — a new age of microelectronics that would democratize access to information , help individuals organize for action , challenge the established order , and generally serve the People and not the System . “ Part of the grotesqueness of American life in these latter days is a subservience to Plan that amounts to panic , ” Brand wrote . “ What we don’t intend shouldn’t happen . What happens anyway is either blamed on our enemies or baldly ignored . In our arrogance we close our ears to voices not our rational own , we routinely reject the princely gifts of spontaneous generation . “ Spacewar as a parable is almost too pat . It was the illegitimate child of the marrying of computers and graphic displays . It was part of no one’s grand scheme . It served no grand theory . It was the enthusiasm of irresponsible youngsters . It was disreputably competitive ( ‘ You killed me , Tovar ! ’ ) . It was an administrative headache . It was merely delightful .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9891</div><div class='noteText'>“ OK , ” says a sighing Jack Goldman , who caught most of the flak on this one . “ So along comes the Rolling Stone article . The people in Stamford and Rochester who are jealous of our budget , and who are eager to take potshots at those guys sitting out in the beanbags , they say , ‘ Hey , you’ve opened the door for Xerox to be criticized , to be made fun of . The shareholders will be upset : we’re wasting their money . ’ Of course , they were using that as an excuse . It was really , ‘ Hey , you guys are wasting our money . ’ ” Now , this was never really a serious threat , insists Goldman , rumors at PARC to the contrary , and eventually it all blew over . “ Nobody ever threatened to shut PARC down , or to take the budget away , ” he says , “ because our budget was protected by the CEO . It just meant I had to defend how we did research — when we didn’t have any products yet . ” But never mind that , says Goldman . What he found truly distressing about the episode was what it symbolized : Xerox had changed . He’d been watching it happen almost from the day he arrived in December 1968 , Goldman explains . “ Remember , this was the period of Xerox’s phenomenal growth . In nineteen sixty - nine , the company’s sales crossed the billion - dollar mark . And because they were growing so fast , they had to create a whole new management staff to handle it . ” Indeed , the finance and administrative systems that Xerox had inherited from its slow - paced days as Haloid were nearing collapse . Copiers weren’t getting delivered , salesmen weren’t getting paid , logistics were breaking down everywhere . So , with their company on the verge of being rained by its own success , Wilson and McColough had hired a string of top - rank executives from what were then considered the two best - run corporations in America . One was IBM , which contributed mainly marketing people ; the other was Ford Motor Company . “ Finance types , ” says Goldman with an almost audible shudder . “ McNamara protégés . ” These were the guys he’d hoped to leave behind when he left Ford . And now these were the guys who had come pouring in right behind him at Xerox . Now , in all fairness , Goldman concedes , the new recruits did give the Xerox management a much - needed overhaul , and they did keep the company from choking on its own growth . But that actually became a big part of the problem : success reinforced their own worst instincts . Talk about subservience to Plan — these were numbers guys , who thought that letting people pursue wild and crazy ideas was tantamount to letting them play in a sandbox ; who thought that nothing was real until they could reduce it to entries on a spreadsheet ; who thought that everything could be predicted , analyzed , controlled , and managed . At one point in the mid - 1970s , Goldman recalls , “ I tried to explain Moore’s law to one of them . Twice the power for half the price , and so on . Well , the guy just couldn’t understand it . He said , ‘ Nothing could follow that kind of law ! ’ ” Still , he says , the numbers guys were little more than an irritation — until November 22 , 1971 , when the chairman of Xerox’s board , Joe Wilson , suddenly died of a heart attack . The company was left in shock and mourning , for Wilson had been its true visionary , its guiding spirit since the Haloid days . Indeed , it was Wilson who had seen the promise of xerography in the first place , just as it was Wilson who had been willing to gamble his company on the technology , and who had then imbued the explosively growing Xerox with his own transcendent vision . “ It is frightfully important for man to communicate with his fellow man , ” he declared in a film that was shown to newcomers all through the sixties , when that message seemed to have a special urgency . “ And this is the very heart of our business . ” Indeed , it was Wilson who had first seen the need to move Xerox into computing , as a way of embracing a whole new form of communication .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9922</div><div class='noteText'>without Wilson — well , says Goldman , the company had been placed in the hands of two excellent men : Peter McColough , who stepped up to become chairman , and finance chief Archie McCardell , an early Ford recruit who became the new president . They were imaginative , daring , insightful — everything that Joe Wilson’s successors ought to be . Both of them , in particular , were strong supporters of PARC . Nonetheless , says Goldman , two good men together can’t equal one great man , a truism that was demonstrated anew just a few months later , in the spring of 1972 , when McCardell decided to reorganize Xerox along functional lines . Henceforth , he decreed , all of Xerox’s manufacturing and new - product development , for both computers and copiers , would be handled by an Information Technology Group to be headed by James O’Neill , one of the former finance men from Ford . Disaster . It wasn’t that O’Neill was a bad guy personally , says Goldman . “ Jim had a wonderful sense of humor and was fun to be with — if you were talking with him about anything but business or politics . ” But as soon as O’Neill stepped into the executive suite , Goldman maintains , he became “ the real villain of the piece , ” a numbers guy to end all numbers guys . He was an absolute wizard at controlling costs , forecasting production volume , and calculating profit . But he knew nothing whatsoever about engineering , or manufacturing , or research , or even researchers ; to him they were all just factors of production . Shortly after the reorganization , for example , some administrators at the government’s Lawrence Livermore nuclear laboratory happened to hear about Gary Starkweather’s prototype laser printer , the one that he’d retrofitted into a Xerox 7000 photocopier , and became so intrigued that they offered to lease five of the machines as a test . In effect , it was an offer to help Xerox jump - start a whole new line of business . But when Goldman excitedly took the news to O’Neill , the numbers - guy - in - chief simply sharpened his pencils . Let’s see , figuring in the historical maintenance costs on the 7000 , times 5 , times the life of the contract — ouch ! Xerox might lose as much as $ 150,000 here . Sorry .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 9950</div><div class='noteText'>In any case , there was worse to come . In early 1973 , Xerox decided to reinvigorate its nearly moribund Office Systems Division , the group that had responsibility for developing noncopier products . The company saw some major opportunities ahead , notably in the office word - processing market , which had been heating up since the introduction of IBM’s Magnetic Tape Selectric Typewriter in 1964 . To help shake the division out of its doldrums , Xerox planned to move it as far away as possible from its current site in Rochester . The question was , where to ? To Goldman , there was only one conceivable choice : Silicon Valley , which was where the action was , and where the product - development people could be right next to PARC . It’s true that the Alto was still brand - new , he says . But even so , you could already sense the riches that would soon be pouring out of PARC . Having the Office Systems Division right next door would make for an incredible synergy . The development group would be working directly with researchers out on the very cutting edge of technology — even as it kept those researchers grounded in what real offices needed . It would be an unbeatable combination ; Xerox would own the office of the future . Goldman made the case as urgently as he could . But few people at headquarters were listening to him anymore : the numbers guys had long since gained the upper hand , and the research chief had found himself slipping steadily down the hierarchy . By 1973 he was no longer reporting directly to the president , but to a marketing executive . And in any case , the decision was largely up to Jim O’Neill , who had been sharpening his pencils again . He had his people do a hard - nosed , bottom - line analysis of the Bay Area versus another site they were considering in Dallas , taking into account labor costs , land costs , taxes , the works . And of course , with that hard - nosed analysis effectively assigning a value of zero to unquantifiable factors such as propinquity , synergy , and the paradigm - shifting power of new technology , Texas kept coming out ahead . So in April 1973 , just as Thacker and McCreight were booting up their first prototype Altos , Xerox announced that the Office Systems Division would be relocating to Dallas . Multidisaster . Instead of synergy , with a smooth flow of PARC technology into the marketplace , Xerox got a rivalry . Once the Office Systems Division was established in Dallas , the engineers there explicitly rejected the PARC approach and went off in their own direction , designing an electromechanical word processor that was safe , familiar — and obsolete before it was built . Goldman still has trouble controlling his temper when he thinks about it . The Dallas decision was “ the one clear fuckup ” in the whole story , he says . “ By nineteen seventy - four , PARC had the Alto , the Ethernet , and the laser printer in daily operation . We could have had desktop publishing right there . But the schmucks in Rochester and Stamford and Dallas didn’t understand that . ” In fact , he maintains , if he hadn’t thrown a tantrum , they might just have rejected the laser printer itself — the one PARC - bred product that would eventually earn billions for Xerox and repay its investment in PARC many times over . By 1974 , the Product Review Committee at Xerox headquarters finally decided that yes , the company would market a computer printer . But what kind ? Well , says Goldman , “ a bunch of horse’s asses who didn’t know anything about technology were making the decision , and it looked to me , sitting there a week before the selection , that it was going toward CRT technology ” — that is , the photocopy - a - TV - screen approach that Gary Starkweather had abandoned a decade earlier . Apparently , some people felt that lasers were death rays that shouldn’t be allowed in Xerox products . “ It was Monday night , ” recalls Goldman . “ I commandeered a plane . I took the planning vice president and the marketing vice president by the ear , and I said , ‘ Clear your Tuesday calendars . You are coming with me to PARC tonight . We’ll be back for the eight - thirty meeting on Wednesday morning . ’ The guys at PARC , bless them , did a beautiful presentation showing what the laser printer could do . ” It worked , sort of . Goldman went into the fight with a strong ally : Jack Lewis , the head of Xerox’s printer division , who was already such an ardent champion of Starkweather’s creation that he had twice refused direct orders to kill its development . And now , having kicked the tires , so to speak , the committee members did indeed endorse laser printing . Yet there were still delays , says Goldman . “ They wouldn’t let us get them out on 7000s . Instead they insisted on going with the new 9000 series , which were high - end machines that wouldn’t come out until nineteen seventy - seven . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10017</div><div class='noteText'>Still , one of the things that the PARC crew didn’t understand ( or refused to understand ) was that Potter was expected to come up with a product by the following year , not in five years . Nor did they seem to grasp that the electromechanical system favored by Potter was technically mature , familiar to customers , and much , much cheaper than PARC - style personal computing — which was still in the early prototype phase in any case . By subjecting Potter to one of their Dealer Meeting firestorms instead of listening to what he had to say , they quite effectively squandered any chance of influencing Xerox’s second - and third - generation word processors . “ I went out there and sat in their beanbags , ” Potter later recounted . “ But I couldn’t get anything out of them . I even told them I was their savviest , best customer in the corporation . But they were only interested in their own thing . They thought they were four feet above everybody else . ” 22 Visibly miffed , Potter went back to his own division and thereafter refused to have anything more to do with PARC and its self - satisfied princelings .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10062</div><div class='noteText'>In the aftermath of the Vietnam disaster — not to mention the sixties - era culture wars , and now , heaven help us , the unfolding scandal of Watergate — the miasma of suspicion , mistrust , and hostility lay thick over Washington . And for ARPA , at least , it had taken on a tangible form : the Mansfield Amendment . Passed by Congress in the fall of 1969 as a rider to the Fiscal Year 1970 Defense Department Authorization Bill , the amendment decreed that the funds in question could be used for research only if there was “ a direct or apparent relationship ” to a specific military function . “ Of course , it was really a way of cutting the defense budget by alleging that a lot of it wasn’t relevant , ” says Lukasik . “ And of course , hardly anything was eliminated because , in fact , the department had been pursuing relevant research . But everyone who was in the research business stood on their head , and for a year we wrote relevance statements . ” Technically , of course , the Mansfield Amendment was in effect only for that one year . Nonetheless , it sent a powerful message that Congress was watching , and that ARPA officials would no longer be trusted to make judgments on their own . † † In retrospect , moreover , it came to be seen as the symbolic watershed for ARPA , the point at which it started its downhill slide from being a cutting - edge agency that was blessedly free to take risks to being an ordinary agency that was cautious and risk - averse . “ It was the end of Eden and the beginning of the real world , ” says Stanford’s Ed Feigenbaum . Another such moment came in 1972 , when a bureaucratically inspired reshuffling of the Defense Department’s organization chart gave ARPA the new name DARPA : the Defense Advanced Research Projects Agency . Of course , as Lukasik points out , this change was utterly meaningless in any practical sense . Certainly no one on the inside ever used the new name , except on the official stationery ; he personally thought “ DARPA ” sounded like a dog food and told his people to ignore it as much as possible . Nonetheless , the import of that D was inescapable : “ defense relevance ” was the order of the day , and Big Brother was watching .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10080</div><div class='noteText'>IPTO clearly needed a capable leader . Yet no one seemed willing to brave the political minefields . “ Finally , ” he says , “ we were sitting around one day , racking our brains , and somehow the suggestion came up : ‘ How about Lick ? He’s such a good guy , he won’t turn us down . ’ ” No one was eager to ask him , says Lukasik — “ and I mean that as no reflection on Lick . He was our last resort because this was like asking somebody to take a second tour in Vietnam . But in the end we had to go back to him because nobody else would come . ” Thus Larry Roberts’s call to Lick in the summer of 1973 : Would he ? Could he ? Lick accepted without enthusiasm , undoubtedly thinking of all the administrative paperwork he’d wanted never to see again . In the two years since he resigned the directorship of Project MAC , he’d had a fine time working on dynamic modeling . Still , he told Roberts , if you really need me to do it for the good of the community , I will . “ So I told him that I’d keep trying to find somebody else , ” says Roberts , who was painfully aware of what he was asking of the older man — and equally aware of what a disaster Lick had been as head of Project MAC . “ And I did try for months . But in September of nineteen seventy - three I had to take him up on his offer . Telenet was going to file with the FCC the next day for permission to be a carrier , and I had to be there . ” Roberts got on the phone again and at last tracked Lick down in Wales , where he was on a driving tour with Louise . “ OK , ” Lick sighed . And it was set : Roberts’s successor would officially start work in January 1974 . “ I never saw Larry so overjoyed as when he finally got his replacement , ” says IPTO financial officer Al Blue , who would serve as acting director for the interim . Of course , Blue adds , he himself was pretty happy , too , albeit for a slightly different reason . “ When you were working with Larry , ” he says , “ you came into the office and you hit the ground running , and you did not quit running until the whistle blew , and then you ran some more . So as much as I loved working for Larry , I thought , Well , Lick is going to be different . Lick is relaxed . He is a gentleman . ” But alas , says Blue , when Lick arrived in January 1974 , the reality was more akin to a Christian’s being fed to the lions : “ We would go up to the director’s office and it would be , ‘ Give me an analysis on this , and a complete budget rundown , and do this and do that and have it up here by four o’clock . ’ And we would go back to our office and Lick would say , ‘ This is not the ARPA that I knew . ’ ” It wasn’t — and Lukasik , who could remember the old days , too , was sympathetic . “ By Lick’s second time around , ” he says , “ we had budgets , line items , relevance statements , people crawling all over our back . I never asked him , but I’m sure he would have said , ‘ It’s not fun like it used to be . ’ ” Then , too , Lick at age fifty - eight was not the man ARPA had known : physically , if not mentally , he was growing old and frail . His allergies had long since crossed the line into asthma — he never went anywhere without an inhaler — and his hands had a noticeable tremor . “ Although he was extremely well motivated , ” says Steve Crocker , “ it showed through : he just didn’t seem to have the energy anymore . ” Happily , though , that was one problem Lick’s boss could solve . Reaching down into ARPA’s nuclear - monitoring research office , Lukasik brought up an army colonel named David Russell to serve as Lick’s deputy . The mild - mannered but very capable Colonel Russell soon had everything quietly under control . And Lick , now blessedly freed of doing any but the highest - level paperwork , was able to do what he did best , which was set the tone and direction of the office . Of course , notes Steve Crocker , to people who were used to the hyperenergetic , do - it - all - myself style of Larry Roberts , their new office director looked suspiciously like a figurehead — honored , respected , and listened to , to be sure , but not really in charge . The real power , they believed , lay in the hands of Dave Russell . But whatever the truth of that perception , Lick himself probably didn’t care : he’d made a promise to be here , and he felt duty bound to keep that promise . As Tracy Licklider points out , his father also had a very personal stake in the outcome : “ His feeling was , ‘ I’ve invested a lot in creating the ARPA community , and I don’t want to see it backslide . ’ ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10141</div><div class='noteText'>Lick must have been deeply disturbed to hear an Ed Feigenbaum talk about “ keeping his head down . ” He could certainly understand the impulse , since at various times almost everyone had drawn a bead on ARPA’s artificial - intelligence program : Congress , the upper echelons of the Pentagon , even Lukasik , though the ARPA director had eventually become a cautious supporter . The payoffs just seemed to be so speculative , and far off . Nonetheless , the current climate was making researchers timid . And maybe worst of all was that it was making them view one another as rivals instead of colleagues . “ In the early days , ” notes Vint Cerf , “ ARPA could build a community because ARPA could afford to support everybody . But when there is scarcity , you don’t have community ; all you have is survival . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10404</div><div class='noteText'>Maybe that was why they got so excited when they heard about Boca — the Xerox World Conference , scheduled for November 1977 in Boca Raton , Florida . As the first company - wide gathering of Xerox managers in six years , the four - day conference would showcase the company’s newest and shiniest products , including its first commercial laser printer , the just - introduced Xerox 9700 , which would soon become one of the company’s hottest sellers . And it would build toward the grand finale of Futures Day , a celebration of all that had been achieved at the Xerox Palo Alto Research Center . Back at PARC , says Starkweather , he and his colleagues saw this as their last , best chance . “ The feeling was , ‘ If they don’t get this , we don’t know what we can do . ” So , he says , with John Ellenby coordinating an all - out effort , “ we stripped everything out of PARC down to the power cords and set it all up again in Boca . Computers , networks , printers — the whole thing ! I built a laser printer that did color . Bill English had a word processor that did Japanese . We were going to show them space flight ! ” They certainly tried . On Thursday , November 10 , 1977 , Xerox executives and their families swarmed through the Grenada Rooms of the Boca Raton Hotel for a hands - on demonstration of WYSIWYG editing in Bravo , graphical programming in Smalltalk , E - mailing in Laurel , artistry in Paint and Draw — the works . “ The idea was a mental slam - dunk ! ” says Starkweather . “ And some people did see it . ” The executives ’ wives , for example — many of them former secretaries who knew all about carbon paper , Wite - Out , and having to retype whole pages to correct a single mistake — took one look at Bravo and got it . “ The wives were so ecstatic they came over and kissed me , ” remembers Jack Goldman . “ They said , ‘ Wonderful things you’re doing ! ’ Years later , I’d see them and they’d still remember Boca . ” Then there were the delegates from Fuji Xerox , the company’s Japanese partner : they were beside themselves over Bill English’s word processor . “ Fuji clamored , ‘ Give us this ! We’ll manufacture it ! ’ ” recalls Goldman . In fact , he says , that was a near - universal reaction : “ People from Europe , people from South America , marketing groups around the U.S . — everyone who went out of that conference was excited by what they had seen . ” Everyone , that is , except the copier executives , the real power brokers in Xerox . You couldn’t miss them ; they were the ones standing in the background with the puzzled , So - What ? look on their faces . “ Oh , ” they would say as their wives waxed rhapsodic over on - screen cut - and - paste . “ It does that ? ” Chalk it up to bad timing , says Starkweather . “ Savin had just come out with its desktop copier . So maybe that caused an attention deficit . ” Indeed , one of the corporation’s purposes in calling this conference was to rally the troops for the coming era of ever - more - ferocious competition . In fairness , those executives in the background had to worry about defending the homeland now , not ten years from now . Or maybe they were simply too bound by the culture of the executive suite , vintage 1977 . The xerographers lived in a world in which typing was women’s work and keyboards were for secretaries . It was a rare executive who would even deign to touch one .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10431</div><div class='noteText'>But whatever the reason , says Starkweather , it was disheartening . “ Right afterward , it felt like a Moon launch : ‘ We did it ! ’ But in the next few weeks and months that followed , when it became clear that nothing was going to happen , dejection set in . What did we have to do to get this across ? But we all had some projects on the back burner we could go work on , and sulk . ” George Pake was disappointed , too , in his characteristically measured way : “ Boca Raton was not as much of a turning point as we’d hoped , ” he says . Jack Goldman , meanwhile , was exasperated : Damn straight it wasn’t a turning point , he says . “ There was this feeling of exhilaration after Boca — then bingo , the meeting was over , and nothing happened ! ” Bob Taylor , for his part , was disgusted : “ I watched them just stand there , ” he says of the executives , still gritting his teeth all these years later . And Steve Lukasik ? He was long gone : Xerox had already stretched his slim reserves of patience past the breaking point . Yes , the company’s core business was threatened , he says . But from his point of view , the reaction had been panic , and a rush to abandon the future . “ Just about the time I came on board , ” he says , “ money became tight . I’d tell them , such - and - such will cost ten million dollars . They’d say , We can’t give you ten million , how about five million ? Then in the next budget cycle they’d cut it to three million . After that happened five , six times , I realized they would never let me do what they’d hired me to do . In fact , all they wanted to talk about at the head office was the next - generation copier . Instead of developing the electronic office , I was supposed to tell them about how to feed the paper , do the stapling , and so on . ” So in June 1976 , says Lukasik , with the Systems Development Division barely a year old , he walked . “ It had been fun , ” he insists . “ I don’t regret a single minute at Xerox . ” Nonetheless , he says , his eighteen months there have to be judged a failure — “ a failure at the personal level by people like me , a failure of imagination on the part of the xerographers , and a failure at the highest level of management . Xerox never got organized for this . And perhaps Peter McColough didn’t organize it . ” But then again , he says , it’s worth remembering that everybody in the computer business was stumbling its way through the 1970s , not just Xerox . Computation had once been a scarce resource ; now , thanks to the microchip , it was fast becoming an abundant one . And not even the most imaginative visionaries had fully grasped the implications of that fact . Certainly nobody knew for sure what would fly in the marketplace — not PARC , not DEC , not IBM , and not even the hobbyists in the garages of Silicon Valley . In that environment , all anyone could do was try things out , see what worked and what didn’t , and continue to explore the unknown .</h3>
<h2 class='sectionHeading'>Chapter 9:      Lick’s kids</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10541</div><div class='noteText'>Lick did much the same for the students in his Dynamic Modeling group . “ I always felt that he liked and respected me , ” says Tim Anderson , “ even though he had no reason to : I was no smarter than anybody else . I think everybody in the group felt that way , and that was a big part of what made the group the way it was . ” Lick was definitely the spiritual and intellectual leader , agrees Al Vezza , who was now the titular leader . Lick somehow made his people feel that by playing around and having fun with computers , they were actually building something much larger than themselves . He would happily sit for hours , spinning visions of graphical computing , digital libraries , on - line banking and E - commerce , software that would live on the network and move wherever it was needed , a mass migration of government , commerce , entertainment , and daily life into the on - line world — possibilities that were just mind - blowing in the 1970s . Let’s be optimists , he wrote in 1979 , on one of those rare occasions when he committed such a scenario to paper . * Let’s assume that Moore’s law will continue to work its magic as it has in the past , and now let’s imagine ourselves in the year 2000 : “ Waveguides , optical fibers , rooftop satellite antennae , and coaxial cables provide abundant bandwidth and inexpensive digital transmission both locally and over long distances . Computer consoles with good graphic display and speech input and output have become almost as common as television sets . ” 1 Great . But what would all those gadgets add up to , Lick wondered , other than a bigger pile of gadgets ? Well , he said , if we continued to be optimists and assumed that all this technology was connected so that the bits flowed freely , then it might actually add up to an electronic commons open to all , as “ the main and essential medium of informational interaction for governments , institutions , corporations , and individuals . ” Indeed , he went on , looking back from the imagined viewpoint of the year 2000 , “ [ the electronic commons ] has supplanted the postal system for letters , the dial - tone phone system for conversations and teleconferences , stand - alone batch - processing and time - sharing systems for computation , and most filing cabinets , microfilm repositories , document rooms and libraries for information storage and retrieval . ” This vision of the “ Multinet , ” as Lick called it — the term “ Internet ” didn’t really exist yet — was his synthesis of all the thinking and talking and writing that had gone on about the on - line world within the ARPA community since his “ Symbiosis ” paper in 1960 . The Multinet would permeate society , Lick wrote , thus achieving the old MIT dream of an information utility , as updated for the decentralized network age : “ Many people work at home , interacting with coworkers and clients through the Multinet , and many business offices ( and some classrooms ) are little more than organized interconnections of such home workers and their computers . People shop through the Multinet , using its cable television and electronic funds transfer functions , and a few receive delivery of small items through adjacent pneumatic tube networks . . . . Routine shopping and appointment scheduling are generally handled by private - secretary - like programs called OLIVERs which know their masters ’ needs . Indeed , the Multinet handles scheduling of almost everything schedulable . For example , it eliminates waiting to be seated at restaurants . ” Thanks to ironclad guarantees of privacy and security , Lick added , the Multinet would likewise offer on - line banking , online stock - market trading , on - line tax payment — the works .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10622</div><div class='noteText'>“ I’d never liked time - sharing , ” Dertouzos explains . “ Maybe it was the Greek in me , but it seemed like a socialist kind of sharing , with central control , like forcing everyone to ride a bus as opposed to driving a personal automobile . And I’d never liked the information - utility notion , which I first heard from Fano . Information isn’t natural gas . It doesn’t come from one place , or a few places . It comes from all over . It’s much more of a commodity . But now , with the networks , we were moving away from a centralized - brain metaphor to a system without centralized control — a heterarchy . So in nineteen seventy - six or so I was looking for a metaphor for how the machines in such a system would interact with each other . Being Greek , I thought of the Athens flea market , where I used to spend every Sunday , and I envisioned an on - line version : a community with very large numbers of people coming together in a place where they could buy , sell , and exchange information . So every year I would push this information - marketplace idea to the lab members . And every year I would get lots of negative reaction . One , it was too far out conceptually . For most of them , it seemed completely far - fetched to go beyond the log - in / log - out interface for networking and try to establish some broader concepts . And two , the on - line marketplace just didn’t seem like it was computer science ; it was more a fruity sociopolitical thing . It wasn’t so much that they fought the idea . It was more like — suppose we had just invented the car , and I was asking them to study the social implications when they were still focused on the engine and trying to make it go from twenty miles per hour to thirty miles per hour . In fact , my recollection is that until about nineteen - ninety , almost the whole world was oblivious to these ideas . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10725</div><div class='noteText'>Nonetheless , Lick wrote in his “ Multinet ” article , he was still an optimist . Even if you couldn’t automatically look to the private sector or to the government for leadership , you still had — well , the People . At least when it came to computing , he wrote , “ there is a feeling of renewed hope in the air that the public interest will find a way of dominating the decision processes that shape the future . ” 5 Just look at E - mail , the Arpanet mailing lists , and all the rest , he said . Just look at the on - line communities that seemed to come into being wherever there was a network . Users of a modern computing system weren’t just passive consumers ; the medium itself drew them in . It gave them a forum , it made them active participants , it gave them a stake in deciding their own destiny . So if you could somehow expose ordinary people to this medium — if you could somehow get the technology out of the laboratory and into the mass market so they could experience it firsthand — then ordinary people might just create this embodiment of equality , community , and freedom on their own . It was a vision that was downright Jeffersonian in its idealism , and perhaps in its naïveté as well . Nonetheless , Lick insisted , “ the renewed hope I referred to is more than just a feeling in the air . . . . It is a feeling one experiences at the console . The information revolution is bringing with it a key that may open the door to a new era of involvement and participation . The key is the self - motivating exhilaration that accompanies truly effective interaction with information and knowledge through a good console connected through a good network to a good computer . ” 6</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10780</div><div class='noteText'>The PDP - 8 , as it came to be known , was a significant gamble for the firm : the machine that had inspired it — Wes Clark’s LINC — was barely out of its development phase itself . No one knew how much of a market there really was for such a machine . As it turned out , however , the timing was auspicious . The watchwords for the PDP - 8 project were price ( low ) , size ( small ) , and performance ( high ) ; semiconductor and storage technology was ripe for advances in all three areas . For many applications , in fact — the major exception being arithmetic on very large “ floating point ” numbers , where the machine’s twelve - bit architecture proved to be a severe bottleneck — the PDP - 8 would have no problem living up to DEC’s trade literature , which proclaimed it “ one of the fastest computers in the world . ” 8 It would also be one of the cheapest to manufacture . “ We set out to study all the technology used for home appliances and automobiles , ” says Olsen . “ I went to several discount stores for hours , studying every single washing machine , drier , and stove to see how they built things and what we could use . The switch handles [ on the circuit boards ] came from a Maytag dryer . Using a glass panel without separate lights showing was the technology used in appliances . Inside , we used the slip - on connectors that were commonly used in automobiles . We tried every way we could to take the technology that made mass production possible in appliances . ” The result was a computer so unbelievably small and light — at just 250 pounds — that it could be transported in the back seat of a Volkswagen Beetle convertible . ( For those who didn’t believe that claim , DEC ran an ad providing photographic proof : smiling model in front , PDP - 8 in back . ) More to the point , it had an unbelievably low price of eighteen thousand dollars , complete with Model 33 Teletype terminal . True , that wasn’t exactly pocket change , especially not in the 1960s . But it was just under one sixth the price of the PDP - 1 , and far cheaper than anything in the IBM catalog . To customers , most important , it was irresistible . No sooner had the machines started shipping in April 1965 than they started flying out of the Mill , winding up in chemical plants , newspapers , laboratories , refineries , and schools . Much to the astonishment of DEC staffers and everyone else , even nontechnical users loved a computer they could get their hands on . One PDP - 8 controlled the digital scoreboards at Boston’s Fenway Park ; another ran the streaming news display in New York City’s Times Square . There was even a PDP - 8 — based time - sharing system : TSS / 8 , created at Carnegie Mellon University .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10838</div><div class='noteText'>Along the way , meanwhile , all of these increasingly high - powered minicomputers had rolled right over the faltering “ computer utility ” industry . After all , why should anybody pay upward of ten dollars an hour in connect charges per user — twenty thousand dollars for a year of eight - hour days — when that same money would buy a mini that could support a dozen users ? ( Most of the utility companies quickly folded ; the idea wouldn’t really revive until the 1980s , when modem - equipped microcomputers started tapping into newer , network - based utilities such as CompuServe and America Online . ) And out in the labs , by no coincidence , those same new - generation minis were inciting users into open revolt against the tyranny of mainframes — a process that Steve Wolff calls the slaughter of the whitecoats .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10849</div><div class='noteText'>Ah , but then the minicomputers came along , the high - tech embodiments of individual autonomy , hands - on control , and freedom . Naturally , says Wolff , the computer centers tried to have them outlawed . “ But there were many groups that stormed the bastions and slaughtered the whitecoats . They discovered that they could buy a computer cheaply — a PDP - 8 , a PDP - 11 , or , later , a VAX — and run it themselves . It wasn’t as fast as a mainframe . But they could turn it on and let it run all weekend . ” Sure , he says , you still needed mainframes for big - time number - crunching ; IBM wasn’t going broke , and neither was Seymour Cray , with his “ supercomputers . ” But for your small - to mid - size groups , such as university departments , research labs , and even many businesses , the in - house mini rapidly became the computer of choice in the 1970s . It was glorious fun , Wolff remembers . Then , around 1974 , Unix came along , and suddenly you could get your hands on the software , too . “ Unix was the first really general - purpose operating system for minicomputers , ” he says . “ It took off for two reasons . One , it was free . And two , Unix was the first operating system you could get source code [ the full list of programming commands ] for . You could hack it . ” Actually , Unix was “ free ” only because AT &amp; T wasn’t allowed to sell it ; until the breakup , in 1982 , the company was a regulated telephone monopoly and as such was barred from doing much of anything in the computer business . But Unix was hackable because it was about as open as a system could get . Order the data tapes ( nominal charge : $ 150 for materials ) , and you got the complete source code , which was yours to modify as you wished . Dennis Ritchie and Ken Thompson had created Unix for their own use back in 1969 , after Bell Labs ’ withdrawal from the Multics partnership , and the project had retained that loose , hands - on feeling ever since . Then , too , Ritchie and Thompson had created Unix with hacking in mind , deriving its basic structure from Fernando Corbató’s CTSS via Multics — namely , a tool kit of utilities and software routines that the user could call upon to perform specific tasks , all built on top of an invisible “ kernel ” of software that functioned as the autonomic nervous system of the computer , seamlessly moving bits through the machine at a level below the user’s consciousness . The difference was that the Unix kernel was a marvel of efficiency , simplicity , and conciseness . This was partly a reaction against the complexities of Multics ( the designers kept the features that seemed truly useful , such as the file structure , and left out the more baroque elaborations ) and partly a reflection of Ritchie and Thompson’s ancient and underpowered PDP - 7 , the only machine they could scrounge for the project . But mainly Unix was tightly written because that was how the two men felt a kernel ought to be : sweet , quick , and clean . When Ritchie and Thompson were finally able to migrate their system to a PDP - 11 in 1970 , they weren’t even tempted to add extra bells and whistles .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10875</div><div class='noteText'>They followed the same aesthetic with the software tool kit . Each routine — “ copy , ” for example ( abbreviated cp ) , or “ print ” ( pr ) — was designed to do one specific thing as efficiently as possible . But the routines were also designed to be connected together like so much plumbing — literally . By February 1973 , when they made their first public presentation of their system , Ritchie , Thompson , and the other members of their steadily growing Unix group had data flowing from one component to the next through software constructs known as pipes . The result was a Unix environment in which it was very easy to connect simple routines on the fly to form more complex utilities . At the time of that initial presentation , there were just sixteen Unix installations in the world , all inside AT &amp; T . Within six months , as word spread outside the company , that number had tripled . Of course , sometimes you had to get down into the bits and bytes and compose a completely new software tool . But that was pretty easy , too , especially after Ritchie completely rewrote the Unix kernel in an elegant new computer language of his own devising . Since he’d based it on an earlier , experimental language by Thompson , code - named “ B , ” Ritchie code - named his language “ C . ” The name stuck . By July 1974 , when the written version of their presentation came out in the journal Communications of the ACM , the team had rewritten key elements of the software tool kit in C , and Unix had taken a long stride toward the nirvana of “ machine independence . ” In principle , all you had to do was take the free Unix source code , run it through a C compiler for your specific brand of machine , and you’d have a Unix operating system that worked just as well on your machine as it did on the PDP - 11 .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10897</div><div class='noteText'>Indeed , the users quickly turned Unix into the People’s Operating System , “ open software ” that would flourish through the 1970s in much the same way that its descendant , Linux , would do in the late 1990s . Moreover , at Ken Thompson’s alma mater , Berkeley , where he spent a sabbatical year in 1975 spreading the gospel , a quietly brilliant graduate student named Bill Joy was soon leading a covey of like - minded Unix mavens on a quest to make Unix more usable by and more accessible to nontechies . By decade’s end , their Berkeley System Distribution 4.2 Unix was emerging as a semiofficial standard in the community , complete with an endorsement from ARPA itself . And Joy and his crew had been commissioned by that same agency to integrate TCP / IP into Unix . To help with all this sharing of information , meanwhile , another group of Unix mavens were putting together a “ poor man’s Arpanet , ” a.k.a . Usenet . That innovation began in the fall of 1979 , when graduate students Tom Truscott and Jim Ellis , along with a number of their friends at Duke and at the nearby University of North Carolina in Chapel Hill , were looking for a way to communicate with their fellow Unix enthusiasts on - line ( Truscott had just returned from a marvelous summer at Unix heaven , Bell Labs ) . Neither school was on the Arpanet , unfortunately , but Truscott , Ellis , and their friends realized that they could just cobble together a little bulletin - board utility based on the Unix version of E - mail . True , communications would have to run over 300 - bit - per - second modems , but still , the system worked . After several revisions and a complete rewrite in C , moreover , not to mention some help from sympathizers at both Bell Labs and DEC , it worked quite well . In January 1980 the Duke - UNC cabal presented its “ rapid - access newsletter ” at a national meeting of Usenix , the Unix users ’ group . At first , Truscott noted in the written announcement , most messages would probably be concerned with “ bug fixes , trouble reports , and general cries for help , ” 10 but the system could also support other newsgroups if there was enough interest . There was . Slowly at first , then more and more rapidly , Usenet became living proof of a prediction that Lick and Bob Taylor had made back in 1968 , in their article on the computer as a communications device : “ Life will be happier for the on - line individual because the people with whom one interacts most strongly will be selected more by commonality of interests and goals than by accidents of proximity . ” 11 Newsgroups proliferated . There was net.unix - wizards , for example , and net.chess , and fa.human - nets — the last devoted to the implications of worldwide networking . ( The prefix fa stood for “ from Arpanet . ” The naming scheme with the dots was invented by Duke graduate student Stephen Daniel ; it has since been refined into now - familiar categories such as comp for computers , rec for hobbies , and alt for anything goes . ) By 1981 the ad hoc Usenet encompassed something like 150 sites around the country . And among them , significantly , was Berkeley , where Usenet had gained its first portal to the Arpanet . This , in turn , opened it to the already flourishing world of Arpanet mailing lists , such as the legendary “ SF - Lovers ” list for science - fiction buffs . By the mid - 1980s articles were flowing both ways , newsgroups were proliferating madly — today they number in the tens of thousands — and Usenet was well on its way to becoming Network News , an integral part of the Internet .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10970</div><div class='noteText'>And so it was that the field was left open for the hobbyists in their basements and garages , individuals who didn’t have to worry about meeting payrolls and pleasing the stockholders but just liked to play around with electronics — and were used to making components do things their manufacturers had never imagined . These were the same kinds of tinkerers who’d gotten creative with DEC’s first transistor modules in the 1950s , who’d fallen in love with the PDP - 8 in the 1960s , and who were snapping up the programmable calculators now . They were the spiritual brothers of the MIT hackers and the freewheeling Unix mavens . They were the people who had been ham - radio operators and / or stereo buffs since they were teenagers , often using equipment they had built themselves from mail - order kits , or from scratch . They were the guys who had gotten intrigued by the minicomputers they’d encountered at work or at school . And for no “ logical ” reason whatsoever — certainly none that they could explain to their spouses — they were the people who wanted computers of their own at home , to play with , to experiment with , to experience . Enter the Altair . Now , the Altair was not the first commercial microcomputer ; that honor goes to the Micral , an Intel 8008 — based machine that was sold in France starting in May 1973 . Created by Vietnamese immigrant Thi T . Truong , the two - thousand - dollar Micral sold fairly well for a time but was marketed only on the Intel model , as an industrial process controller . The Altair wasn’t even the first microcomputer kit to appear on the cover of a general - interest electronics magazine . That honor goes to the Mark - 8 , another 8008 - based machine , designed in the fall of 1973 by Jonathan Titus , then a graduate student in chemistry at the Virginia Polytechnic Institute in Blacks - burg , Virginia . Hard - core hobbyist that he was , Titus never even thought of starting a company ; he just wanted to share his creation with his fellow fanatics . So he wrote to the hobbyist magazine Radio - Electronics , which always tried to offer its readers at least one construction project every month . The result was that magazine’s cover story for July 1974 : “ Build the Mark - 8 : Your Personal Minicomputer . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 10989</div><div class='noteText'>the Altair was the first commercially successful microcomputer . By no coincidence , it was also the first to be based on the Intel 8080 , which really was a major advance over the 8008 . The father of the Altair was H . Edward Roberts of Albuquerque , New Mexico , a thirty - four - year - old electrical engineer who was a big man not only physically — he stood six foot four and weighed 250 pounds — but in his intellectual appetites as well . He once described himself as the kind of guy who devoured whole library shelves at a time . Mostly , however , Roberts was fascinated by electronics . In 1969 , while he was still an air force captain working at nearby Kirkland Air Force Base , he and several of his colleagues founded a hobbyist shop called Micro Instrumentation Telemetry Systems , or MITS , which mainly sold radio transmitters for model airplanes through the mail . Then , in the early 1970s , after leaving the air force and buying out his partners , Roberts branched out into mail - order electronic - calculator kits . These sold pretty briskly until the rapidly falling prices of commercial models made them pointless . So in early 1974 , with some twenty - five employees now on his payroll and a company that was suddenly facing bankruptcy , Roberts elected to try a computer kit . He’d always been interested in digital electronics , he later explained , and he’d been wanting to try his hand at building a minicomputer anyway . He proceeded to rough out a design using the Intel 8080 , which he’d decided was by far the best chip available . And by midyear he was ready to approach the editors of Popular Electronics , where he’d been an occasional contributor , to ask if they’d like to feature his kit as a construction project . They would . The magazine was Radio - Electronics’s arch rival , and technical editor Les Solomon just loved the idea of an 8080 - based computer project that would top the Mark - 8 story . The only ground rules were that the end result had to be a real computer , not a toy like the Mark - 8 , and the kit had to cost less than four hundred dollars . The price was feasible ; Roberts had already talked Intel into selling him the 8080 chips for just seventy - five dollars apiece in bulk . So he and his codesigners at MITS went into overdrive to get the Altair ready in time . Solomon , meanwhile , came up with the perfect name for the machine . ( Looking for ideas , he asked his daughter , Lauren , what they called the computer on Star Trek . “ Computer , ” she replied . But she added that the starship Enterprise was headed for the star Altair that night , so why not call it that ? )</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11075</div><div class='noteText'>But wherever the notion came from , it was obviously in the air by January 1975 . As Popular Electronics put it in the editorial that introduced the Altair , “ we’ve been reading and hearing about how computers will one day be a household item . . . for many years . ” By 1976 , moreover , some of the start - up companies were visibly taking this prospect seriously . A different kind of customer meant a different kind of product , they realized . Instead of just providing a kit , a bag of parts , they would have to offer something much more like an appliance : a finished system that would work as soon as you plugged it in . Keyboard , monitor , disk drives , operating system , software — everything had to be right there in the box , or else be very easy to add . On the hardware side , this challenge was taken up most famously by the Apple Computer Company , founded in 1976 by Homebrew Computer Club members Steve Wozniak and Steve Jobs , longtime buddies from the Silicon Valley town of Cupertino . After some encouraging success with their first computer , which they marketed through local hobby shops — it was actually just a single circuit board using the new , 8 - bit 6502 microprocessor from MOS Technology , plus 4 kilobytes of RAM — Jobs and Wozniak were joined by the thirty - four - year - old A . C . Markkula , formerly the marketing manager for Intel . Markkula , who had retired from that company two years earlier after earning more than a million dollars in stock options , bought a one - third partnership in Apple for $ 91,000 and began working his contacts to bring in venture capital and management expertise . The result was the Apple II , a much - upgraded , 6502 - based micro that was introduced in April 1977 at the first West Coast Computer Faire in San Francisco . Apple’s new machine was a beautiful thing to behold , with a built - in keyboard and a professionally designed beige - colored case . It was comparatively cheap , in that a configuration with 16 kilobytes of RAM and no monitor cost just $ 1,195 . It was easily expandable , with plenty of empty slots for add - on cards . It was the focus of an imaginative ad campaign masterminded by the Palo Alto firm of Regis McKenna ( an early ad called it “ The home computer that’s ready to work , play , and grow with you ” ) . And perhaps most important of all , it was great for playing video games ; Wozniak , the technical wizard of the team and a video - game addict himself , had designed it with precisely that use in mind .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11159</div><div class='noteText'>Even Lick was pleased by Infocom’s success , says Tracy Licklider , who himself worked at VisiCorp ( the maker of VisiCalc ) during this period and later served as president of the Boston Computer Society . It wasn’t that his father ever cared about money per se , he says , but Lick was certainly happy for his former students ’ sake . And he was enthralled by the sight of his “ self - motivating exhilaration ” going mass - market at a speed and on a scale that he had never thought possible . Millions of people had grown up thinking of computers as big machines , mysterious machines , omniscient , cold , and relentless machines . But now those same people could walk into their local ComputerLand and see all these little machines . It was as if the computer had been reinvented before their eyes : the pitiless HAL 9000 of 2001 : A Space Odyssey had become the Computer for the Rest of Us , an instrument of individual empowerment . Indeed , the new micros were not only friendly but downright intimate . They were “ mirrors of the mind , ” as the MIT sociologist Sherry Turkle put it in her 1984 book , The Second Self . “ In talking to personal computer owners , ” she explained , “ I found that for them the computer is important not just for what it does but for how it makes you feel . It is described as a machine that lets you see yourself differently , as in control , as ‘ smart enough to do science , ’ as more fully participant in the future . ” 14 Lick couldn’t have said it better himself . In fact , he seems to have found only one thing to complain about in the personal - computer revolution : the machines themselves . “ He got an IBM PC , ” remembers Tracy Licklider , “ but it never had the resources to do what he wanted . ” Yes , Lick knew , these talented little micros had been good enough to reinvent the computer in the public mind , which was no small thing . But so far , at least , they had shown people only the faintest hint of what was possible . Before his vision of a free and open information commons could be a reality , the computer would have to be reinvented several more times yet , becoming not just an instrument for individual empowerment but a communications device , an expressive medium , and , ultimately , a window into online cyberspace . In short , the mass market would have to give the public something much closer to the system that had been created a decade before at Xerox PARC .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11182</div><div class='noteText'>“ It had never occurred to us that people would buy crap , ” declares Alan Kay , who considered the hobbyists in their garages down the hill to be very bright and very creative ignoramuses — undisciplined kids who didn’t read and didn’t have a clue about what had already been done . They were successful only because their customers were just as unsophisticated . “ What none of us was thinking was that there would be millions of people out there who would be perfectly happy with the McDonald’s hamburger approach : they didn’t know it wasn’t real food . ” The PARC - ites had known about the micros from the beginning , of course . They read the hobbyist magazines , too . They shopped at Radio Shack . And at least a few of them attended the twice - weekly meetings of the Homebrew Computer Club , held just a mile or so away , in an auditorium at the Stanford Linear Accelerator Center . Yet like Lick and most of the rest of the ARPA community , they found it hard to see the micros as anything more than toys . Imagine what it was like to go from the Alto’s WYSIWYG text editing to an Apple II , says Jerry Elkind : “ You had to hook it up to a television , and you got only forty characters per line , with no lowercase letters . It was terrible . ’ ” It was a different level of aspiration , ” agrees Chuck Thacker . “ I did buy an Apple II and look at it early on . It turned out to be based on a 6502 microprocessor , which was the same chip we used as a controller in the Alto keyboard ! ” PARC , they were confident , had something much more exciting to offer — if they could ever get that something out the door . This was actually getting to be a matter of some urgency . In 1974 PARC’s technology had been light - years beyond anything else in the world , but by the late 1970s that lead was dwindling fast . PARC hadn’t exactly kept itself a secret , after all . The wizards had published papers , given seminars , recruited students , and proselytized at every opportunity . The lab had likewise kept its door open : just about everybody in the computer field had already visited the place , or knew somebody who was working there , or was angling for a way to work there himself . So PARC’s ideas were known by the late 1970s . As early as 1974 , for example , MIT’s AI Lab had started experimenting with personal machines that were specialized for running Lisp , but with graphics inspired by the bit - mapped display on the Alto . By 1977 , hand - built models were in routine use at Tech Square . And by 1980 , commercial versions were being produced under license by two new Cambridge - area start - ups : Symbolics and Lisp Machine , Inc . At Carnegie Mellon , likewise , a group that included longtime PARC consultant Allen Newell , PARC veteran Bob Sproull , and MIT AI Lab veteran Scott Fahlman had convinced the computer - science department to embrace a version of personal distributed computing that they called the Scientific Personal Integrated Computing Environment , or SPICE . “ The era of time - sharing is ended , ” they declared in the department’s 1979 invitation for vendors to bid on the SPICE computer . “ New possibilities [ include ] high resolution color graphics , 1 million instructions per second , . . . 1 megabyte primary memory , 100 megabyte secondary memory [ hard disk ] . . . . We would expect that by the mid - 1980s such systems could be priced around $ 10,000 . ” They were right . And while the department’s eventual choice in the competition would be a disappointment — the new PERQ computer from start - up Three Rivers , Inc . , conceived as a next - generation derivative of the Alto , proved to contain a number of dead - end design features — the Carnegie Mellon effort was nonetheless a wake up call to the community as a whole : high - end , graphics - based machines of the Alto class and above , a group that people were beginning to call workstations , might actually find a market .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11260</div><div class='noteText'>By now , of course , Steve Jobs’s visit to PARC in December of 1979 has long since passed into legend . “ Apple’s daylight raid , ” as one writer called it , has become one of the founding myths of the personal - computer revolution , the moment when the nimble young Jason snatched the Golden Fleece from the sleeping dragon . Indeed , as reporter Michael Hiltzik pointed out in his 1999 book about PARC , Dealers of Lightning , the mythology has accumulated to the point of burying the reality almost beyond recovery . “ The collective memory of the Jobs visit and of its aftermath is so vivid that some former PARC scientists are no longer sure whether they were there themselves , or just heard about it later , ” as he put it . 15 Nonetheless , Hiltzik’s book includes perhaps the most careful and complete reconstruction of the event to date , and it makes a number of key points . First , Jobs and his crew didn’t need a special presentation to learn about graphical user interfaces . That idea was already in the air by 1979 , along with everything else PARC had done . Since October 1978 , in fact , Apple had been working in secret on a next - generation machine called the Lisa , after Jobs’s out - of - wedlock daughter . The 16 - bit Lisa featured a bit - mapped graphics screen and , by December 1979 , a windowing interface that could be controlled by a mouse . The project was chaotic and unfocused , to be sure , and the interface was clumsy . But it was there . Second , the dragon wasn’t asleep , or even hostile . Quite the opposite : Xerox had courted Apple shamelessly . Or more precisely , the Xerox Development Corporation had . XDC was yet another Xerox subsidiary , recently founded in West Hollywood to make venture - capital investments in promising young firms . Moreover , XDC’s director , Abe Zarem , knew exactly what PARC had — and how ineptly its parent company was handling it . His plan was to license PARC’s technology to one of these lean and hungry start - ups instead , and then let the kids commercialize it . So in the spring of 1979 , when he learned that Apple was raising $ 7 million with a private stock sale to major institutional investors ( the company hadn’t gone public yet ) , Zarem wanted in , and badly . Third , the hero wasn’t quite as nimble as the legends would have it . Initially , at least , Jobs greeted Zarem’s overture with contempt , not an unusual response from him . What could a sclerotic bureaucracy like Xerox do that his own team couldn’t do better and faster ? Partly , this reaction was a function of his counter - cultural disdain for large corporations in general . ( The scruffily bearded Jobs wore his T - shirts , jeans , and sandals like a badge of honor . ) And partly it was attributable to his memory of Steve Wozniak’s former employer , Hewlett - Packard , which had once rebuffed Woz’s proposal for a microcomputer . But in any case , Jobs changed his mind after repeated urging by Apple engineer Jef Raskin , who had joined the company to help design the Apple II . Raskin had visited PARC , as it happened , and his friends there had shown him its wonders . So on April 2 , 1979 , Jobs and his team met with the XDC people and struck a deal that could make sense only in the go - go world of Silicon Valley : Xerox would be allowed to invest $ 1.05 million in Apple’s private stock sale , and in return it would allow Apple full access to PARC’s technology . Jobs had only the vaguest idea of what that involved , evidently . But his engineers were specifically interested in the inner workings of Smalltalk , which they hoped would help them with the Lisa interface . Fourth , the presentation wasn’t a naive giveaway by the Smalltalk team . Granted , Alan Kay himself might have embraced the Apple group as saviors if he’d been there ; certainly he had abandoned any hope of seeing Xerox bring PARC’s technology to market . But Kay had recently gone off to Los Angeles on a long - promised sabbatical , partly to be with a new girlfriend and partly to “ take organ lessons , ” and the interim team leader , Adele Goldberg , still harbored some hope that Xerox would come through . To her mind , this “ alliance ” with Apple was potential suicide for PARC . So when Jobs and his top engineers finally showed up for an afternoon visit in December 1979 , the presentation was as minimal as Goldberg could make it . She and her Smalltalk colleagues gave Jobs and company the standard visitor’s tour : the Alto , the mouse , Bravo word processing , some drawing programs — nothing that the whole world hadn’t seen before . And afterward their guests departed , apparently satisfied . Two days later , having realized almost at once that they’d been shortchanged , Jobs and his crew showed up in the PARC lobby with no advance warning . They wanted to see the good stuff , they said — now . There ensued several hours of argument between the Smalltalk team and its bosses . But in the end , after a direct order , with Xerox headquarters ’ backing up XDC , a red - faced Goldberg did indeed show Jobs and his people the good stuff . This included education applications written by Goldberg herself , programming tools created by Larry Tesler , and animation tools cooked up by Diana Merry for combining pictures and text in a single document — all of it hitherto top - secret material that showed off Smalltalk’s capabilities to the fullest . Just as Goldberg had feared , moreover , Jobs’s engineers were asking very detailed questions ; they seemed to have read everything the Smalltalk team had ever published .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11305</div><div class='noteText'>The climactic moment came when Jobs pointed out that Smalltalk scrolled through text one full line at a time , which made its action rather jerky ; he wondered aloud if it couldn’t scroll continuously , one bit - mapped pixel at a time . Sure , said Dan Ingalls , Smalltalk’s lead programmer . He opened a window , changed a few lines of the scrolling code , then closed the window again , and voilà ! Through the modular magic of object - oriented programming , Smalltalk now scrolled continuously . The visitors were blown away . “ Why hasn’t this company brought this to market ? ” Jobs famously shouted , waving his arms around while his engineers did their best to ignore him and focus on how the system worked . “ What’s going on here ? I don’t get it ! ” By the time the Apple team finally departed , according to Jobs’s later account , he was a “ raving maniac ” : he had seen the future . According to legend , moreover , he immediately ordered that the Lisa be reconfigured to match the Alto display . But in reality , Hiltzik concluded in his book , the visit didn’t have all that much impact on the Lisa — or not directly , anyway . Apple’s partnership with Xerox fell apart soon afterward , the victim of a culture clash that was just too extreme . Lisa’s chief programmer , Bill Atkinson , had to re - create most of what he’d seen on his own . Indirectly , though , the visit did give energy and focus to a project that badly needed both of those things . More important , it was an epiphany for Jobs and his whole team : from now on Apple would follow the gospel according to Smalltalk . “ Lisa must be fun to use , ” declared a project design manifesto written a month or so after the show - and - tell . “ Special attention must be paid to the friendliness of the user interaction and the subtleties that make using the Lisa rewarding and job - enriching . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11396</div><div class='noteText'>Whenever the realization came , however , this was easily the saddest page in the whole PARC story . The young visionaries who had gathered there had participated in one of the great sagas of the information age , the creation of the first modern personal computer . And yet that saga had now become one of the great cautionary tales . Despite a decade’s head start and more , history was passing them by . The business writers Douglas K . Smith and Robert C . Alexander said it all in the title of their 1988 account , Fumbling the Future : How Xerox Invented , Then Ignored , the First Personal Computer . Indeed , in the pop mythology of the personal - computer era , the story of PARC and the Alto has become an endlessly repeated classic : visionary genius stifled by leaden bureaucracy . And yet many of the PARC veterans themselves now see the situation a bit differently . The fact is , they believe , they finally had a chance , and they blew it . Remember , says Butler Lampson : despite all the incomprehension that headquarters showed in the early days , and despite all the mistakes that the higher - ups undoubtedly made with the Star ( perhaps the most notable being that the copier sales force was turned loose to sell the system without any real training in computers ) , “ the fact is that headquarters had the vision for PARC in the beginning . And they sank a lot of money into the development organization . ” In the end , moreover , the higher - ups let Massaro , Liddle , and the research team at the System Development Division shape the Star as they saw fit . “ They knew they didn’t understand computers , but they knew they had a great research lab , ” says Lampson . “ So they figured that the engineers would take care of it . ” And that was the essential tragedy , he says : whereas headquarters understood marketing but not computers , the wizards out on Coyote Hill Road understood computers but not marketing . They had gone into the design process believing fervently in the PARC vision , in personal distributed computing as a whole , integrated system . They knew that it far transcended anything else on the market . And they couldn’t imagine that customers would want anything less . They’d also been given to understand that cost was no constraint : their target was the corporate world , the Fortune 500 — scale customers that were used to shelling out hundreds of thousands of dollars for computer equipment . The result was an unfettered exuberance that led the Star’s designers into at least three critical errors . The first and most obvious was a rampant case of feature - itis : they loaded up the Star software with every neat thing they could think of , until it had grown to roughly a million lines of code and was at the ragged edge of what the 1981 - vintage hardware could support . Indeed , that was the first thing users noticed : the Star was painfully , maddeningly sloooow . A second and more fundamental error was the designers ’ decision to make the Star a closed system , meaning that all the hardware and all the software had to come from Xerox . Now , in fairness , this was how most major corporations had always operated . “ People thought that that was how you became a serious computer company , ” says Jerry Elkind . “ Get the customers hooked , and they were yours for life . ” In the corporate market that the Star was aiming for , moreover , this was what the customers preferred : they were looking for “ turnkey ” installations like IBM mainframes ( or Xerox copiers ) , which would be fully functional as soon as they were installed and would forever after be serviced by the vendor . However , if being closed meant that Xerox could lock in its customers , it also meant that it had to guess right about what those customers wanted ; it had no way to tap into the creativity of the wider community . And in at least one instance , the Star’s software designers spectacularly failed to guess right : the Star had no spreadsheet program . Nobody at PARC had ever thought to write one because nobody in a research lab ever needed one . What they did need was a good way to write technical papers — “ so we got all caught up with WYSIWYG word processing and printing , ” says Elkind . It was precisely the inverse of priorities in the business world . In the executive suites of 1981 , word processing was widely considered to be low - level stenographers ’ work , whereas a spreadsheet was just the kind of application a manager might use . And the result was another sale for Apple , not for Xerox . The closed - system approach likewise left potential customers without an inexpensive , low - risk entry path . The Coyote Hill Road designers had implemented the Star system as a seamless whole , and that was the only way Xerox would sell it . So even leaving aside the fact that a single Star workstation cost more than $ 16,500 , or about ten times as much as an Apple II , customers couldn’t buy just a single Star to see what it could do . They had to buy Stars for everyone , along with all the Ethernet cabling , laser printers , and such that went with them ; a minimal installation cost at least $ 100,000 . And while there were many Fortune 500 executives who could easily afford that , they were understandably leery of betting their entire operation on a brand - new system , especially when they still weren’t too sure what a personal computer was . From the users ’ perspective , it was far safer to wait and see — and in the meantime maybe buy a couple of Apple IIs to kick around . Finally , the third and perhaps most distressing error was that the designers passed up several chances to do something simpler . “ The option was open all through the nineteen - seventies , ” says Lampson . “ We could have shipped something much like the IBM PC , and a short time later shipped something very much like the original Alto . ” Starting around 1979 , in fact , when the Star development was going through a rough phase , senior hardware developer Bob Belleville had agitated for a fresh start : Let’s forget about the Star platform , he said , and instead get the technology out there quickly by creating a 16 - bit microcomputer based on the Motorola 68000 chip , or maybe an Intel 8086 . He even built a prototype in the lab to show that it could be done . But the answer was no . “ I was one of the people involved in deciding against it , ” admits Elkind , “ largely because all the software would have had to be rewritten , and we didn’t have the stomach for it . ” It would have been too painful , agrees Lampson : “ We would have had to scale back too much . [ Belleville’s machine ] wouldn’t have supported the wonderful things you could do with the Star . ” So there it was : with the best intentions in the world , the researchers on Coyote Hill Road created a product that was lovely to behold — and an also - ran in the marketplace . “ We certainly had the idea that computers like the Star would be mass - market items within a decade , ” says Lampson . “ But we just didn’t pay attention to a business model of how to do it . ” And in the end , he says , “ the problem wasn’t a shortage of vision at headquarters . If anything , it was an excess of vision at PARC . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11452</div><div class='noteText'>Fittingly enough , Larry Tesler was among the first to walk . In the spring of 1980 , a few months after the famous visit , Steve Jobs tried to lease Smalltalk for the Lisa . And when Xerox refused ( the partnership was already dead by that point ) , Jobs simply offered to hire Tesler , a Smalltalk team member who had done much of the presentation for the visit . Tesler was receptive , having sensed something stirring in the hobbyist community almost from the beginning . Yes , the garage computers were ridiculously primitive , but people were buying them . And yes , the hobbyists tended to be incredibly naive about what had already been accomplished in computing . But if you actually went to the Homebrew Computer Club meetings — and Tesler was one of the few PARC - ites who regularly attended — you could feel the energy there . The world was full of bright people who didn’t work for PARC , Tesler realized — people who weren’t even part of the ARPA community . And they were learning fast . So he accepted Jobs’s offer and went to Apple , where he would eventually become the company’s chief scientist .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11520</div><div class='noteText'>The inevitable showdown came in late August 1983 , when the physicist Bill Spencer , who had been named the director of PARC earlier that year , presented Taylor with a memo detailing a dozen ways in which he was to modify his behavior — along with a demand that he report to the director’s office every Monday morning at nine to discuss his progress toward these goals . Taylor , grossly insulted , refused . A mediation effort by the office of David Kearns himself proved fruitless . On Monday , September 19 , Taylor called a CSL meeting in the beanbag room , with Spencer in attendance . After an emotional farewell , he announced his resignation and walked out of the room , to be followed a few moments later by Chuck ( “ This is bullshit ! ” ) Thacker . A shaken Spencer was left to face the wrath of fifty people who had just lost the only leader many of them had ever known , along with their top hardware wizard ( “ You can fucking resign ! ” he was told by one anonymous shouter ) . Spencer himself did not resign , but many others did . By January 1984 Taylor had arranged for DEC to launch a new DEC Systems Research Center in downtown Palo Alto , with himself as director . Many of PARC’s finest soon joined him , a group that included Butler Lampson , Chuck Thacker , and thirteen others . PARC’s computer - research capabilities were devastated and would take years to recover .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11543</div><div class='noteText'>Indeed , the personal - computer revolution was what transformed the Bob Metcalfe of 1979 into the Bob Metcalfe of today : the proud possessor of a farm in Maine , a town house suitable for an embassy in Boston’s tony Back Bay neighborhood , a prestigious second career in technology journalism , and a personal fortune that amounts to a noticeable fraction of Bill Gates’s . “ I tell people I didn’t get rich inventing Ethernet , ” he says with a laugh . “ I got rich selling it ! ” Just so — though in truth , the microcomputer market was something of a tough sell in those early days . Partly it was a matter of technology , since the early micros were too feeble to handle network communications very effectively . But much of it was also cultural : back in the hobbyist days of micros , in the 1970s , the emphasis had always been on the individual user and the individual machine . Lots of people had modems , of course , but a permanent network connection , as with Ethernet , was exotic to the point of being incomprehensible . That was why Steve Jobs and his engineers had come away from their infamous visit to PARC having totally missed the significance of the Alto’s Ethernet connection — as Jobs himself would later admit . Indeed , in those days Jobs absolutely despised the idea of networking . Like many of his contemporaries , he felt that tying your machine to someone else’s meant giving up your autonomy — an unthinkable choice for any child of the Me Decade , and a violation of everything that personal computing seemed to stand for . ( Legend has it that when Jobs was later asked why the Lisa didn’t have a networking port , he threw a floppy disk at the questioner and snarled , “ There’s my fucking network . ” )</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11595</div><div class='noteText'>Thus the “ Hacker Farm , ” a program that funded undergraduates to come and get their hands dirty alongside the professionals in Tech Square . “ There was a core group of about six of us who were in the first round and who were actually living in the same dorm , ” says Malone . “ We wound up in the part of the Hacker Farm that was located with the Dynamic Modeling group on the second floor , right near Lick’s office . Around our second year , in fact , when LCS got money for a major remodeling of the second floor , Lick insisted that the undergraduates get a space of our own and that we get to design it ourselves . So we chose a large open area in the center of the building and did it up with green carpets and blue walls , so that it would look as much as possible like the outdoors . We called it the Meadow , after the ‘ Bloom County ’ comic strip . Lick’s office was right across from that . “ Meanwhile , ” Malone continues , “ about the same time that Athena was being set up , there was a parallel effort by DEC to experiment with personal computing , to learn what it would be like to have one computer per person . So they donated twenty VAX / 750s . We helped uncrate them ; they were about the size of washing machines . Lick stretched the rules and got one assigned to the undergraduates . The staffers and professors were naming their machines after beers : Heineken , Molson , XX — Dos Equis — and so on . But since we were all under the drinking age in Massachusetts , we named ours Grape Nehi . Lick later got a Micro VAX and named it ClassiCola , which we felt was a vote of solidarity . Also , since we were sharing a computer , we needed a group name so we could share files . It had to be one word in lower case because we were using Unix , so someone came up with lixkids . “ Anyway , as we started doing serious development on Grape Nehi , we started running out of disk space . Lick had no hesitation : he pulled out a catalog and bought the best Misubishi disk drive available . Also the fastest controller . The first we heard of it was the day he walked in and said , ‘ Here it is ! ’ — and went home . Well , the thing weighed forty pounds . There was no case , just a raw drive . It was supposed to be rack - mounted , and we had no rack . The documentation was obviously translated from the Japanese . So we hauled it up to the ninth floor and got an old rack from somewhere . But the holes on the rack didn’t line up with the holes on the drive . So we had to drill new holes . Then the controller was a different brand from the drive ; we had to rejumper it with raw wires . At any time we could have fried the thing — we could have fried Grape Nehi ! It was a miracle we didn’t . I don’t know how many days it was before we got it working . But we did , and Lick was impressed . He told us much later that he’d fully expected to have to hire an expert to install this thing . But he’d decided to let us try first because he knew it would be a learning experience . He figured that the money was better spent in training us to use the equipment , and to gain confidence , than in bringing in an outside expert . Lick considered that that was what we were there for . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11691</div><div class='noteText'>the NSF had a reputation for spreading its funding around to small research groups all over the country , a practice that ( again allegedly ) kept Congress happy but most definitely made it harder to build up a Project MAC — style critical mass of talent in any one place . And worst of all , from the computerists ’ point of view , was that the NSF’s support for computing had always been anemic at best , particularly in comparison with ARPA’s . In the early 1970s , in fact , the agency had even stopped funding campus computer centers , which had left a lot of universities with aging machines and no money to upgrade them . Still , the NSF was the only funding agency chartered to support the research community as a whole . Moreover , it had a long tradition of undertaking projects such as the Kitt Peak National Observatory and the U.S . Antarctic research bases — big infrastructure efforts that served large segments of the community in common . And on those rare occasions when the auspices were good , the right people were in place , and the planets were lined up just so , it was an agency where great things could happen . Certainly that was the case with the Internet , which not only survived but went on to achieve its stunning growth in the 1990s largely thanks to NSF’s efforts in the 1980s . The impetus for the foundation’s first foray into networking had come from computer scientists at the “ have - not ” universities , who were sick of being shut out of the Arpanet . By the late 1970s it was painfully obvious that the ‘ Net made it much easier for their colleagues at the “ have ” schools to share results and collaborate with one another , which in turn made it much easier for them to advance their research . So in 1979 , with Larry Landweber of the University of Wisconsin and David Farber of the University of Delaware taking the lead , the have - nots started lobbying the NSF to finance some form of equal access to the Arpanet . And in January 1981 the agency duly launched CSnet , the Computer Science Network . “ This was actually a seminal program , ” says Steve Wolff , who would later become the NSF’s networking chief . “ Not only did CSnet open up the Arpanet to the entire computer - science community , but it was the first instance of shared use by anyone . ” In the process , moreover , the TCP / IP protocol — for that was what CSnet used — began to expand beyond its ghetto in the Defense Department .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11800</div><div class='noteText'>Along the way the agencies had also begun to consolidate their various networks around TCP / IP . Why should each agency maintain a specialized system for its own researchers when the NSFnet was open to everybody ? Indeed , in one of the more poignant ironies of the story , the offspring quickly displaced its parent . Recognizing that the megabit speeds of the upgraded NSFnet had turned the 56 - kilobit Arpanet into a dinosaur , ARPA officials started systematically decommissioning their venerable IMPs and transferring their users to the faster network . By 1990 the Arpanet was history . The upshot , says Wolff , was that by the beginning of the 1990s the de facto national research network was in place , and TCP / IP ruled : the Internet had expanded from its original base in the Defense Department to the research community as a whole . But of course , the expansion hardly stopped there ; Wolff was already taking steps to extend the Internet into the commercial arena as well . “ I pushed the Internet as hard as I did because I thought it was capable of becoming a vital part of the social fabric of the country — and the world , ” he says . “ But it was also clear to me that having the government provide the network indefinitely wasn’t going to fly . A network isn’t something you can just buy ; it’s a long - term , continuing expense . And government doesn’t do that well . Government runs by fad and fashion . Sooner or later funding for NSFnet was going to dry up , just as funding for the Arpanet was drying up . So from the time I got here , I grappled with how to get the network out of the government and instead make it part of the telecommunications business . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11828</div><div class='noteText'>Now , this scheme didn’t get fully implemented until they were planning the 1988 upgrade , says Wolff . But in due course , with NSF’s providing the seed money , the regional networks took shape , all operating as not - for - profit Internet access providers to the research community . However , he says , “ we told them , ‘ You guys will eventually have to go out and find other customers . We don’t have enough money to support the regionals forever . ’ So they did — commercial customers . We tried to implement an NSF Acceptable Use Policy to ensure that the regionals kept their books straight and to make sure that the taxpayers weren’t directly subsidizing commercial activities . But out of necessity , we forced the regionals to become general - purpose network providers . ” Or as they would soon be called , Internet Service Providers . Vint Cerf , for one , is still lost in admiration for this little gambit . “ Brilliant , ” he calls it . “ The creation of those regional nets and the requirement that they become self - funding was the key to the evolution of the current Internet . ” Certainly the gambit was effective . While it’s true that many of the regionals themselves faltered rather badly in the marketplace , some of them did quite well . New York’s NYSERnet , for example , spun off its operational activities into a very successful commercial subsidiary , Performance Systems International ( PSInet ) in Reston , Virginia . And in any case , there were any number of independent access providers springing up as well . “ So by nineteen - ninety , ” says Wolff , “ we had all these young but extremely vigorous commercial operators who had no commitment to academia . They would just sell Internet access to business , industry , individuals , whoever would buy it . ”</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11842</div><div class='noteText'>Indeed , this new wave of sellers and buyers soon became something of a self - exciting system . On the supply side , there were national carriers offering business - class service in the major cities , small - town PC retailers offering dial - in access to local customers as a sideline , and everything in between : entry into the market was comparatively cheap and easy by the early 1990s , if only because all the necessary Internet hardware was now available off the shelf . Routers , connectors , cables , modems — entrepreneurial firms such as Cisco Systems had been churning them out ever since the Defense Department first embraced TCP / IP , in the early 1980s . And then with the coming of the NSFnet in 1986 , their market had been virtually guaranteed . The first Interop trade show attracted five thousand engineers , who browsed through exhibits from fifty companies — and that was in September 1988 , when there were “ only ” some sixty thousand host computers on the Internet . By 1991 , when the NSF did its second backbone upgrade , the Internet was connecting ten times that many host computers , and the provider business was booming . It was also becoming obstreperous . During the NSFnet upgrade of 1991 , most notably , a group of commercial access providers led by PSI alleged that the upgrade was being managed in a manner that was anticompetitive . The networking industry had matured to the point where NSF ( or the regional networks ) could simply buy long - distance backbone services on the open market . And yet , they said , Wolff and company had arbitrarily awarded the backbone contract to a single vendor known as ANS — a consortium of IBM , MCI , and Merit , a Michigan firm that had run the earlier backbone . “ They called it a partnership , ” fumed PSI president William Schrader . “ I called it a conspiracy . ” Back at headquarters , Wolff enjoyed this about as much as any parent enjoys listening to a rebellious teenager . Nonetheless , he insists that he was delighted with the outcome : after some scathing congressional hearings and a two - year investigation by the NSF Inspector General ( which found no wrongdoing ) , his office was “ forced ” to do what he’d always been aiming toward anyway , which was to push the Internet into the private sector . In 1992 Congress passed a bill that formally allowed for - profit access providers to use the NSFnet backbone . And on April 30 , 1995 , the NSFnet ceased to exist : Wolff’s office would henceforth take the backbone’s $ 12 million annual operating cost and start distributing it to the regional networks to buy long - distance service on the open market from vendors such as MCI . ( That funding , in turn , would decline to zero over the next four years . ) The foundation would continue to operate a much smaller , very - high - speed system connecting its supercomputer centers at 155 megabits per second . But beyond that , the Internet was at last on its own , and self - sustaining .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11865</div><div class='noteText'>On the demand side , meanwhile , all these new , nonacademic customers were discovering that entry into the Internet was considerably less intimidating than it had once been . Thanks to the Usenet newsgroups , for example , as well as the ListServ mailing lists that had originated on Bitnet , the sense of community was stronger than ever : you could always find someone on the Internet who shared your interests . Then , too , E - mail had been standardized and greatly streamlined , first in January 1983 , when ARPA adopted the simple mail - transfer protocol ( SMTP ) , and then in January 1986 , when a summit of network representatives sorted out the ad hoc chaos of Internet addressing . ( They had to do something , said one participant : every host computer on the Internet needed a name , and everybody wanted to claim “ Frodo . ” ) The solution was DNS , the now - famous domain - name system that assigns each host computer a sequence of names separated by periods , as in lcs.mit.edu . New users could likewise find a variety of new tools for navigating the ‘ Net . In 1990 , for instance , programmers at the University of Minnesota created a popular utility known as Gopher , which allowed a user to search for information on the Internet via a series of hierarchical menus . Shortly thereafter , another group at Thinking Machines , Inc . , came up with WAIS , the Wide Area Information Service , which enabled users to search for Internet files based on their content . And then around Christmastime 1990 , at CERN , the European Center for Particle Physics in Geneva , Switzerland , an English physicist named Tim Berners - Lee finished the initial coding of a system in which Internet files could be linked via hypertext . Actually , Berners - Lee had already been playing with the idea of hypertext for a full decade by that point , having independently reinvented the idea long before he ever heard of Vannevar Bush , Doug Engelbart , Ted Nelson , or , for that matter , the Internet itself ; his first implementation , in 1980 , had been a kind of free - form database that simply linked files within a single computer . But having a program follow hyperlinks across the network was an obvious extension of the idea , especially after CERN joined the Internet in the late 1980s . Thus the 1990 implementation , which also included Berners - Lee’s notion of “ browsing ” : the program had a word - processor - like interface that displayed the links in a file as underlined text ; the user would just click on a link with the mouse , and the program would automatically make the leap , display whatever files or pictures it found at the other end , and then be ready to leap again .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 11903</div><div class='noteText'>“ I think he knew something was going wrong with him all that day , ” says Louise Licklider , thinking back to the beginning of June 1990 . “ We were driving back from a vacation trip through the Midwest , ” she explains . “ He loved to drive . But we both knew that this would be our last vacation . Robin [ still her pet name for her husband ] had asthma , which was rapidly getting worse . He had Parkinson’s that was rapidly getting worse . And now he had prostate cancer that had metastasized . So on the trip coming back , I had been steeling myself for rapid changes in our life - styles . ” On the last leg toward home , Lick seemed to be in a nostalgic , sentimental mood , as if he were very far away . “ It was unusual for him to be that far back in the past , ” she says . “ It was different enough that it caught my attention . Then when we got to the end of the Massachusetts Turnpike , there was an inn out in the countryside where we often liked to stop . So he said , ‘ Let’s go in for a martini . ’ We did , and we sat there on the porch for a while . Finally , he said , ‘ What do you say we just sit here all afternoon ? ’ It was a beautiful day , and he didn’t want to leave . But I said , ‘ Oh , come on , Robin ! You need to get home and rest . ’ So we went home . And all the way in , he hummed and sang all the old love songs that were popular back when we were dating . So looking back on it later , I had to feel that he had some premonition that something was going on in his body . “ When we got home , ” Louise continues , “ he went upstairs . I was picking up the mail when suddenly he called down to me very urgently , ‘ Louise , bring me a pen ! ’ ” Louise ? “ I knew something was wrong because he never called me Louise — always Sugar , or Shuggie . So I grabbed a pen out of the kitchen — one of those silly little things you keep with a notepad — and ran upstairs . ” Linda Licklider Smith , who lived with her own family just a block away , can vividly remember being awakened by her mother’s frantic phone call , throwing on some clothes , and then running down the dark street to her parents ’ house . “ The night was beautiful , and the silence of the street was deafening , ” she says . “ I immediately went upstairs to my parents ’ bedroom and found my father collapsed on the floor . I tried to find a pulse , but I could not . ” The ambulance crew were able to keep Lick alive using CPR until they could get him to Symmes Hospital in Arlington , where the emergency - room doctors got his heart beating again . But his wife and daughter both knew that too many minutes had passed in the interim . “ He’s brain - dead , isn’t he ? ” Louise asked the doctors . And they said , “ Yes . ” Louise looked at the forest of tubes and pumps forcing oxygen into and out of her husband’s lungs , the IV bags dripping nutrients into his bloodstream , the electrodes and wires monitoring his heart . “ Take all that stuff off ! ” she demanded . She tried somehow to make them understand that this was a man who lived by his brains , whose greatest joy was the playful workings of his imagination , who . . .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 12025</div><div class='noteText'>Much later , says Louise Licklider , when she decided to move out of the house in suburban Arlington , Massachusetts , where they’d lived for the past twenty - five years , she had to confront the space in the basement where her husband had stored his “ papers . ” “ The MIT Archives had been desperate for his papers , ” she says . “ They kept saying , ‘ We’ll send someone to take it all out . ’ And I kept saying , ‘ That just isn’t possible . ’ They thought I was simply being emotional and difficult . But I wasn’t . Robin was a very specific , accurate man . But he was not a filer . He had a natural inclination to save everything , even erasers that had worn down . So he had all these personal things in the middle that I wasn’t about to sort out . “ Well , Archives got very irritated and finally quit bugging me . But when I moved , a young man named Keith , who loved and adored Lick , came and stood beside me as we went through the basement , just shaking his head . You’d pick up a paper , and it would be a test from a course he taught twenty years ago . Under that would be a flier advertising a lecture . There would be maps of towns he’d been in that had no historical significance , because he liked old maps . I’d throw a few things into a box for MIT , but most of it we threw out . “ Well , ” she says , “ at one point I heard Keith just burst out laughing . Anything Lick loved , he loved — chocolate , for one thing . And Keith had come across a folder full of chocolate - bar wrappers that Lick had collected , all neatly folded . Beautiful wrappers from all over the world . . . ”</h3>
<h2 class='sectionHeading'>Addendum</h2><h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 14298</div><div class='noteText'>“ Man - computer symbiosis ” is a subclass of man - machine systems . There are many man - machine systems . At present , however , there are no man - computer symbioses . The purposes of this paper are to present the concept and , hopefully , to foster the development of man - computer symbiosis by analyzing some problems of interaction between men and computing machines , calling attention to applicable principles of man - machine engineering , and pointing out a few questions to which research answers are needed . The hope is that , in not too many years , human brains and computing machines will be coupled together very tightly , and that the resulting partnership will think as no human brain has ever thought and process data in a way not approached by the information - handling machines we know today .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 14315</div><div class='noteText'>Man - computer symbiosis is probably not the ultimate paradigm for complex technological systems . It seems entirely possible that , in due course , electronic or chemical “ machines ” will outdo the human brain in most of the functions we now consider exclusively within its province . Even now , Gelernter’s IBM - 704 program for proving theorems in plane geometry proceeds at about the same pace as Brooklyn high school students , and makes similar errors . [ 12 ] There are , in fact , several theorem - proving , problem - solving , chess - playing , and pattern - recognizing programs ( too many for complete reference [ 1 , 2 , 5 , 8 , 11 , 13 , 17 , 18 , 19 , 22 , 23 , 25 ] ) capable of rivaling human intellectual performance in restricted areas ; and Newell , Simon , and Shaw’s [ 20 ] “ general problem solver ” may remove some of the restrictions . In short , it seems worthwhile to avoid argument with ( other ) enthusiasts for artificial intelligence by conceding dominance in the distant future of cerebration to machines alone . There will nevertheless be a fairly long interim during which the main intellectual advances will be made by men and computers working together in intimate association . A multidisciplinary study group , examining future research and development problems of the Air Force , estimated that it would be 1980 before developments in artificial intelligence make it possible for machines alone to do much thinking or problem solving of military significance . That would leave , say , five years to develop man - computer symbiosis and 15 years to use it . The 15 may be 10 or 500 , but those years should be intellectually the most creative and exciting in the history of mankind .</h3>
<h3 class='noteHeading'>Highlight (<span class='highlight_yellow'>yellow</span>) - Location 14333</div><div class='noteText'>However , many problems that can be thought through in advance are very difficult to think through in advance . They would be easier to solve , and they could be solved faster , through an intuitively guided trial - and - error procedure in which the computer cooperated , turning up flaws in the reasoning or revealing unexpected turns in the solution . Other problems simply cannot be formulated without computing - machine aid . Poincare anticipated the frustration of an important group of would - be computer users when he said , “ The question is not , ‘ What is the answer ? ’ The question is , ‘ What is the question ? ’ ” One of the main aims of man - computer symbiosis is to bring the computing machine effectively into the formulative parts of technical problems .</h3>
</div> 
</body> 
</html> 
